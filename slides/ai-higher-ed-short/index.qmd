---
title: "KI in der Hochschulbildung"
subtitle: "Werkzeuge f√ºr Experten, Herausforderungen f√ºr Lernende"
author:
  - name: Andrew Ellis
    url: https://github.com/awellis
    affiliation: Virtuelle Akademie, Berner Fachhochschule
    affiliation-url: https://virtuelleakademie.ch
    orcid: 0000-0002-2788-936"
# institute: "Virtuelle Akademie, Berner Fachhochschule"
format:
  revealjs:
    theme: default
    slide-number: true
    preview-links: auto
    footer: "KI in der Lehre: Refresher"
    navigation-mode: linear
    controls: true
    progress: true
    hash: true
    center: false
    transition: fade
    width: 1600
    height: 900
    margin: 0.1
bibliography: ../../bibliography.bib
---

```{r}
#| include: false
library(tidyverse)

# Set seed for reproducible simulated data
set.seed(2025)

# Color palette - define once, use everywhere
color_primary <- "#A3195B"
color_secondary <- "#666666"
color_tertiary <- "#999999"

# Base minimalist theme for all figures
theme_minimal_custom <- theme_minimal(base_size = 18) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey90"),
    axis.line = element_line(color = "black", linewidth = 0.5),
    axis.ticks = element_line(color = "black"),
    plot.title = element_text(face = "bold", size = 20),
    plot.subtitle = element_text(color = "grey40"),
    legend.position = "bottom"
  )

# Variant with top legend for line plots
theme_minimal_top_legend <- theme_minimal_custom +
  theme(
    legend.position = "top",
    legend.text = element_text(size = 16)
  )
```

## Ein √ºberraschendes Ergebnis

<br>

::: {.columns}
::: {.column width="50%"}

**Mit KI-Zugang:**

<br>

[48% mehr Aufgaben]{.fragment style="font-size: 2em; font-weight: bold; color: #2E7D32;"}

[korrekt gel√∂st]{.fragment}

:::

::: {.column width="50%"}

**Ohne KI (sp√§ter):**

<br>

[17% schlechter]{.fragment style="font-size: 2em; font-weight: bold; color: #A3195B;"}

[als die Kontrollgruppe]{.fragment}

:::
:::

. . .

<br><br>

::: {style="background-color: #f0f0f0; padding: 1em; border-radius: 8px;"}
**Quelle:** @bastaniGenerativeAIGuardrails2025:

~1000 Gymnasiasten, GPT-4 Zugang w√§hrend Mathe-√úbungen
:::

::: {.notes}
Ich m√∂chte mit einem √ºberraschenden Befund beginnen, der die Komplexit√§t unseres Themas illustriert.

In einer gross angelegten Studie mit etwa 1000 Gymnasiasten in der T√ºrkei erhielten Sch√ºler Zugang zu GPT-4 w√§hrend ihrer Mathematik-√úbungen.

[KLICK] Die Ergebnisse w√§hrend der √úbungsphase waren beeindruckend: 48 Prozent mehr Aufgaben korrekt gel√∂st.

[KLICK] Klingt nach einem Erfolg, oder? Aber dann kam der Test ohne KI-Zugang.

[KLICK] 17 Prozent schlechter als die Kontrollgruppe.

[KLICK] Das ist die zentrale Spannung: Mehr Aufgaben gel√∂st bedeutet nicht automatisch mehr gelernt.

Der 17%-Nachteil entspricht etwa 0.2-0.3 Standardabweichungen. Relevant, aber kein Totalausfall. Wichtig: Die Studie testete auch einen "GPT Tutor" mit p√§dagogischen Leitplanken, der deutlich bessere Ergebnisse zeigte. Das Problem ist nicht KI an sich, sondern wie sie eingesetzt wird.
:::

## Das Paradox

<br>

```{r}
#| fig-width: 12
#| fig-height: 6
#| echo: false

# Simulated data showing the paradox with uncertainty
# In test phase, groups are similar (overlapping confidence intervals)
paradox_data <- tibble(
  phase = factor(
    rep(c("√úbungsphase\n(mit/ohne KI)", "Test\n(alle ohne KI)"), each = 2),
    levels = c("√úbungsphase\n(mit/ohne KI)", "Test\n(alle ohne KI)")
  ),
  gruppe = rep(c("Mit KI", "Ohne KI"), 2),
  leistung = c(85, 60, 55, 60),
  se = c(3, 3, 6, 5)
)

ggplot(paradox_data, aes(x = phase, y = leistung, group = gruppe, color = gruppe)) +
  geom_line(linewidth = 1.5) +
  geom_errorbar(
    aes(ymin = leistung - se, ymax = leistung + se),
    width = 0.1,
    linewidth = 0.8
  ) +
  geom_point(size = 5) +
  scale_color_manual(
    values = c("Mit KI" = color_primary, "Ohne KI" = color_secondary),
    name = NULL
  ) +
  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 25)) +
  labs(
    x = NULL,
    y = "Aufgabenleistung (%)"
  ) +
  theme_minimal_top_legend
```

. . .

<br>

**Aufgabenleistung ‚â† Lernen**

::: {.notes}
Hier sehen wir das Paradox visualisiert.

Die magentafarbene Linie zeigt die Gruppe mit KI-Zugang, die graue die Kontrollgruppe ohne KI.

In der √úbungsphase links performt die KI-Gruppe deutlich besser. Das macht Sinn: Sie hatten ja Hilfe. Der Unterschied ist klar, die Fehlerbalken √ºberlappen nicht.

Aber schauen Sie, was beim Test passiert. Die KI-Gruppe schneidet tendenziell schlechter ab, aber beachten Sie die Fehlerbalken: Sie √ºberlappen sich. Der Unterschied ist statistisch nicht so dramatisch, wie die Linien allein suggerieren w√ºrden.

[KLICK] Die Kernaussage: Aufgabenleistung ist nicht dasselbe wie Lernen. Wir verwechseln oft Performanz mit Kompetenz. Wenn Studierende mit KI-Hilfe eine Aufgabe l√∂sen, sehen wir die Performanz des Systems, nicht unbedingt das Lernen des Studierenden.
:::

## Das Nadel√∂hr des Lernens {.nostretch}

```{r}
#| fig-width: 14
#| fig-height: 5.5
#| echo: false
#| out-width: "95%"
#| fig-align: "center"

# Bottleneck visualization with hourglass shape for working memory

ggplot() +
  # Left box: Neue Information (wide)
  geom_rect(
    aes(xmin = 0.5, xmax = 2, ymin = 0.2, ymax = 0.8),
    fill = color_tertiary, color = "white", linewidth = 2
  ) +
  # Right box: Langzeitged√§chtnis (wide)
  geom_rect(
    aes(xmin = 4, xmax = 5.5, ymin = 0.2, ymax = 0.8),
    fill = color_secondary, color = "white", linewidth = 2
  ) +
  # Middle: Bottleneck/hourglass shape using polygon
  geom_polygon(
    aes(
      x = c(2.4, 2.85, 3.15, 3.6, 3.6, 3.15, 2.85, 2.4),
      y = c(0.8, 0.55, 0.55, 0.8, 0.2, 0.45, 0.45, 0.2)
    ),
    fill = color_primary, color = "white", linewidth = 2
  ) +
  # Arrows connecting components
  geom_segment(
    aes(x = 2.05, xend = 2.35, y = 0.5, yend = 0.5),
    arrow = arrow(length = unit(0.4, "cm"), type = "closed"),
    linewidth = 2, color = "grey40"
  ) +
  geom_segment(
    aes(x = 3.65, xend = 3.95, y = 0.5, yend = 0.5),
    arrow = arrow(length = unit(0.4, "cm"), type = "closed"),
    linewidth = 2, color = "grey40"
  ) +
  # Labels above shapes
  geom_text(
    aes(x = 1.25, y = 0.93, label = "Neue\nInformation"),
    size = 6, fontface = "bold", lineheight = 0.9
  ) +
  geom_text(
    aes(x = 3, y = 0.93, label = "Arbeitsged√§chtnis"),
    size = 6, fontface = "bold"
  ) +
  geom_text(
    aes(x = 4.75, y = 0.93, label = "Langzeit-\nged√§chtnis"),
    size = 6, fontface = "bold", lineheight = 0.9
  ) +
  # Capacity labels inside shapes
  geom_text(
    aes(x = 1.25, y = 0.5, label = "‚àû"),
    size = 14, color = "white", fontface = "bold"
  ) +
  geom_text(
    aes(x = 3, y = 0.5, label = "4¬±1"),
    size = 7, color = "white", fontface = "bold"
  ) +
  geom_text(
    aes(x = 4.75, y = 0.5, label = "‚àû"),
    size = 14, color = "white", fontface = "bold"
  ) +
  # Bottleneck annotation
  geom_text(
    aes(x = 3, y = 0.07, label = "DAS NADEL√ñHR"),
    size = 6, color = color_primary, fontface = "bold"
  ) +
  coord_cartesian(xlim = c(0.2, 5.8), ylim = c(0, 1)) +
  theme_void() +
  theme(plot.margin = margin(5, 5, 5, 5))
```

. . .

::: {style="background-color: #F5E6C8; padding: 0.8em; border-radius: 8px; margin-top: 0.5em;"}
{{< fa lightbulb >}} **Kernaussage:** Alles Lernen muss durch das Nadel√∂hr des Arbeitsged√§chtnisses [@swellerCognitiveLoadTheory2024].
:::

::: {.notes}
Um zu verstehen, warum das passiert, m√ºssen wir einen kurzen Ausflug in die Kognitionspsychologie machen.

Hier sehen Sie ein vereinfachtes Modell des menschlichen Ged√§chtnisses. Links die neue Information, rechts das Langzeitged√§chtnis, und in der Mitte: das Nadel√∂hr.

Das Arbeitsged√§chtnis hat eine stark begrenzte Kapazit√§t: etwa 4 plus/minus 1 Elemente gleichzeitig. Neue Information links ist unbegrenzt. Das Langzeitged√§chtnis rechts ist praktisch unbegrenzt. Aber alles, was von links nach rechts wandern soll, muss durch dieses enge Nadel√∂hr.

[KLICK] Das ist die Kernaussage der Cognitive Load Theory: Alles Lernen muss durch das Nadel√∂hr des Arbeitsged√§chtnisses. Es gibt keinen Weg drumherum. Keine Abk√ºrzung. Keine KI kann diesen biologischen Engpass umgehen.
:::

## Erw√ºnschte Schwierigkeiten

<br><br>

::: {style="font-size: 1.4em; text-align: center; font-style: italic; max-width: 80%; margin: 0 auto;"}
"Conditions that slow the rate of apparent learning often optimize long-term retention and transfer."
:::

<br>

::: {style="text-align: center; color: #666;"}
Robert Bjork [@bjorkMakingThingsHard2011]
:::

. . .

<br><br>

::: {style="text-align: center; font-size: 1.2em;"}
**Schwerer f√ºhlt sich schlechter an, ist aber besser f√ºr langfristiges Lernen.**
:::

::: {.notes}
Das bringt uns zu einem kontraintuitiven Konzept: den erw√ºnschten Schwierigkeiten, oder auf Englisch "Desirable Difficulties".

Hier ein Zitat von Robert Bjork: "Conditions that slow the rate of apparent learning often optimize long-term retention and transfer."

√úbersetzt: Bedingungen, die das scheinbare Lernen verlangsamen, optimieren oft das langfristige Behalten und den Transfer.

[KLICK] Oder noch k√ºrzer: Schwerer f√ºhlt sich schlechter an, ist aber besser f√ºr langfristiges Lernen.

Das ist ein fundamentales Prinzip, das wir immer wieder vergessen. Wenn Lernen sich leicht anf√ºhlt, lernen wir wahrscheinlich weniger, als wenn es sich anstrengend anf√ºhlt.
:::

## Die vier Strategien

<br>

::: {.columns}
::: {.column width="25%"}

{{< fa pen size=3x >}}

<br>

**Selbst generieren**

[Eigene Antworten formulieren]{style="color: #666; font-size: 0.9em;"}

:::

::: {.column width="25%"}

{{< fa calendar size=3x >}}

<br>

**Verteilt lernen**

[Zeitliche Abst√§nde einbauen]{style="color: #666; font-size: 0.9em;"}

:::

::: {.column width="25%"}

{{< fa brain size=3x >}}

<br>

**Aktiv abrufen**

[Wissen aus dem Ged√§chtnis holen]{style="color: #666; font-size: 0.9em;"}

:::

::: {.column width="25%"}

{{< fa shuffle size=3x >}}

<br>

**Variieren**

[Themen und Aufgaben mischen]{style="color: #666; font-size: 0.9em;"}

:::
:::

. . .

<br><br>

::: {style="background-color: #f0f0f0; padding: 1em; border-radius: 8px; text-align: center;"}
{{< fa robot >}} **KI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit √ºbernimmt.**
:::

::: {.notes}
Bjork hat vier konkrete Strategien identifiziert, die als erw√ºnschte Schwierigkeiten fungieren:

[KLICK] Erstens, selbst generieren. Eigene Antworten formulieren, statt vorgegebene zu lesen.

[KLICK] Zweitens, verteilt lernen. Zeitliche Abst√§nde einbauen.

[KLICK] Drittens, aktiv abrufen. Wissen aus dem Ged√§chtnis holen, statt es nachzuschlagen.

[KLICK] Viertens, variieren. Themen und Aufgabentypen mischen.

[KLICK] Und hier kommt der kritische Punkt: KI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit √ºbernimmt.

Warum selbst generieren, wenn KI es besser kann? Warum sich anstrengen, wenn die Antwort einen Klick entfernt ist? Warum aus dem Ged√§chtnis abrufen, wenn ich nachfragen kann?
:::

## Der Generierungseffekt {.nostretch}

```{r}
#| fig-width: 10
#| fig-height: 5
#| out-width: "50%"
#| fig-align: "center"
#| echo: false

# Simulated data based on generation effect literature
generation_data <- tibble(
  methode = factor(
    c("Selbst\ngeneriert", "Gelesen", "Von KI\nerhalten"),
    levels = c("Selbst\ngeneriert", "Gelesen", "Von KI\nerhalten")
  ),
  retention = c(70, 50, 35),
  se = c(5, 5, 8)
)

ggplot(generation_data, aes(x = methode, y = retention, fill = methode)) +
  geom_col(width = 0.6) +
  scale_fill_manual(
    values = c(
      "Selbst\ngeneriert" = color_primary,
      "Gelesen" = color_secondary,
      "Von KI\nerhalten" = color_tertiary
    ),
    guide = "none"
  ) +
  geom_errorbar(
    aes(ymin = retention - se, ymax = retention + se),
    width = 0.2,
    linewidth = 0.8
  ) +
  scale_y_continuous(
    limits = c(0, 100),
    breaks = seq(0, 100, 25),
    labels = function(x) paste0(x, "%")
  ) +
  labs(
    x = NULL,
    y = "Behaltensleistung"
  ) +
  theme_minimal_custom

```

Selbst generierte Information wird besser behalten [@slameckaGenerationEffectDelineation1978].

. . .

<br>

**Wenn KI generiert, was Studierende selbst produzieren sollten, entf√§llt der Lerneffekt.**

. . .

<br>

[Der Generierungseffekt ist nicht neu. Immer wenn Technologie kognitive Arbeit √ºbernimmt, sehen wir √§hnliche Muster...]{style="color: #666; font-style: italic;"}

::: {.notes}
Schauen wir uns den Generierungseffekt genauer an, weil er besonders relevant f√ºr KI ist.

Die Grafik zeigt die Behaltensleistung in Prozent. Selbst generierte Information wird am besten behalten, etwa 70 Prozent. Gelesene Information liegt bei etwa 50 Prozent. Und von KI erhaltene Information? Noch niedriger, hier illustrativ bei etwa 35 Prozent dargestellt.

Die Forschung zum Generierungseffekt stammt aus den 1970er Jahren. Slamecka und Graf zeigten, dass selbst produziertes Material besser behalten wird als passiv aufgenommenes.

[KLICK] Die Implikation ist klar: Wenn KI generiert, was Studierende selbst produzieren sollten, entf√§llt der Lerneffekt.

[KLICK] Aber dieser Effekt ist nicht neu. Das bringt uns zu den historischen Analogien.
:::

## Historische Analogien {.nostretch}

```{r}
#| fig-width: 14
#| fig-height: 4
#| echo: false
#| out-width: "100%"
#| fig-align: "center"

# Timeline data
timeline_data <- tibble(
  x = c(1, 2, 3, 4),
  name = c("Taschenrechner", "GPS", "Google", "KI"),
  decade = c("1970er", "1990er", "2000er", "2020er"),
  effect = c("Konzeptuelles\nVerst√§ndnis ‚Üì", "R√§umliches\nGed√§chtnis ‚Üì", "\"Wo\" ersetzt\n\"Was\"", "Alles vorherige\n+ mehr?"),
  highlight = c(FALSE, FALSE, FALSE, TRUE)
)

ggplot(timeline_data) +

  # Timeline line

  geom_segment(aes(x = 0.6, xend = 4.5, y = 0, yend = 0),
               color = "#cccccc", linewidth = 3) +
  # Arrow head

  geom_segment(aes(x = 4.45, xend = 4.55, y = 0.08, yend = 0),
               color = "#cccccc", linewidth = 2) +
  geom_segment(aes(x = 4.45, xend = 4.55, y = -0.08, yend = 0),
               color = "#cccccc", linewidth = 2) +
  # Node circles

  geom_point(aes(x = x, y = 0, color = highlight), size = 16, show.legend = FALSE) +
  geom_point(aes(x = x, y = 0), size = 14, color = "white", show.legend = FALSE) +
  geom_point(aes(x = x, y = 0, color = highlight), size = 12, show.legend = FALSE) +
  scale_color_manual(values = c("FALSE" = "#666666", "TRUE" = color_primary)) +
  # Technology names
  geom_text(aes(x = x, y = -0.25, label = name, color = highlight),
            size = 6, fontface = "bold", show.legend = FALSE) +
  # Decade labels
  geom_text(aes(x = x, y = -0.45, label = decade),
            size = 4.5, color = "#999999") +
  # Effect labels
  geom_text(aes(x = x, y = 0.35, label = effect, color = highlight),
            size = 4, fontface = "italic", lineheight = 0.9, show.legend = FALSE) +
  coord_cartesian(xlim = c(0.4, 4.7), ylim = c(-0.6, 0.55)) +
  theme_void() +
  theme(plot.margin = margin(10, 10, 10, 10))
```

. . .

<br>

::: {style="text-align: center;"}
**Das Muster wiederholt sich. Aber: KI ist breiter als GPS oder Taschenrechner.**

[[@dahmaniHabitualUseGPS2020; @sparrowGoogleEffectsMemory2011]]{style="color: #999; font-size: 0.8em;"}
:::

::: {.notes}
Hier sehen Sie eine Zeitlinie technologischer Entwicklungen und ihrer Auswirkungen auf unsere kognitiven F√§higkeiten.

Die 1970er: Der Taschenrechner. Studien zeigen, dass fr√ºher und intensiver Taschenrechner-Einsatz das konzeptuelle mathematische Verst√§ndnis beeintr√§chtigen kann.

Die 1990er: GPS-Navigation. Habitueller GPS-Gebrauch ist mit schw√§cherem r√§umlichem Ged√§chtnis assoziiert.

Die 2000er: Google. Der "Google-Effekt": Wir erinnern besser, WO Information zu finden ist, als WAS die Information ist.

Die 2020er: KI. Und jetzt? KI kombiniert und verst√§rkt all diese Effekte.

[KLICK] Das Muster wiederholt sich. Aber der Unterschied: KI ist breiter als GPS oder Taschenrechner. Sie betrifft nicht eine kognitive Dom√§ne, sondern potenziell alle.
:::

## Die entscheidende Frage

<br><br>

::: {style="font-size: 1.3em; text-align: center;"}
Dasselbe Werkzeug, unterschiedliche Ergebnisse.
:::

. . .

<br>

::: {style="text-align: center;"}
Taschenrechner helfen Mathematikern, k√∂nnen aber Lernenden schaden.

GPS unterst√ºtzt Taxifahrer, schw√§cht aber das r√§umliche Ged√§chtnis von Neulingen.
:::

. . .

<br><br>

::: {style="font-size: 1.4em; text-align: center; font-weight: bold;"}
Die Frage ist nicht *ob* KI, sondern *wer* davon profitiert.
:::

. . .

<br>

[Die Antwort liegt in dem, was Experten von Lernenden unterscheidet.]{style="color: #666; font-style: italic; display: block; text-align: center;"}

::: {.notes}
Das bringt uns zur entscheidenden Frage.

Dasselbe Werkzeug, unterschiedliche Ergebnisse.

[KLICK] Taschenrechner helfen Mathematikern enorm. Aber f√ºr Lernende, die gerade erst das Rechnen verstehen sollen, k√∂nnen sie sch√§dlich sein.

GPS unterst√ºtzt Taxifahrer bei der Navigation. Aber es schw√§cht nachweislich das r√§umliche Ged√§chtnis von Menschen, die es noch nicht aufgebaut haben.

[KLICK] Die Frage ist also nicht, OB KI n√ºtzt oder schadet. Die Frage ist: WER profitiert und wer nicht?

[KLICK] Die Antwort liegt in dem, was Experten von Lernenden unterscheidet.
:::

## Was Experten sehen

<br>

::: {.columns}
::: {.column width="50%"}

![](../../assets/images/chess.png){width="90%"}

:::

::: {.column width="50%"}

<br>

**Novize:** sieht Einzelteile

"64 Felder, 32 Figuren, viele M√∂glichkeiten"

. . .

**Experte:** sieht Muster und Bedeutung

"Sizilianische Verteidigung, K√∂nigsangriff m√∂glich, Schw√§che auf f7"

. . .

<br>

Experten speichern Wissen in **Chunks**: vernetzte Wissensstrukturen, die automatisch abgerufen werden [@grootThoughtChoiceChess1978; @chasePerceptionChess1973].

:::
:::

::: {.notes}
Schauen wir uns an, was Experten von Novizen unterscheidet. Das klassische Beispiel kommt aus der Schachforschung.

Was sieht ein Novize? 64 Felder, 32 Figuren, viele M√∂glichkeiten. Er sieht die Einzelteile.

[KLICK] Was sieht ein Experte? "Sizilianische Verteidigung, K√∂nigsangriff m√∂glich, Schw√§che auf f7." Er sieht Muster und Bedeutung.

[KLICK] Das ist der fundamentale Unterschied. Experten speichern Wissen in sogenannten "Chunks": vernetzte Wissensstrukturen, die automatisch abgerufen werden.

Ein Schachmeister hat etwa 50.000 solcher Chunks im Langzeitged√§chtnis. Die Forschung dazu geht auf de Groot zur√ºck und wurde von Chase und Simon quantifiziert.
:::

## Der Expertise-Umkehr-Effekt

::: {style="background-color: #f5f5f5; padding: 0.6em 1em; border-radius: 6px; font-size: 0.9em; margin-bottom: 0.5em;"}
{{< fa hand-pointer >}} **Interaktiv:** Klicke auf die Prozentwerte, um zu sehen, wie sich die optimale Lehrmethode je nach Vorwissen ver√§ndert.
:::

```{ojs}
//| echo: false

// =============================================================================
// Configuration: All parameters in one place for easy maintenance
// =============================================================================
config = ({
  // Color palette
  colors: {
    highSupport: "#A3195B",
    lowSupport: "#666666",
    neutral: "#333",
    background: "#f5f5f5"
  },
  // Line equations: y = intercept + slope * x
  // Lines cross where: highIntercept + highSlope*x = lowIntercept + lowSlope*x
  lines: {
    high: { intercept: 65, slope: -0.4 },
    low: { intercept: 25, slope: 0.4 }
  },
  // Input options
  steps: [0, 20, 40, 60, 80, 100],
  defaultValue: 20,
  // Plot dimensions
  plot: {
    width: 900,
    height: 480,
    margins: { left: 70, bottom: 60, top: 30, right: 40 }
  },
  // Labels
  labels: {
    highSupport: "Hohe Unterst√ºtzung",
    lowSupport: "Niedrige Unterst√ºtzung",
    highExamples: ["üìñ Worked Examples", "üß≠ Direkte Instruktion"],
    lowExamples: ["üß© Problembasiertes Lernen", "üîç Eigene L√∂sungswege"]
  }
})

// =============================================================================
// Derived values: Computed from config (no magic numbers)
// =============================================================================

// Crossover point: solve for x where both lines intersect
crossoverPoint = {
  const { high, low } = config.lines;
  return (high.intercept - low.intercept) / (low.slope - high.slope);
}

// Helper function to calculate y-value on a line
calcY = (line, x) => line.intercept + line.slope * x

// =============================================================================
// State: Single source of truth for user input (hidden, controlled by buttons)
// =============================================================================
viewof vorwissen = {
  const input = Inputs.radio(config.steps, {
    value: config.defaultValue,
    label: "",
    format: x => x + "%"
  });
  input.style.display = "none";
  return input;
}

// =============================================================================
// Reactive calculations based on current state
// =============================================================================
currentState = {
  const x = vorwissen ?? config.defaultValue;
  const highY = calcY(config.lines.high, x);
  const lowY = calcY(config.lines.low, x);
  const isHighBetter = x <= crossoverPoint;

  return {
    x,
    highY,
    lowY,
    isHighBetter,
    optimalY: isHighBetter ? highY : lowY,
    suboptimalY: isHighBetter ? lowY : highY,
    optimalLabel: isHighBetter ? config.labels.highSupport : config.labels.lowSupport,
    optimalColor: isHighBetter ? config.colors.highSupport : config.colors.lowSupport,
    suboptimalColor: isHighBetter ? config.colors.lowSupport : config.colors.highSupport
  };
}

// =============================================================================
// Plot: Visualization with all marks
// =============================================================================
expertisePlot = {
  const { colors, lines, plot, labels } = config;
  const { x, highY, lowY, isHighBetter, optimalY, suboptimalY, optimalColor, suboptimalColor } = currentState;

  // Generate line data points
  const highLineData = [{x: 0, y: calcY(lines.high, 0)}, {x: 100, y: calcY(lines.high, 100)}];
  const lowLineData = [{x: 0, y: calcY(lines.low, 0)}, {x: 100, y: calcY(lines.low, 100)}];

  // Label positions (relative to line endpoints)
  const labelOffsetY = 7;
  const exampleBaseY = calcY(lines.high, 0) + labelOffsetY;

  return Plot.plot({
    width: plot.width,
    height: plot.height,
    marginLeft: plot.margins.left,
    marginBottom: plot.margins.bottom,
    marginTop: plot.margins.top,
    marginRight: plot.margins.right,
    style: { fontSize: "16px" },
    x: {
      domain: [0, 100],
      label: "Vorwissen ‚Üí",
      labelOffset: 45,
      ticks: [0, 50, 100],
      tickFormat: d => d === 0 ? "Niedrig" : d === 50 ? "Mittel" : "Hoch"
    },
    y: {
      domain: [0, 100],
      label: "‚Üë Lerneffekt",
      labelOffset: 50,
      grid: true
    },
    marks: [
      // Support lines
      Plot.line(highLineData, {x: "x", y: "y", stroke: colors.highSupport, strokeWidth: 3}),
      Plot.line(lowLineData, {x: "x", y: "y", stroke: colors.lowSupport, strokeWidth: 3}),

      // Vertical position indicator
      Plot.ruleX([x], {stroke: colors.neutral, strokeWidth: 1.5, strokeDasharray: "8,5"}),

      // Suboptimal dot (smaller, faded)
      Plot.dot([{x, y: suboptimalY}], {
        x: "x", y: "y",
        fill: suboptimalColor,
        r: 8,
        opacity: 0.4
      }),

      // Optimal dot (larger, prominent with white stroke)
      Plot.dot([{x, y: optimalY}], {
        x: "x", y: "y",
        fill: optimalColor,
        r: 14,
        stroke: "white",
        strokeWidth: 3
      }),

      // High support examples (left side, near line start)
      Plot.text([{x: 15, y: exampleBaseY}], {
        x: "x", y: "y", text: [labels.highExamples[0]], fill: colors.highSupport, fontSize: 13
      }),
      Plot.text([{x: 15, y: exampleBaseY - 6}], {
        x: "x", y: "y", text: [labels.highExamples[1]], fill: colors.highSupport, fontSize: 13
      }),

      // Low support examples (right side)
      Plot.text([{x: 85, y: exampleBaseY}], {
        x: "x", y: "y", text: [labels.lowExamples[0]], fill: colors.lowSupport, fontSize: 13
      }),
      Plot.text([{x: 85, y: exampleBaseY - 6}], {
        x: "x", y: "y", text: [labels.lowExamples[1]], fill: colors.lowSupport, fontSize: 13
      }),

      // Line labels (near line ends)
      Plot.text([{x: 88, y: calcY(lines.high, 100) - 5}], {
        x: "x", y: "y", text: [labels.highSupport], fill: colors.highSupport, fontSize: 15, fontWeight: "bold"
      }),
      Plot.text([{x: 12, y: calcY(lines.low, 0) - 5}], {
        x: "x", y: "y", text: [labels.lowSupport], fill: colors.lowSupport, fontSize: 15, fontWeight: "bold"
      })
    ]
  });
}

// =============================================================================
// Button Group: Custom styled segmented control
// =============================================================================
buttonGroup = {
  const { x, optimalColor } = currentState;
  const { colors, steps } = config;

  const buttonStyle = (isSelected, selectColor) => `
    padding: 12px 18px;
    border: none;
    background: ${isSelected ? selectColor : colors.background};
    color: ${isSelected ? 'white' : '#333'};
    font-size: 1em;
    font-weight: ${isSelected ? 'bold' : 'normal'};
    cursor: pointer;
    border-right: 1px solid #ddd;
    transition: background 0.15s ease;
  `;

  const container = html`<div style="display: flex; border-radius: 8px; overflow: hidden; border: 2px solid #ddd;"></div>`;

  steps.forEach(v => {
    const isSelected = x === v;
    const selectColor = v <= crossoverPoint ? colors.highSupport : colors.lowSupport;
    const btn = html`<button style="${buttonStyle(isSelected, selectColor)}">${v}%</button>`;
    btn.onclick = () => {
      viewof vorwissen.value = v;
      viewof vorwissen.dispatchEvent(new Event('input', {bubbles: true}));
    };
    container.appendChild(btn);
  });

  return container;
}

// =============================================================================
// Layout: Compose all elements
// =============================================================================
html`<div style="display: flex; align-items: center; gap: 40px;">
  <div>${expertisePlot}</div>
  <div style="display: flex; flex-direction: column; align-items: center; gap: 20px; min-width: 280px;">
    <div style="font-weight: bold; font-size: 1.1em;">Vorwissen des Lernenden</div>
    <div>${buttonGroup}</div>
    <div style="font-size: 1.3em; text-align: center; padding: 15px; background: ${currentState.optimalColor}22; border-radius: 8px; border-left: 4px solid ${currentState.optimalColor};">
      <span style="color: ${currentState.optimalColor}; font-weight: bold;">${currentState.optimalLabel}</span><br>
      <span style="font-size: 0.8em; color: #666;">ist effektiver</span>
    </div>
  </div>
</div>`
```

<br>
<br>

Der Expertise-Umkehr-Effekt [@kalyugaExpertiseReversalEffect2009].

::: {.notes}
Das bringt uns zu einem der wichtigsten Befunde der Instruktionsforschung: dem Expertise-Umkehr-Effekt.

Sie k√∂nnen die Prozent-Buttons anklicken, um zu sehen, wie sich die optimale Lehrmethode ver√§ndert.

Auf der x-Achse sehen Sie das Vorwissen des Lernenden. Auf der y-Achse den Lerneffekt.

Die magentafarbene Linie zeigt hohe Unterst√ºtzung: ausgearbeitete Beispiele, direkte Instruktion. Die graue Linie zeigt niedrige Unterst√ºtzung: problembasiertes Lernen, eigene L√∂sungswege.

Bei niedrigem Vorwissen ist hohe Unterst√ºtzung klar besser. Novizen brauchen Struktur.

Aber bei hohem Vorwissen kehrt sich der Effekt um. F√ºr Experten ist niedrige Unterst√ºtzung besser. Die detaillierten Anleitungen werden redundant und st√∂ren sogar.

Das ist der Expertise-Umkehr-Effekt: Was f√ºr Novizen optimal ist, ist f√ºr Experten suboptimal. Und umgekehrt.
:::

## Warum Experten profitieren, Lernende nicht

<br>

::: {.columns}
::: {.column width="50%"}

**Experten:**

<br>

- {{< fa cogs >}} K√∂nnen Routine auslagern
- {{< fa magnifying-glass >}} K√∂nnen KI-Output bewerten
- {{< fa lightbulb >}} Mehr Kapazit√§t f√ºr Komplexes

:::

::: {.column width="50%"}

**Lernende:**

<br>

- {{< fa eye-slash >}} K√∂nnen nicht bewerten
- {{< fa forward-fast >}} √úberspringen Grundlagen
- {{< fa mask >}} Risiko: "Fliessende Inkompetenz"

:::
:::

. . .

<br>

**Dasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.**

::: {.notes}
Jetzt k√∂nnen wir zusammenfassen, warum Experten und Lernende so unterschiedlich von KI-Werkzeugen betroffen sind.

[KLICK] Experten k√∂nnen Routine auslagern. Sie k√∂nnen KI-Output bewerten. Und sie haben mehr Kapazit√§t f√ºr Komplexes.

[KLICK] Lernende hingegen k√∂nnen KI-Output nicht bewerten. Sie √ºberspringen m√∂glicherweise Grundlagen. Und das Risiko ist "fliessende Inkompetenz": Sie k√∂nnen mit Hilfe alles, ohne Hilfe nichts.

[KLICK] Das Fazit: Dasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.
:::

## Kritisches Denken braucht Fachwissen

<br>

> "Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context."
>
> Daniel Willingham [@willinghamCriticalThinkingWhy2008]

. . .

<br>

::: {.columns}
::: {.column width="50%"}

**Biomedizin-Experte:**

Erkennt, wenn ChatGPT bei Biochemie falsch liegt

:::

::: {.column width="50%"}

**Novize:**

Kann diese Bewertung nicht vornehmen

:::
:::

. . .

<br>

**Du kannst nicht kritisch bewerten, was du nicht verstehst.**

. . .

<br>

[Warum ist Fachwissen so entscheidend? Weil es bestimmt, ob KI deine Kognition erweitert oder ersetzt.]{style="color: #666; font-style: italic;"}

::: {.notes}
An diesem Punkt h√∂re ich oft einen Einwand: "Dann bringen wir den Studierenden eben bei, KI-Output kritisch zu pr√ºfen."

Aber hier kommt ein wichtiger Punkt von Daniel Willingham: Kritisches Denken ist keine kontextfreie F√§higkeit. Man kann nicht einfach "kritisch denken lernen" und es dann √ºberall anwenden.

[KLICK] Ein Biomedizin-Experte erkennt, wenn ChatGPT bei Biochemie falsch liegt. Ein Novize kann diese Bewertung nicht vornehmen.

[KLICK] Die Kernaussage: Du kannst nicht kritisch bewerten, was du nicht verstehst.

[KLICK] Und genau deshalb ist Fachwissen so entscheidend.
:::

## Kognition erweitern vs. ersetzen

<br>

::: {.columns}
::: {.column width="50%"}

**{{< fa expand >}} Kognition erweitern:**

<br>

- Mensch bleibt kognitiv engagiert
- Werkzeug verst√§rkt, ersetzt nicht
- F√§higkeiten bleiben erhalten

:::

::: {.column width="50%"}

**{{< fa compress >}} Kognition ersetzen:**

<br>

- Mensch wird passiv
- Werkzeug √ºbernimmt das Denken
- Abh√§ngigkeit entsteht

:::
:::

. . .

<br>

**Dasselbe Werkzeug kann beides sein, abh√§ngig von der Nutzung** [@clarkExtendingMindsGenerative2025].

::: {.notes}
Andy Clark, ein Philosoph, hat eine n√ºtzliche Unterscheidung eingef√ºhrt.

[KLICK] Kognition erweitern: Der Mensch bleibt kognitiv engagiert. Das Werkzeug verst√§rkt, ersetzt nicht. Die F√§higkeiten bleiben erhalten.

[KLICK] Kognition ersetzen: Der Mensch wird passiv. Das Werkzeug √ºbernimmt das Denken. Es entsteht Abh√§ngigkeit.

[KLICK] Und hier ist der wichtige Punkt: Dasselbe Werkzeug kann beides sein, abh√§ngig von der Nutzung.

ChatGPT kann ein Brainstorming-Partner sein, der die eigene Kreativit√§t verst√§rkt. Oder es kann ein Ghostwriter sein, der das Denken ersetzt. Die Frage ist nicht das Werkzeug. Die Frage ist die Nutzung.
:::

## Die Sequenzierungsfrage

<br>

::: {style="text-align: center; font-size: 1.3em; margin-bottom: 40px;"}
[Novize]{style="color: #A3195B; font-weight: bold;"}
‚Äî‚Äî‚Äî [**Schwelle?**]{style="background: #D4A03E; padding: 5px 15px; border-radius: 4px;"} ‚Äî‚Äî‚Äî
[Experte]{style="color: #24526B; font-weight: bold;"}
:::

::: {.incremental}
- Die Schwelle ist **unbekannt** und empirisch nicht bestimmt
- Sie variiert nach **Dom√§ne** und **Person**
- Der Expertise-Umkehr-Effekt erfordert **dynamische** KI-Nutzungsempfehlungen
:::

. . .

<br>

::: {style="text-align: center; font-size: 1.2em;"}
**Wer profitiert von KI-Werkzeugen? Wer nicht?**
:::

::: {.notes}
Das bringt uns zur praktischen Frage: Wenn Experten profitieren und Lernende Gefahr laufen, wann ist der √úbergang?

Links der Novize, rechts der Experte. Irgendwo dazwischen liegt eine Schwelle.

[KLICK] Das Problem ist: Diese Schwelle ist unbekannt.

[KLICK] Sie variiert nach Dom√§ne und Person.

[KLICK] Der Expertise-Umkehr-Effekt erfordert dynamische Empfehlungen.

[KLICK] Die praktische Frage: Wer profitiert von KI-Werkzeugen? Und wer nicht? Diese Frage k√∂nnen wir nicht pauschal beantworten.
:::

## Die Kernaussage

. . .

::: {style="font-size: 2em; text-align: center; margin-top: 1.5em; font-weight: 700; color: #24526B;"}
KI-Werkzeuge sind f√ºr Experten gemacht.
:::

. . .

::: {style="display: flex; justify-content: center; gap: 3em; margin-top: 2em; margin-bottom: 2em;"}
::: {style="text-align: center; padding: 1em 1.5em; border-left: 4px solid #D4A03E;"}
[Sie machen Experten produktiver.]{style="font-size: 1.1em; color: #24526B;"}
:::

::: {style="text-align: center; padding: 1em 1.5em; border-left: 4px solid #A3195B;"}
[Lernende profitieren oft nicht, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.]{style="font-size: 1.1em; color: #A3195B;"}
:::
:::

. . .

::: {style="text-align: center; margin-top: 2em; padding: 1em 2em; border: 2px solid #A3195B; border-radius: 8px;"}
[**Lernende brauchen erst das Fundament, das kritische KI-Nutzung erm√∂glicht.**]{style="font-size: 1.4em; color: #A3195B;"}
:::

::: {.notes}
[Pause, dann KLICK] KI-Werkzeuge sind f√ºr Experten gemacht.

[KLICK] Das ist keine Wertung, sondern eine Feststellung. Diese Werkzeuge wurden von Experten entwickelt und funktionieren am besten f√ºr Menschen, die bereits wissen, was sie tun.

Sie machen Experten produktiver.

[KLICK] Aber: Lernende profitieren oft nicht. Lernen erfordert genau die kognitive Anstrengung, die KI zu eliminieren droht.

Das ist nicht KI-Feindlichkeit. Lernen braucht Anstrengung. KI kann diese Anstrengung reduzieren, wenn sie passiv genutzt wird. Aber: Es ist nicht unvermeidlich. Erinnern Sie sich an den GPT-Tutor? Die Art der Nutzung entscheidet.

[KLICK] Die Konsequenz: Lernende brauchen erst das Fundament, das kritische KI-Nutzung erm√∂glicht. Nicht "keine KI", aber "Fundament zuerst".
:::

## Was bedeutet das f√ºr die Lehre?

<br>

::: {.columns}
::: {.column width="33%"}

{{< fa dumbbell size=3x >}}

<br>

**Anstrengung ist das Signal**

:::

::: {.column width="33%"}

{{< fa comments size=3x >}}

<br>

**KI als Tutor, nicht als Antwortgeber**

:::

::: {.column width="33%"}

{{< fa stairs size=3x >}}

<br>

**Expertise bestimmt den Nutzen**

:::
:::

. . .

::: {.columns}
::: {.column width="33%"}

[Wenn Lernen sich zu leicht anf√ºhlt, findet es wahrscheinlich nicht statt.]{style="color: #666;"}

:::

::: {.column width="33%"}

[KI soll Denkprozesse anregen, nicht ersetzen.]{style="color: #666;"}

:::

::: {.column width="33%"}

[Dasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.]{style="color: #666;"}

:::
:::

. . .

<br>

**Grundlagen BEVOR Werkzeuge**

::: {.notes}
Zum Abschluss: Was bedeutet das konkret f√ºr unsere Lehre?

[KLICK] Erstens: Anstrengung ist das Signal. Wenn Lernen sich zu leicht anf√ºhlt, findet es wahrscheinlich nicht statt.

[KLICK] Zweitens: KI als Tutor, nicht als Antwortgeber. KI soll Denkprozesse anregen, nicht ersetzen.

[KLICK] Drittens: Expertise bestimmt den Nutzen. Dasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.

[KLICK] Und die Zusammenfassung: Grundlagen BEVOR Werkzeuge.

Erst das Fundament, dann die Erweiterung. Erst verstehen, dann automatisieren. Erst selbst k√∂nnen, dann delegieren.

Vielen Dank.
:::

## Referenzen

::: {#refs}
:::
