---
title: "Speaker Notes: KI in der Hochschulbildung (Kurzversion)"
subtitle: "Werkzeuge f√ºr Experten, Herausforderungen f√ºr Lernende"
author: "Andrew Ellis"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
bibliography: ../bibliography.bib
---

üëÜ = Klick auf Folie | ‚≠ê = Kernaussage | üéì = Kurs-Hinweis

# Einleitung (vor den Folien)

**Sprechtext:**

Willkommen. Bevor wir beginnen, m√∂chte ich kurz erkl√§ren, warum ich diesen Vortrag so aufgebaut habe, wie er ist.

Wenn wir √ºber KI in der Bildung sprechen, h√∂ren wir meist zwei Narrative: Entweder "KI revolutioniert das Lernen" oder "KI zerst√∂rt die Bildung". Beide sind zu einfach.

Was wir brauchen, ist ein **Rahmen**, um zu verstehen, wann KI hilft und wann sie schadet. Und diesen Rahmen liefert uns die Kognitionspsychologie. Nicht weil sie alle Antworten hat, sondern weil sie uns die richtigen Fragen stellt.

Die Kognitionspsychologie untersucht seit Jahrzehnten, wie Menschen lernen, wie Expertise entsteht, und was passiert, wenn Werkzeuge kognitive Arbeit √ºbernehmen. Diese Erkenntnisse sind direkt anwendbar auf die KI-Frage.

Ich beginne mit einer konkreten Studie, weil sie das Paradox illustriert, das uns heute besch√§ftigt: Studierende k√∂nnen mit KI mehr leisten, aber weniger lernen. Dieses Auseinanderfallen von Leistung und Lernen ist der Kern des Problems.

Dann gehen wir einen Schritt zur√ºck und fragen: Warum passiert das? Die Antwort liegt in der Architektur des menschlichen Ged√§chtnisses und in dem, was Experten von Lernenden unterscheidet.

Am Ende werden Sie einen Rahmen haben, um KI-Nutzung in Ihrer Lehre differenziert zu beurteilen. Nicht "KI ja oder nein", sondern "f√ºr wen, wann, und wie".

::: {.callout-note}
## Warum dieser Aufbau?

**Die Struktur des Vortrags:**

1. **Empirischer Einstieg** (Bastani-Studie): Konkret und √ºberraschend, weckt Interesse
2. **Theoretischer Rahmen** (Kognitionspsychologie): Erkl√§rt das "Warum"
3. **Differenzierung** (Experten vs. Novizen): Macht handlungsf√§hig
4. **Praktische Implikationen**: Gibt Orientierung

**Warum Kognitionspsychologie?**

Die Debatte um KI in der Bildung wird oft gef√ºhrt ohne Bezug auf das, was wir √ºber Lernen wissen. Dabei haben wir Jahrzehnte an Forschung zu:

- Wie Wissen im Ged√§chtnis gespeichert wird
- Warum Anstrengung f√ºr Lernen notwendig ist
- Wie Expertise sich von Novizentum unterscheidet
- Was passiert, wenn Werkzeuge kognitive Arbeit √ºbernehmen

Diese Erkenntnisse sind nicht neu, aber sie werden in der KI-Diskussion oft ignoriert. Der Vortrag macht sie anwendbar.

**Warum mit einer Studie beginnen?**

Die Bastani-Studie ist nicht perfekt (keine Studie ist das), aber sie ist:

- Methodisch rigoros (RCT mit grosser Stichprobe)
- √úberraschend (widerspricht der Intuition)
- Konkret (nicht theoretisch, sondern empirisch)
- Aktuell (2025, GPT-4)

Sie dient als Aufh√§nger, nicht als Beweis. Der eigentliche Beweis kommt aus der Theorie.
:::

---

# Ein √ºberraschendes Ergebnis

**Sprechtext:**

Schauen wir uns also diese Studie an, die das Paradox illustriert.

In einer gross angelegten Studie mit etwa 1000 Gymnasiasten in der T√ºrkei erhielten Sch√ºler Zugang zu GPT-4 w√§hrend ihrer Mathematik-√úbungen.

üëÜ

Die Ergebnisse w√§hrend der √úbungsphase waren beeindruckend: Die Sch√ºler mit KI-Zugang l√∂sten **48 Prozent mehr Aufgaben** korrekt.

üëÜ

Klingt nach einem Erfolg, oder? Aber dann kam der Test. Und zwar ohne KI-Zugang.

üëÜ

Die Gruppe, die zuvor mit KI ge√ºbt hatte, schnitt **17 Prozent schlechter** ab als die Kontrollgruppe, die nie KI-Zugang hatte.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Kernaussage
Mehr Aufgaben gel√∂st bedeutet nicht automatisch mehr gelernt.
:::

::: {.callout-note}
## Hintergrund zur Bastani-Studie

Die Studie von Bastani et al. (2025) "Generative AI Can Harm Learning" ist eine der ersten rigorosen randomisierten kontrollierten Studien zu KI im Bildungskontext. Die Autoren sind von der Harvard Business School und MIT.

**Wichtige Details:**

- Ca. 1000 t√ºrkische Gymnasiasten, 9. Klasse
- Fach: Mathematik
- Intervention: GPT-4 Zugang w√§hrend √úbungsphasen
- Der 17%-Nachteil betraf den direkten GPT-4-Zugang

**Praktische Einordnung der Effektst√§rke:**

Der 17%-Nachteil klingt dramatisch, sollte aber eingeordnet werden. In der Studie entspricht dies etwa 0.2-0.3 Standardabweichungen, ein kleiner bis mittlerer Effekt. Zum Vergleich: Der Unterschied zwischen einem Sch√ºler auf dem 50. und dem 40. Perzentil. Relevant, aber kein Totalausfall.

**Der GPT-Tutor-Befund (oft √ºbersehen):**

Die Studie testete auch einen "GPT Tutor" mit p√§dagogischen Leitplanken: Das System gab keine direkten Antworten, sondern Hinweise und Fragen. Diese Bedingung zeigte deutlich bessere Ergebnisse als der direkte GPT-4-Zugang. Das ist ein zentraler Befund: Das Problem ist nicht KI an sich, sondern wie KI eingesetzt wird. Ein gut designtes KI-Tutoring-System kann die negativen Effekte abmildern oder vermeiden.

**Einschr√§nkungen:**

- Spezifischer Kontext (T√ºrkei, Mathematik, Gymnasium)
- Kurzfristige Messung (Wochen, nicht Semester)
- Replikationen stehen aus
- Generalisierung auf Schweizer Hochschulstudierende in anderen F√§chern erfordert Vorsicht

**Dennoch wichtig:** Die Kernaussage, dass Aufgabenleistung und Lernen auseinanderfallen k√∂nnen, ist theoretisch gut fundiert und deckt sich mit der Cognitive Load Theory. Und der GPT-Tutor-Befund zeigt einen Weg nach vorne.
:::

---

# Das Paradox

**Sprechtext:**

Hier sehen wir das Paradox visualisiert.

Die magentafarbene Linie zeigt die Gruppe mit KI-Zugang, die graue die Kontrollgruppe ohne KI.

In der √úbungsphase links performt die KI-Gruppe deutlich besser. Das macht Sinn: Sie hatten ja Hilfe. Der Unterschied ist klar, die Fehlerbalken √ºberlappen nicht.

Aber schauen Sie, was beim Test passiert, bei dem beide Gruppen ohne KI arbeiten mussten. Die KI-Gruppe schneidet tendenziell schlechter ab, aber beachten Sie die Fehlerbalken: Sie √ºberlappen sich. Der Unterschied ist statistisch nicht so dramatisch, wie die Linien allein suggerieren w√ºrden.

Das ist wichtig f√ºr die ehrliche Interpretation: Der Vorteil w√§hrend der √úbung ist verschwunden, und es gibt Hinweise auf einen Nachteil, aber wir sollten die Unsicherheit nicht ignorieren.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Kernaussage
**Aufgabenleistung ist nicht dasselbe wie Lernen.**
:::

Wir verwechseln oft Performanz mit Kompetenz. Wenn Studierende mit KI-Hilfe eine Aufgabe l√∂sen, sehen wir die Performanz des Systems, nicht unbedingt das Lernen des Studierenden. Und selbst wenn der Nachteil in dieser einen Studie nicht riesig war: Der erwartete Lernvorteil blieb aus.

::: {.callout-note}
## Hintergrund: Performance vs. Learning

Diese Unterscheidung geht auf Robert Bjork zur√ºck, einen f√ºhrenden Ged√§chtnisforscher. Er unterscheidet:

- **Performance**: Momentane Leistung unter bestimmten Bedingungen
- **Learning**: Dauerhafte Ver√§nderung im Langzeitged√§chtnis

Die beiden k√∂nnen dissoziieren. Hohe Performance w√§hrend des √úbens (mit Hilfe) kann mit niedrigem Learning einhergehen. Umgekehrt kann niedrige Performance w√§hrend des √úbens (ohne Hilfe, mit Anstrengung) zu hohem Learning f√ºhren.

Das ist keine neue Erkenntnis. Jeder Sporttrainer weiss, dass Training h√§rter sein muss als der Wettkampf. Was neu ist: KI macht es extrem einfach, Performance ohne Learning zu erreichen.
:::

---

# Das Nadel√∂hr des Lernens

**Sprechtext:**

Um zu verstehen, warum das passiert, m√ºssen wir einen kurzen Ausflug in die Kognitionspsychologie machen.

Hier sehen Sie ein vereinfachtes Modell des menschlichen Ged√§chtnisses. Links die neue Information, rechts das Langzeitged√§chtnis, und in der Mitte: das Nadel√∂hr.

Das Arbeitsged√§chtnis hat eine stark begrenzte Kapazit√§t. Die aktuelle Forschung spricht von etwa 4 plus/minus 1 Elementen, die wir gleichzeitig aktiv verarbeiten k√∂nnen.

Neue Information links ist unbegrenzt. Das Langzeitged√§chtnis rechts ist praktisch unbegrenzt. Aber alles, was von links nach rechts wandern soll, muss durch dieses enge Nadel√∂hr.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Kernaussage
**Alles Lernen muss durch das Nadel√∂hr des Arbeitsged√§chtnisses.**

Es gibt keinen Weg drumherum. Keine Abk√ºrzung. Keine KI kann diesen biologischen Engpass umgehen.
:::

::: {.callout-note}
## Hintergrund: Cognitive Load Theory

Die Cognitive Load Theory wurde von John Sweller in den 1980er Jahren entwickelt und ist heute eine der einflussreichsten Theorien im Instruktionsdesign.

**Die drei Arten von Cognitive Load:**

1. **Intrinsic Load**: Inherente Komplexit√§t des Materials (nicht reduzierbar ohne Vereinfachung)
2. **Extraneous Load**: Unn√∂tige kognitive Belastung durch schlechtes Design (zu minimieren)
3. **Germane Load**: Produktive Anstrengung, die zum Lernen f√ºhrt (zu optimieren)

**Warum das f√ºr KI relevant ist:**

Wenn KI die kognitive Arbeit √ºbernimmt, reduziert sie potenziell den Germane Load. Das ist gut f√ºr Experten (weniger Routinearbeit), aber schlecht f√ºr Lernende (weniger Lernarbeit).

Die Kapazit√§t von "4¬±1" stammt aus Cowan's (2001) Revision von Millers klassischer "7¬±2" Regel. Moderne Forschung zeigt, dass die echte Kapazit√§t ohne Chunking-Strategien n√§her bei 4 liegt.
:::

---

# Erw√ºnschte Schwierigkeiten

**Sprechtext:**

Das bringt uns zu einem kontraintuitiven Konzept: den erw√ºnschten Schwierigkeiten, oder auf Englisch "Desirable Difficulties".

Hier ein Zitat von Robert Bjork, der dieses Konzept gepr√§gt hat:

> "Conditions that slow the rate of apparent learning often optimize long-term retention and transfer."

√úbersetzt: Bedingungen, die das scheinbare Lernen verlangsamen, optimieren oft das langfristige Behalten und den Transfer.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Merksatz
**Schwerer f√ºhlt sich schlechter an, ist aber besser f√ºr langfristiges Lernen.**
:::

Das ist ein fundamentales Prinzip, das wir immer wieder vergessen. Wenn Lernen sich leicht anf√ºhlt, lernen wir wahrscheinlich weniger, als wenn es sich anstrengend anf√ºhlt.

::: {.callout-note}
## Hintergrund: Desirable Difficulties

Robert Bjork pr√§gte diesen Begriff in den 1990er Jahren. Die Forschung zeigt konsistent, dass bestimmte "Schwierigkeiten" das Lernen verbessern:

**Warum wirken Desirable Difficulties?**

1. Sie erzwingen tiefere Verarbeitung
2. Sie aktivieren Abrufprozesse, die das Ged√§chtnis st√§rken
3. Sie verhindern "Fluency Illusions" (wir √ºbersch√§tzen unser Wissen, wenn etwas leicht erscheint)

**Wichtige Einschr√§nkung:**

Nicht alle Schwierigkeiten sind erw√ºnscht. Die Schwierigkeit muss produktiv sein, also tats√§chlich zu Lernprozessen f√ºhren. Frustrierende, verwirrende oder irrelevante Schwierigkeiten sind nicht erw√ºnscht.

Die Kunst liegt darin, den "Sweet Spot" zu finden: herausfordernd genug, um Lernen zu erzwingen, aber nicht so schwer, dass Lernende aufgeben.
:::

---

# Die vier Strategien

**Sprechtext:**

Bjork hat vier konkrete Strategien identifiziert, die als erw√ºnschte Schwierigkeiten fungieren:

üëÜ f√ºr jede Strategie

1. ‚úèÔ∏è **Selbst generieren.** Eigene Antworten formulieren, statt vorgegebene zu lesen.
2. üìÖ **Verteilt lernen.** Zeitliche Abst√§nde einbauen. 4x1h > 1x4h.
3. üß† **Aktiv abrufen.** Wissen aus dem Ged√§chtnis holen, statt nachzuschlagen.
4. üîÄ **Variieren.** Themen und Aufgabentypen mischen.

üëÜ

::: {.callout-important appearance="simple"}
## ‚ö†Ô∏è Kritischer Punkt
**KI kann jede dieser Strategien untergraben**, wenn sie die kognitive Arbeit √ºbernimmt.

Warum selbst generieren, wenn KI es besser kann? Warum sich anstrengen, wenn die Antwort einen Klick entfernt ist?
:::

::: {.callout-tip appearance="simple"}
## üéì Kurs-Hinweis
Wie man KI-Anwendungen so gestaltet, dass sie diese Strategien **unterst√ºtzen** statt untergraben: **Intermediate-Kurs**
:::

::: {.callout-note}
## Hintergrund: Die vier Strategien im Detail

**1. Generation Effect (Selbst generieren)**
- Erste Studien: Slamecka & Graf (1978)
- Material, das selbst produziert wird, wird besser behalten als gelesenes
- Gilt f√ºr W√∂rter, S√§tze, Konzepte, Probleml√∂sungen

**2. Spacing Effect (Verteiltes Lernen)**
- Einer der robustesten Befunde der Lernpsychologie
- Optimaler Abstand: Ebbinghaus (1885), Cepeda et al. (2006)
- Gilt √ºber Minuten, Tage, Wochen, Monate

**3. Testing Effect / Retrieval Practice (Aktiver Abruf)**
- Roediger & Karpicke (2006): Testen ist besser als erneutes Studieren
- Jeder erfolgreiche Abruf st√§rkt die Ged√§chtnisspur
- Auch erfolglose Abrufversuche (mit Feedback) sind wirksam

**4. Interleaving (Variieren)**
- Rohrer & Taylor (2007): Gemischtes √úben schl√§gt geblocktes √úben
- Erh√∂ht die Diskriminationsf√§higkeit
- F√ºhlt sich w√§hrend des √úbens schwieriger an, f√ºhrt aber zu besserem Transfer

**KI und diese Strategien:**

- Generation: KI generiert f√ºr uns
- Spacing: KI liefert instant Antworten, kein Warten
- Retrieval: KI macht Abruf unn√∂tig
- Interleaving: KI l√∂st jede Aufgabe einzeln, ohne Variation zu erzwingen
:::

---

# Der Generierungseffekt

**Sprechtext:**

Schauen wir uns den Generierungseffekt genauer an, weil er besonders relevant f√ºr KI ist.

Die Grafik zeigt die Behaltensleistung in Prozent. Selbst generierte Information wird am besten behalten, etwa 70 Prozent. Gelesene Information liegt bei etwa 50 Prozent. Und von KI erhaltene Information? Noch niedriger, hier spekulativ bei etwa 35 Prozent dargestellt.

Die Forschung zum Generierungseffekt stammt aus den 1970er Jahren. Slamecka und Graf zeigten, dass selbst produziertes Material besser behalten wird als passiv aufgenommenes.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Implikation
**Wenn KI generiert, was Studierende selbst produzieren sollten, entf√§llt der Lerneffekt.**
:::

üëÜ

Aber dieser Effekt ist nicht neu. Immer wenn Technologie kognitive Arbeit √ºbernimmt, sehen wir √§hnliche Muster. Das bringt uns zu den historischen Analogien.

::: {.callout-note}
## Hintergrund: Der Generierungseffekt

**Urspr√ºngliche Studie:**
Slamecka & Graf (1978) zeigten, dass Teilnehmer W√∂rter besser erinnerten, wenn sie diese aus einem Hinweis generieren mussten (z.B. "schnell - s____" f√ºr "schnell - schnee"), als wenn sie beide W√∂rter nur lasen.

**Warum funktioniert es?**

1. Tiefere Verarbeitung w√§hrend der Generierung
2. Verkn√ºpfung mit bestehendem Wissen
3. St√§rkere Ged√§chtnisrepr√§sentation

**Grenzen:**

- Effekt ist st√§rker f√ºr semantisch bedeutsames Material
- Generierung muss erfolgreich sein (oder Feedback muss folgen)
- √úberanstrengung kann kontraproduktiv sein

**Der "Von KI erhalten"-Balken:**

Die 35% sind illustrativ, nicht aus einer spezifischen Studie. Allerdings gibt es Hinweise, dass passiv erhaltene, nicht selbst verarbeitete Information schlecht behalten wird. Die Bastani-Studie und √§hnliche Befunde deuten in diese Richtung.
:::

---

# Historische Analogien

**Sprechtext:**

Hier sehen Sie eine Zeitlinie technologischer Entwicklungen und ihrer Auswirkungen auf unsere kognitiven F√§higkeiten.

Die 1970er: Der Taschenrechner. Studien zeigen, dass fr√ºher und intensiver Taschenrechner-Einsatz das konzeptuelle mathematische Verst√§ndnis beeintr√§chtigen kann.

Die 1990er: GPS-Navigation. Habitueller GPS-Gebrauch ist mit schw√§cherem r√§umlichem Ged√§chtnis assoziiert. Londoner Taxifahrer, die "The Knowledge" lernen m√ºssen, haben messbar gr√∂ssere Hippocampi.

Die 2000er: Google. Sparrow und Kollegen zeigten den "Google-Effekt": Wir erinnern besser, WO Information zu finden ist, als WAS die Information ist.

Die 2020er: KI. Und jetzt? KI kombiniert und verst√§rkt all diese Effekte. Sie kann Rechnen, Navigieren, Suchen, aber auch: Schreiben, Analysieren, Argumentieren, Kreativ sein.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Der Unterschied
**KI ist breiter als GPS oder Taschenrechner.** Sie betrifft nicht eine kognitive Dom√§ne, sondern potenziell alle.
:::

::: {.callout-note}
## Hintergrund: Die Studien im Detail

**Taschenrechner (1970er-heute):**
Meta-Analysen zeigen gemischte Ergebnisse. Der Schl√ºssel ist WANN Taschenrechner eingesetzt werden. F√ºr bereits beherrschte Algorithmen: f√∂rderlich. Bevor konzeptuelles Verst√§ndnis aufgebaut ist: hinderlich.

**GPS [@dahmaniHabitualUseGPS2020]:**
Die Studie zeigte, dass h√§ufiger GPS-Gebrauch mit schlechterem r√§umlichem Ged√§chtnis korreliert, auch nach Kontrolle f√ºr andere Faktoren. Die Kausalit√§t ist schwer zu etablieren, aber die Theorie ist plausibel: Wer nicht navigiert, trainiert den Hippocampus nicht.

Die ber√ºhmte Taxifahrer-Studie (Maguire et al., 2000) zeigte strukturelle Gehirnver√§nderungen bei Londoner Cabbies. Interessanterweise: Nach der Pensionierung bildete sich der Effekt teilweise zur√ºck.

**Google-Effekt [@sparrowGoogleEffectsMemory2011]:**
Teilnehmer erinnerten Information schlechter, wenn sie glaubten, diese sei gespeichert und abrufbar. Aber sie erinnerten den Speicherort besser. Das Gehirn outsourcet strategisch.

**Die KI-Frage:**
Was passiert, wenn wir nicht nur Faktenwissen, sondern auch Denk- und Analyseprozesse outsourcen k√∂nnen? Die historischen Analogien sind instruktiv, aber KI ist qualitativ anders.
:::

---

# Die entscheidende Frage

**Sprechtext:**

Das bringt uns zur entscheidenden Frage.

Das gleiche Werkzeug, unterschiedliche Ergebnisse.

üëÜ

- üßÆ **Taschenrechner** helfen Mathematikern enorm. Aber f√ºr Lernende k√∂nnen sie sch√§dlich sein.
- üìç **GPS** unterst√ºtzt Taxifahrer. Aber es schw√§cht das r√§umliche Ged√§chtnis von Menschen, die es noch nicht aufgebaut haben.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Die entscheidende Frage
**Nicht OB KI n√ºtzt oder schadet. Sondern: WER profitiert und wer nicht?**
:::

üëÜ

Die Antwort liegt in dem, was Experten von Lernenden unterscheidet.

::: {.callout-note}
## Hintergrund: Die Werkzeug-Nutzer-Interaktion

**Das Paradox kognitiver Werkzeuge:**

Werkzeuge, die Experten produktiver machen, k√∂nnen Lernenden schaden. Das liegt an unterschiedlichen Bed√ºrfnissen:

- **Experten** m√ºssen Routine-Aufgaben erledigen, um sich auf h√∂here Aufgaben zu konzentrieren. Werkzeuge, die Routine automatisieren, befreien kognitive Kapazit√§t.

- **Lernende** m√ºssen genau diese Routine-Aufgaben √ºben, um Expertise aufzubauen. Werkzeuge, die √ºbernehmen, nehmen die Lernchance.

**Das Matthew-Prinzip:**

"Wer hat, dem wird gegeben." Experten werden durch Werkzeuge noch besser. Lernende riskieren, nie Expertise zu entwickeln.

**Implikation:**

Die pauschale Frage "Sollten wir KI im Unterricht erlauben?" ist falsch gestellt. Die richtige Frage ist: "F√ºr wen, wann, unter welchen Bedingungen, und mit welcher Unterst√ºtzung?"
:::

---

# Was Experten sehen

**Sprechtext:**

Schauen wir uns an, was Experten von Novizen unterscheidet. Das klassische Beispiel kommt aus der Schachforschung.

*[Bild zeigt eine Schachstellung]*

üë§ **Novize sieht:** 64 Felder, 32 Figuren, viele M√∂glichkeiten. Die Einzelteile.

üëÜ

üéì **Experte sieht:** "Sizilianische Verteidigung, K√∂nigsangriff m√∂glich, Schw√§che auf f7." Muster und Bedeutung.

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Der fundamentale Unterschied
Experten speichern Wissen in **"Chunks"**: vernetzte Wissensstrukturen, die automatisch abgerufen werden.
:::

Ein Schachmeister hat etwa 50.000 solcher Chunks im Langzeitged√§chtnis. Er sieht nicht 32 Figuren, er sieht bekannte Konstellationen, Pl√§ne, Gefahren.

Die Forschung dazu geht auf de Groot zur√ºck und wurde von Chase und Simon quantifiziert. Wenn man Meistern und Anf√§ngern kurz eine Stellung zeigt, erinnern Meister viel mehr. Aber nur bei sinnvollen Stellungen! Bei zuf√§llig platzierten Figuren sind Meister nicht besser als Anf√§nger.

::: {.callout-note}
## Hintergrund: Expertise-Forschung im Schach

**De Groot (1965/1978):**
Der niederl√§ndische Psychologe Adriaan de Groot untersuchte, wie Grossmeister denken. √úberraschenderweise rechneten sie nicht mehr Z√ºge voraus als schw√§chere Spieler. Sie erkannten bessere Z√ºge schneller.

**Chase & Simon (1973):**
Sie quantifizierten den Expertise-Effekt:
- 5-Sekunden-Exposition einer Schachstellung
- Meister erinnerten ~16 von 24 Figuren
- Anf√§nger erinnerten ~4 von 24 Figuren
- Bei Zufallsstellungen: beide etwa 3-4

**Die Chunk-Hypothese:**
Experten haben nicht bessere Ged√§chtnisse. Sie haben bessere Organisationsstrukturen. Ein "Chunk" ist eine bedeutungsvolle Einheit (z.B. "K√∂nigsindische Verteidigung" statt "Springer auf f6, Bauern auf d6 und e5, L√§ufer auf g7...").

**Gesch√§tzte Chunk-Anzahl:**
- Grossmeister: ~50.000-100.000 Schach-Chunks
- Zum Vergleich: Ein Wortschatz hat √§hnliche Gr√∂ssenordnungen

**Transfer zu anderen Dom√§nen:**
√Ñhnliche Muster wurden gefunden bei:
- √Ñrzten bei der Diagnose (Chi et al.)
- Programmierern beim Code-Lesen
- Physikern bei Problemkategorisierung
:::

---

# Der Expertise-Umkehr-Effekt

**Sprechtext:**

Das bringt uns zu einem der wichtigsten Befunde der Instruktionsforschung: dem Expertise-Umkehr-Effekt.

*üëÜ Hinweis auf Interaktivit√§t: Sie k√∂nnen die Prozent-Buttons anklicken, um zu sehen, wie sich die optimale Lehrmethode ver√§ndert.*

Auf der x-Achse sehen Sie das Vorwissen des Lernenden, von niedrig bis hoch. Auf der y-Achse den Lerneffekt.

Die magentafarbene Linie zeigt hohe Unterst√ºtzung: ausgearbeitete Beispiele, direkte Instruktion, Schritt-f√ºr-Schritt-Anleitungen.

Die graue Linie zeigt niedrige Unterst√ºtzung: problembasiertes Lernen, eigene L√∂sungswege finden lassen.

Bei niedrigem Vorwissen (klicken Sie mal auf 20%): **hohe Unterst√ºtzung besser**. Novizen brauchen Struktur.

Aber bei hohem Vorwissen (80% oder 100%): **niedrige Unterst√ºtzung besser**. Detaillierte Anleitungen werden redundant und st√∂ren sogar.

::: {.callout-warning appearance="simple"}
## ‚≠ê Expertise-Umkehr-Effekt
**Was f√ºr Novizen optimal ist, ist f√ºr Experten suboptimal. Und umgekehrt.**
:::

::: {.callout-note}
## Hintergrund: Expertise Reversal Effect

**Ursprung:**
Der Effekt wurde von Kalyuga et al. (2003) systematisch dokumentiert, basierend auf Swellers Cognitive Load Theory.

**Mechanismus:**

Bei Novizen:
- Wenig Chunks im Langzeitged√§chtnis
- Arbeitsged√§chtnis wird schnell √ºberlastet
- Externe Unterst√ºtzung reduziert Cognitive Load
- Mehr Kapazit√§t f√ºr Lernen

Bei Experten:
- Viele Chunks verf√ºgbar
- Externe Instruktion wird mit internem Wissen integriert
- Redundante Information erzeugt EXTRA Cognitive Load
- Weniger Kapazit√§t f√ºr Lernen

**Praktische Implikation:**

Instruktion muss dynamisch an den Lernstand angepasst werden. "Fading" ist eine Technik: Beginne mit hoher Unterst√ºtzung, reduziere sie graduell mit wachsender Expertise.

**F√ºr KI:**

KI bietet typischerweise "volle Unterst√ºtzung" (direkte Antworten). Das ist f√ºr Experten n√ºtzlich, f√ºr Novizen potenziell sch√§dlich. "GPT Tutors" mit p√§dagogischen Leitplanken versuchen, dies zu adressieren.
:::

---

# Warum Experten profitieren, Lernende nicht

**Sprechtext:**

Jetzt k√∂nnen wir zusammenfassen, warum Experten und Lernende so unterschiedlich von KI-Werkzeugen betroffen sind.

üëÜ f√ºr jeden Punkt

üéì **Experten:**

- ‚úÖ K√∂nnen Routine auslagern
- ‚úÖ K√∂nnen KI-Output bewerten
- ‚úÖ Mehr Kapazit√§t f√ºr Komplexes

üëÜ

üë§ **Lernende:**

- ‚ùå K√∂nnen KI-Output **nicht** bewerten
- ‚ùå √úberspringen m√∂glicherweise Grundlagen
- ‚ùå Risiko: **"fliessende Inkompetenz"** (mit Hilfe alles, ohne Hilfe nichts)

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Fazit
**Dasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.**
:::

::: {.callout-tip appearance="simple"}
## üéì Kurs-Hinweis
Warum das so ist: **Beginner-Kurs** erkl√§rt Funktionsweise und Limitationen von Sprachmodellen.
:::

::: {.callout-note}
## Hintergrund: "Fliessende Inkompetenz"

**Der Begriff:**
"Fluent incompetence" oder "fliessende Inkompetenz" beschreibt einen Zustand, in dem jemand mit Hilfsmitteln kompetent erscheint, aber ohne sie scheitert.

**Historische Beispiele:**
- Pilotin, die nur mit Autopilot fliegen kann
- √Ñrztin, die nur mit Diagnose-Software diagnostizieren kann
- Studierende, die nur mit KI schreiben k√∂nnen

**Das Problem:**

1. Die Inkompetenz wird maskiert, bis ein kritischer Moment kommt
2. Betroffene √ºbersch√§tzen ihre eigenen F√§higkeiten
3. Das Hilfsmittel wird zur unverzichtbaren Kr√ºcke

**Besonders relevant f√ºr Pr√ºfungen:**

Wenn Studierende mit KI √ºben und ohne KI gepr√ºft werden (wie in der Bastani-Studie), wird die fliessende Inkompetenz sichtbar.

**Aber auch dar√ºber hinaus:**

Was passiert, wenn die KI nicht verf√ºgbar ist? Bei technischem Ausfall? In Situationen, die Spontanit√§t erfordern? Im Vorstellungsgespr√§ch?
:::

---

# Kritisches Denken braucht Fachwissen

**Sprechtext:**

An diesem Punkt h√∂re ich oft einen Einwand: "Gut, Lernende k√∂nnen KI-Output nicht bewerten. Aber das ist doch l√∂sbar! Wir bringen ihnen einfach bei, KI-Output kritisch zu pr√ºfen. Kritisches Denken als Kompetenz."

Das klingt vern√ºnftig. Aber hier kommt ein wichtiger Punkt von Daniel Willingham, der diesen Ansatz grundlegend in Frage stellt:

> üí¨ "Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context."

Kritisches Denken ist keine kontextfreie F√§higkeit. Man kann nicht einfach "kritisch denken lernen" und es dann √ºberall anwenden.

üëÜ

**Beispiel:**

- üéì Biomedizin-Experte erkennt Fehler in ChatGPT-Antwort zu Biochemie
- üë§ Novize kann diese Bewertung nicht vornehmen

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Kernaussage
**Du kannst nicht kritisch bewerten, was du nicht verstehst.**
:::

üëÜ

Und genau deshalb ist Fachwissen so entscheidend: Es bestimmt, ob KI deine Kognition erweitert oder ersetzt.

::: {.callout-note}
## Hintergrund: Willinghams Argument

**Daniel Willingham** ist kognitiver Psychologe an der University of Virginia, bekannt f√ºr die Anwendung kognitiver Forschung auf Bildung.

**Sein Argument im Detail:**

Kritisches Denken erfordert:
1. Dom√§nenwissen (Fakten und Konzepte)
2. Kenntnis der relevanten Argumente und Gegenargumente
3. Vertrautheit mit typischen Fehlern in der Dom√§ne

Keines davon ist √ºbertragbar. Wer kritisch √ºber Geschichte denken kann, kann nicht automatisch kritisch √ºber Biologie denken.

**Implikation f√ºr "KI-Kompetenz":**

Es gibt keine allgemeine "F√§higkeit, KI-Output zu bewerten". Man kann KI-Output in einer Dom√§ne nur bewerten, wenn man die Dom√§ne versteht.

**Das Problem f√ºr Lernende:**

Wenn man ihnen sagt "Pr√ºfe die KI-Antwort kritisch", ohne dass sie das Fachwissen haben, ist das eine leere Anweisung. Sie k√∂nnen h√∂chstens oberfl√§chliche Checks durchf√ºhren (Konsistenz, Grammatik), aber nicht inhaltliche.

**M√∂glicher Ausweg:**

KI als Tutor, der nicht Antworten gibt, sondern Fragen stellt und Hinweise gibt. Dann bleibt das Denken beim Lernenden.
:::

---

# Kognition erweitern vs. ersetzen

**Sprechtext:**

Andy Clark, ein Philosoph an der University of Edinburgh, hat eine n√ºtzliche Unterscheidung eingef√ºhrt.

üëÜ f√ºr linke Spalte

‚ûï **Kognition erweitern:**

- Mensch bleibt kognitiv engagiert
- Werkzeug verst√§rkt F√§higkeiten, ersetzt sie nicht
- *Beispiel: Taschenrechner f√ºr Mathematiker*

üëÜ f√ºr rechte Spalte

‚ûñ **Kognition ersetzen:**

- Mensch wird passiv
- Werkzeug √ºbernimmt das Denken
- *Beispiel: Student l√§sst ChatGPT Essay schreiben*

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Wichtiger Punkt
**Dasselbe Werkzeug kann beides sein, abh√§ngig von der Nutzung.**

ChatGPT als Brainstorming-Partner ‚Üí Erweiterung

ChatGPT als Ghostwriter ‚Üí Ersetzung
:::

::: {.callout-note}
## Hintergrund: Extended Mind Thesis

**Andy Clark** entwickelte mit David Chalmers die "Extended Mind Thesis" (1998): Kognition endet nicht an der Sch√§delgrenze. Werkzeuge k√∂nnen Teil des kognitiven Systems werden.

**Clarks neuere Arbeit zu KI:**

In "Extending Minds with Generative AI" (2025) argumentiert Clark, dass generative KI besonders geeignet ist, Kognition zu erweitern, weil sie flexibel und sprachbasiert ist.

**Aber mit einer Warnung:**

Erweiterung gelingt nur, wenn:
1. Der Nutzer das Werkzeug versteht
2. Der Nutzer die Kontrolle beh√§lt
3. Der Nutzer die Ergebnisse evaluieren kann

F√ºr Experten sind diese Bedingungen typischerweise erf√ºllt. F√ºr Lernende nicht unbedingt.

**Ersetzung vs. Erweiterung:**

- **Erweiterung**: Du + Werkzeug > Du allein
- **Ersetzung**: Werkzeug anstelle von Dir

Bei Ersetzung: Keine Entwicklung, keine √úbung, keine Expertise.

**Die p√§dagogische Frage:**

Wie gestalten wir KI-Nutzung so, dass sie erweitert statt ersetzt? Antwort: Durch Aufgabendesign, Leitplanken, und bewusste Reflexion.
:::

---

# Die Sequenzierungsfrage

**Sprechtext:**

Das bringt uns zur praktischen Frage: Wenn Experten profitieren und Lernende Gefahr laufen, wann ist der √úbergang?

Hier sehen wir das Spektrum: Links der Novize, rechts der Experte. Irgendwo dazwischen liegt eine Schwelle.

üëÜ f√ºr jeden Punkt

‚ùì **Das Problem:**

- Schwelle ist **unbekannt**
- Variiert nach **Dom√§ne und Person**
- Keine pauschalen Regeln m√∂glich

üëÜ

::: {.callout-warning appearance="simple"}
## ‚≠ê Die praktische Frage
**Wer profitiert von KI-Werkzeugen? Und wer nicht?**

‚Üí H√§ngt ab vom spezifischen Kontext, der Person, der Aufgabe.
:::

::: {.callout-note}
## Hintergrund: Die Sequenzierungsfrage

**Das Dilemma:**

Wenn wir zu fr√ºh KI erlauben: Lernende bauen keine Expertise auf.
Wenn wir zu lange KI verbieten: Wir ignorieren n√ºtzliche Werkzeuge und bereiten nicht auf die Realit√§t vor.

**Ans√§tze aus der Literatur:**

1. **Erst Grundlagen, dann Werkzeuge**: Wie bei Taschenrechnern. Erst Kopfrechnen, dann Taschenrechner.

2. **Fading**: Beginne ohne KI, f√ºhre sie graduell ein.

3. **Reflexive Integration**: Erlaube KI, aber fordere explizite Reflexion √ºber den eigenen Lernprozess.

4. **Aufgabendifferenzierung**: Manche Aufgaben ohne KI, andere mit.

**Das Forschungsdefizit:**

Es gibt noch keine L√§ngsschnittstudien, die zeigen, welche Sequenzierung optimal ist. Die Bastani-Studie ist kurzfristig. Wir wissen nicht, wie sich verschiedene Strategien √ºber Semester oder Jahre auswirken.

**Praktische Empfehlung:**

In Ermangelung perfekter Evidenz: Konservativ beginnen. Die Risiken des zu fr√ºhen Einsatzes (Lerndefizite) sind schwerer zu reparieren als die Kosten des zu sp√§ten Einsatzes (ineffiziente Arbeit).
:::

---

# Die Kernaussage

**Sprechtext:**

*[Pause]*

üëÜ

::: {.callout-important appearance="simple"}
## ‚≠ê ‚≠ê ‚≠ê DIE KERNAUSSAGE
**KI-Werkzeuge sind f√ºr Experten gemacht.**
:::

üëÜ

Das ist keine Wertung, sondern eine Feststellung. Diese Werkzeuge wurden von Experten entwickelt, f√ºr Experten-Workflows optimiert, und funktionieren am besten f√ºr Menschen, die bereits wissen, was sie tun.

Sie machen Experten produktiver:

- üíª Programmierer mit GitHub Copilot
- üìö Forscher mit Literature-Review-Tools
- üñäÔ∏è Schreiber mit KI-Unterst√ºtzung

üëÜ

**Aber:** Lernende profitieren oft nicht. Lernen erfordert genau die kognitive Anstrengung, die KI zu eliminieren droht.

üí° **Der entscheidende Punkt:** Es ist nicht unvermeidlich! Erinnern Sie sich an den **GPT-Tutor** aus der Bastani-Studie? KI, die Fragen stellt statt Antworten zu geben ‚Üí erh√§lt die kognitive Anstrengung.

::: {.callout-tip appearance="simple"}
## üéì Kurs-Hinweis
Im **Advanced-Kurs** entwickeln Sie selbst ein solches p√§dagogisch gestaltetes KI-Tool.
:::

üëÜ

::: {.callout-important appearance="simple"}
## ‚≠ê Die wichtigste Aussage heute
**Lernende brauchen erst das Fundament, das kritische KI-Nutzung erm√∂glicht.**

Nicht "keine KI", aber **"Fundament zuerst"**.
:::

::: {.callout-note}
## Hintergrund: Zusammenfassung der Argumentation

**Die Argumentationskette:**

1. KI √ºbernimmt kognitive Arbeit
2. F√ºr Experten: Entlastung von Routine, mehr Kapazit√§t f√ºr Komplexes
3. F√ºr Lernende: Wegfall der Lernarbeit, keine Expertise-Entwicklung
4. Der Expertise-Umkehr-Effekt erkl√§rt diesen Unterschied theoretisch
5. Die Bastani-Studie belegt ihn empirisch

**Was das NICHT bedeutet:**

- KI ist schlecht (Nein: KI ist kontextabh√§ngig)
- KI sollte verboten werden (Nein: KI sollte klug eingesetzt werden)
- Studierende sind unm√ºndig (Nein: aber sie brauchen Anleitung beim Aufbau von Expertise)

**Was es BEDEUTET:**

- Differenzierte Strategien je nach Lernstand
- Explizite Reflexion √ºber KI-Nutzung
- Pr√ºfungsformate √ºberdenken
- Dozierende m√ºssen selbst KI-kompetent werden

**Die Rolle der Institution:**

Hochschulen m√ºssen Rahmenbedingungen schaffen, die gesunde KI-Nutzung erm√∂glichen. Das erfordert Diskussion, Experimente, und Iteration. Es gibt keine einfachen Antworten.
:::

---

# Was bedeutet das f√ºr die Lehre?

**Sprechtext:**

Zum Abschluss: Was bedeutet das konkret f√ºr unsere Lehre?

üëÜ f√ºr jede S√§ule

::: {.callout-warning appearance="simple"}
## 1Ô∏è‚É£ Anstrengung ist das Signal
Wenn Lernen sich zu leicht anf√ºhlt, findet es wahrscheinlich nicht statt.
:::

::: {.callout-warning appearance="simple"}
## 2Ô∏è‚É£ KI als Tutor, nicht als Antwortgeber
KI soll Denkprozesse anregen, nicht ersetzen. Fragen stellen, Hinweise geben.
:::

::: {.callout-warning appearance="simple"}
## 3Ô∏è‚É£ Expertise bestimmt den Nutzen
Dasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen. Differenzieren!
:::

üëÜ

::: {.callout-important appearance="simple"}
## ‚≠ê ‚≠ê ‚≠ê ZUSAMMENFASSUNG

**Grundlagen BEVOR Werkzeuge.**

Erst das Fundament, dann die Erweiterung.

Erst verstehen, dann automatisieren.

Erst selbst k√∂nnen, dann delegieren.
:::

**Vielen Dank.** üëè

::: {.callout-note}
## Hintergrund: Praktische Implikationen

**F√ºr die Kursplanung:**

1. **Explizit machen**: Erkl√§ren Sie Studierenden, warum bestimmte Aufgaben ohne KI zu l√∂sen sind
2. **Stufenweise einf√ºhren**: KI-Zugang kann mit steigender Kompetenz erweitert werden
3. **Reflexion einbauen**: Fragen Sie nach jedem KI-Einsatz: "Was habe ich dabei gelernt?"

**F√ºr Pr√ºfungen:**

1. **Diversifizieren**: Nicht alle Pr√ºfungen k√∂nnen KI-gest√ºtzt sein
2. **Prozesspr√ºfungen**: Nicht nur Endprodukte, sondern auch den Weg dorthin pr√ºfen
3. **M√ºndliche Elemente**: KI kann (noch) nicht f√ºr jemanden sprechen

**F√ºr die eigene Entwicklung:**

1. **Selbst KI nutzen**: Nur wer KI kennt, kann sinnvoll beraten
2. **Experimente wagen**: Probieren Sie verschiedene Ans√§tze aus
3. **Austausch suchen**: Sprechen Sie mit Kolleginnen und Kollegen

**Weiterf√ºhrende Ressourcen:**

- Mollick, E. (2024). "Co-Intelligence"
- Nationales Forum Hochschullehre: KI-Leitlinien
- Stanford HAI: Reports zu KI in der Bildung

**BFH Weiterbildung:**

- Beginner: Grundlagen zu Sprachmodellen und Chatbots
- Intermediate: Lernpsychologie und KI-gest√ºtztes Lerndesign
- Advanced: Workshop zur Entwicklung eines eigenen KI-Lerntools
:::

---

# Referenzen

**Sprechtext:**

Die Referenzen finden Sie in den Folien und im begleitenden Materialien. Die wichtigsten sind:

- Bastani et al. f√ºr die empirische Studie
- Sweller f√ºr die Cognitive Load Theory
- Bjork f√ºr die erw√ºnschten Schwierigkeiten
- Kalyuga f√ºr den Expertise-Umkehr-Effekt
- Willingham f√ºr kritisches Denken und Fachwissen
- Clark f√ºr die Erweiterung vs. Ersetzung der Kognition

Ich freue mich auf Ihre Fragen und die Diskussion.

::: {.callout-note}
## Vollst√§ndige Referenzliste

**Hauptquellen der Pr√§sentation:**

- Bastani, H., et al. (2025). Generative AI can harm learning. *PNAS*.
- Bjork, R. A. (2011). Making things hard on yourself, but in a good way. In Gernsbacher et al. (Eds.), *Psychology and the real world*.
- Chase, W. G., & Simon, H. A. (1973). Perception in chess. *Cognitive Psychology*.
- Clark, A. (2025). Extending minds with generative AI. *Philosophy & Technology*.
- Dahmani, L., & Bhorer, V. (2020). Habitual use of GPS negatively impacts spatial memory. *Scientific Reports*.
- de Groot, A. D. (1978). *Thought and choice in chess*. Mouton.
- Kalyuga, S. (2009). The expertise reversal effect. In Plass et al. (Eds.), *Cognitive load theory*.
- Slamecka, N. J., & Graf, P. (1978). The generation effect. *Journal of Experimental Psychology: Human Learning and Memory*.
- Sparrow, B., et al. (2011). Google effects on memory. *Science*.
- Sweller, J. (2024). Cognitive load theory. In *The Cambridge handbook of cognition and education*.
- Willingham, D. T. (2008). Critical thinking: Why is it so hard to teach? *Arts Education Policy Review*.
:::
