@article{amLiteratureReviewKnowledge2021,
  title = {A {{Literature Review}} of {{Knowledge Tracing}} for {{Student Modeling}} : {{Research Trends}}, {{Models}}, {{Datasets}}, and {{Challenges}}},
  shorttitle = {A {{Literature Review}} of {{Knowledge Tracing}} for {{Student Modeling}}},
  author = {Am, Ebedia Hilda and Hidayah, Indriana and Kusumawardani, Sri Suning},
  date = {2021-10-08},
  journaltitle = {Journal of Information Technology and Computer Science},
  shortjournal = {JITeCS},
  volume = {6},
  number = {2},
  issn = {2540-9824, 2540-9433},
  doi = {10.25126/jitecs.202162344},
  url = {https://jitecs.ub.ac.id/index.php/jitecs/article/view/344},
  urldate = {2025-06-12},
  abstract = {Modeling students' knowledge is a fundamental part of online learning platforms. Knowledge tracing is an application of student modeling which renowned for its ability to trace students' knowledge. Knowledge tracing ability can be used in online learning platforms for predicting learning performance and providing adaptive learning. Due to the wide uses of knowledge tracing in student modeling, this study aims to understand the state-of-the-art and future research of knowledge tracing. This study focused on reviewing 24 studies published between 2017 to the third quarter of 2021 in four digital databases. The selected studies have been filtered using inclusion and exclusion criteria. Several previous studies have shown that there are two approaches used in knowledge tracing, including probabilistic and deep learning. Bayesian Knowledge Tracing model is the most widely used in the probabilistic approach, while the Deep Knowledge Tracing model is the most popular model in the deep learning approach. Meanwhile, ASSISTments 2009–2010 is the most frequently tested dataset for probabilistic and deep learning approaches. In the future, additional studies are required to explore several models which have been developed previously. Therefore this study provides direction for future research of each existing approach.},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T19:15:32.043Z},
  file = {/Users/andrew/Zotero/storage/X6DD46JC/Am et al. - 2021 - A Literature Review of Knowledge Tracing for Student Modeling  Research Trends, Models, Datasets, a.pdf}
}

@article{andersonAcquisitionCognitiveSkill1982,
  title = {Acquisition of Cognitive Skill},
  author = {Anderson, John R.},
  date = {1982},
  journaltitle = {Psychological Review},
  volume = {89},
  number = {4},
  pages = {369--406},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-1471},
  doi = {10.1037/0033-295X.89.4.369},
  abstract = {Proposes a framework for skill acquisition that includes 2 major stages in the development of a cognitive skill: (1) a declarative stage in which facts about the skill domain are interpreted and (2) a procedural stage in which the domain knowledge is directly embodied in procedures for performing the skill. This general framework has been instantiated in the ACT system in which facts are encoded in a propositional network and procedures are encoded as productions. Knowledge compilation is the process by which the skill transits from the declarative stage to the procedural stage. It consists of the subprocesses of composition, which collapses sequences of productions into single productions, and proceduralization, which embeds factual knowledge into productions. Once proceduralized, further learning processes operate on the skill to make the productions more selective in their range of applications. These processes include generalization, discrimination, and strengthening of productions. Comparisons are made to similar concepts from previous learning theories. How these learning mechanisms apply to produce the power law speedup in processing time with practice is discussed. (62 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {/unread,Cognitive Development,Cognitive Processes,Skill Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-20T19:40:16.275Z},
  file = {/Users/andrew/Zotero/storage/3LC7JXRB/Anderson - Acquisition of cognitive skill.pdf;/Users/andrew/Zotero/storage/XHBB8DK6/1982-27252-001.html}
}

@book{andersonAdaptiveCharacterThought2013,
  title = {The {{Adaptive Character}} of {{Thought}}},
  author = {Anderson, John R.},
  date = {2013-01-11},
  publisher = {Psychology Press},
  location = {New York},
  doi = {10.4324/9780203771730},
  abstract = {This important volume examines the phenomena of cognition from an adaptive perspective. Rather than adhering to the typical practice in cognitive psychology of trying to predict behavior from a model of cognitive mechanisms, this book develops a number of models that successfully predict behavior from the structure of the environment to which cognition is adapted. The methodology -- called rational analysis -- involves specifying the information-processing goals of the system, the structure of the environment, and the computational constraints on the system, allowing predictions about behavior to be made by determining what behavior would be optimal under these assumptions. The Adaptive Character of Thought applies this methodology in great detail to four cognitive phenomena: memory, categorization, causal inference, and problem solving.},
  isbn = {978-0-203-77173-0},
  pagetotal = {290},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-19T08:53:00.337Z},
  file = {/Users/andrew/Zotero/storage/C7TEQ6XI/Anderson - 2013 - The Adaptive Character of Thought.pdf}
}

@book{andersonHowCanHuman2007,
  title = {How {{Can}} the {{Human Mind Occur}} in the {{Physical Universe}}?},
  author = {Anderson, John R.},
  date = {2007-10-01},
  publisher = {Oxford University Press},
  doi = {10.1093/acprof:oso/9780195324259.001.0001},
  url = {https://doi.org/10.1093/acprof:oso/9780195324259.001.0001},
  urldate = {2025-06-20},
  abstract = {This book takes its title from the last lecture by Allen Newell, one of the pioneers of cognitive science. He said, “The question for me is how can the human mind occur in the physical universe? We now know that the world is governed by physics. We now understand the way biology nestles comfortably within that. The issue is how will the mind do that as well?” Newell argued that the answer to his question must take the form of a cognitive architecture, and this book describes an answer that is emerging from the study of brain and behavior. Humans share the same basic cognitive architecture with all primates, but they have evolved abilities to exercise abstract control over cognition and process more complex relational patterns. The human cognitive architecture consists of a set of largely independent modules associated with different brain regions. The book discusses in detail how these various modules can combine to produce behaviors as varied as driving a car and solving an algebraic equation, but focuses principally on two of the modules: declarative and procedural. The declarative module involves a memory system that, moment by moment, attempts to give each person the most appropriate possible window into his or her past. The procedural module involves a central system that strives to develop a set of productions that will enable the most adaptive response from any state of the modules.},
  isbn = {978-0-19-532425-9},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-20T19:37:37.018Z},
  file = {/Users/andrew/Zotero/storage/JHNRS9W6/4367.html}
}

@book{andersonHowCanHuman2007a,
  title = {How {{Can}} the {{Human Mind Occur}} in the {{Physical Universe}}?},
  author = {Anderson, John R.},
  date = {2007-10-01},
  publisher = {Oxford University Press},
  doi = {10.1093/acprof:oso/9780195324259.001.0001},
  url = {https://doi.org/10.1093/acprof:oso/9780195324259.001.0001},
  urldate = {2025-06-20},
  abstract = {This book takes its title from the last lecture by Allen Newell, one of the pioneers of cognitive science. He said, “The question for me is how can the human mind occur in the physical universe? We now know that the world is governed by physics. We now understand the way biology nestles comfortably within that. The issue is how will the mind do that as well?” Newell argued that the answer to his question must take the form of a cognitive architecture, and this book describes an answer that is emerging from the study of brain and behavior. Humans share the same basic cognitive architecture with all primates, but they have evolved abilities to exercise abstract control over cognition and process more complex relational patterns. The human cognitive architecture consists of a set of largely independent modules associated with different brain regions. The book discusses in detail how these various modules can combine to produce behaviors as varied as driving a car and solving an algebraic equation, but focuses principally on two of the modules: declarative and procedural. The declarative module involves a memory system that, moment by moment, attempts to give each person the most appropriate possible window into his or her past. The procedural module involves a central system that strives to develop a set of productions that will enable the most adaptive response from any state of the modules.},
  isbn = {978-0-19-532425-9},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-20T22:41:35.094Z},
  file = {/Users/andrew/Zotero/storage/YS2XXYIY/Anderson - 2007 - How Can the Human Mind Occur in the Physical Universe.pdf;/Users/andrew/Zotero/storage/UGL4982N/4367.html}
}

@article{andersonRadicalConstructivismCognitive1998,
  title = {Radical {{Constructivism}} and {{Cognitive Psychology}}},
  author = {Anderson, John R. and Reder, Lynne M. and Simon, Herbert A. and Ericsson, K. Anders and Glaser, Robert},
  date = {1998},
  journaltitle = {Brookings Papers on Education Policy},
  number = {1},
  eprint = {20067198},
  eprinttype = {jstor},
  pages = {227--278},
  url = {http://www.jstor.org/stable/20067198},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-18T06:57:38.263Z},
  file = {/Users/andrew/Zotero/storage/2QV4DH8T/Anderson et al. - 1998 - Radical Constructivism and Cognitive Psychology.pdf}
}

@book{andersonRulesMind2014,
  title = {Rules of the {{Mind}}},
  author = {Anderson, John R.},
  date = {2014-01-14},
  publisher = {Psychology Press},
  location = {New York},
  doi = {10.4324/9781315806938},
  abstract = {Related to the earlier well-known ACT production system theory, this book's basic goal is to present evidence for the psychological reality of a production system model of mind. Distinguished from the original theory in three ways, this volume uses the rational analyses of Anderson (1990) to improve upon that theory and extend its scope. It also relates the theory to a great deal of new data on the performance and acquisition of cognitive skills.   The new theory -- ACT-R -- involves a neurally plausible implementation of a production system architecture. Rational analysis is used to structure and parameterize the system to yield optimal information processing. The theory is applicable to a wide variety of research disciplines, including memory, problem solving, and skill acquisition. Using intelligent tutors, much of the data is concerned with the acquisition of cognitive skills. The book provides analyses of data sets describing the extended course of the acquisition of mathematical and computer programming skills.},
  isbn = {978-1-315-80693-8},
  pagetotal = {336},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-20T19:37:59.201Z}
}

@article{badrinathPyBKTAccessiblePython,
  title = {{{pyBKT}}: {{An Accessible Python Library}} of {{Bayesian Knowledge Tracing Models}}},
  author = {Badrinath, Anirudhan and Wang, Frederic and Pardos, Zachary},
  abstract = {Bayesian Knowledge Tracing, a model used for cognitive mastery estimation, has been a hallmark of adaptive learning research and an integral component of deployed intelligent tutoring systems (ITS). In this paper, we provide a brief history of knowledge tracing model research and introduce pyBKT, an accessible and computationally efficient library of model extensions from the literature. The library provides data generation, fitting, prediction, and cross-validation routines, as well as a simple to use data helper interface to ingest typical tutor log dataset formats. We evaluate the runtime with various dataset sizes and compare to past implementations. Additionally, we conduct sanity checks of the model using experiments with simulated data to evaluate the accuracy of its EM parameter learning and use real-world data to validate its predictions, comparing pyBKT’s supported model variants with results from the papers in which they were originally introduced. The library is open source and open license for the purpose of making knowledge tracing more accessible to communities of research and practice and to facilitate progress in the field through easier replication of past approaches.},
  langid = {english},
  keywords = {/unread,⛔ No DOI found},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/ZGJS6BXZ/Badrinath et al. - pyBKT An Accessible Python Library of Bayesian Kn.pdf}
}

@online{bastaniGenerativeAICan2024,
  type = {SSRN Scholarly Paper},
  title = {Generative {{AI Can Harm Learning}}},
  author = {Bastani, Hamsa and Bastani, Osbert and Sungu, Alp and Ge, Haosen and Kabakcı, Özge and Mariman, Rei},
  date = {2024-07-15},
  number = {4895486},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4895486},
  url = {https://papers.ssrn.com/abstract=4895486},
  urldate = {2024-07-26},
  abstract = {Generative artificial intelligence (AI) is poised to revolutionize how humans work, and has already demonstrated promise in significantly improving human productivity. However, a key remaining question is how generative AI affects learning, namely, how humans acquire new skills as they perform tasks. This kind of skill learning is critical to long-term productivity gains, especially in domains where generative AI is fallible and human experts must check its outputs. We study the impact of generative AI, specifically OpenAI's GPT-4, on human learning in the context of math classes at a high school. In a field experiment involving nearly a thousand students, we have deployed and evaluated two GPT based tutors, one that mimics a standard ChatGPT interface (called GPT Base) and one with prompts designed to safeguard learning (called GPT Tutor). These tutors comprise about 15\% of the curriculum in each of three grades. Consistent with prior work, our results show that access to GPT-4 significantly improves performance (48\% improvement for GPT Base and 127\% for GPT Tutor). However, we additionally find that when access is subsequently taken away, students actually perform worse than those who never had access (17\% reduction for GPT Base). That is, access to GPT-4 can harm educational outcomes. These negative learning effects are largely mitigated by the safeguards included in GPT Tutor. Our results suggest that students attempt to use GPT-4 as a "crutch" during practice problem sessions, and when successful, perform worse on their own. Thus, to maintain long-term productivity, we must be cautious when deploying generative AI to ensure humans continue to learn critical skills.    * HB, OB, and AS contributed equally},
  langid = {english},
  pubstate = {prepublished},
  keywords = {/unread,Education,Generative AI,Human Capital Development,Human-AI Collaboration,Large Language Models},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-21T23:17:19.083Z},
  file = {/Users/andrew/Zotero/storage/YWWRMSGL/Bastani et al. - 2024 - Generative AI Can Harm Learning.pdf}
}

@article{bastaniGenerativeAIGuardrails2025,
  title = {Generative {{AI}} without Guardrails Can Harm Learning: {{Evidence}} from High School Mathematics},
  shorttitle = {Generative {{AI}} without Guardrails Can Harm Learning},
  author = {Bastani, Hamsa and Bastani, Osbert and Sungu, Alp and Ge, Haosen and Kabakcı, Özge and Mariman, Rei},
  date = {2025-07},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {122},
  number = {26},
  eprint = {40560616},
  eprinttype = {pubmed},
  pages = {e2422633122},
  issn = {1091-6490},
  doi = {10.1073/pnas.2422633122},
  abstract = {Generative AI is poised to revolutionize how humans work, and has already demonstrated promise in significantly improving human productivity. A key question is how generative AI affects learning-namely, how humans acquire new skills as they perform tasks. Learning is critical to long-term productivity, especially since generative AI is fallible and users must check its outputs. We study this question via a field experiment where we provide nearly a thousand high school math students with access to generative AI tutors. To understand the differential impact of tool design on learning, we deploy two generative AI tutors: one that mimics a standard ChatGPT interface ("GPT Base") and one with prompts designed to safeguard learning ("GPT Tutor"). Consistent with prior work, our results show that having GPT-4 access while solving problems significantly improves performance (48\% improvement in grades for GPT Base and 127\% for GPT Tutor). However, we additionally find that when access is subsequently taken away, students actually perform worse than those who never had access (17\% reduction in grades for GPT Base)-i.e., unfettered access to GPT-4 can harm educational outcomes. These negative learning effects are largely mitigated by the safeguards in GPT Tutor. Without guardrails, students attempt to use GPT-4 as a "crutch" during practice problem sessions, and subsequently perform worse on their own. Thus, decision-makers must be cautious about design choices underlying generative AI deployments to preserve skill learning and long-term productivity.},
  langid = {english},
  pmcid = {PMC12232635},
  keywords = {/unread,Adolescent,Artificial Intelligence,education,Female,generative AI,Humans,Learning,Male,Mathematics,personalized tutoring,Problem Solving,Schools,skill acquisition,Students},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T12:04:57.677Z}
}

@article{bauerLookingHypeUnderstanding2025,
  title = {Looking {{Beyond}} the {{Hype}}: {{Understanding}} the {{Effects}} of {{AI}} on {{Learning}}},
  shorttitle = {Looking {{Beyond}} the {{Hype}}},
  author = {Bauer, Elisabeth and Greiff, Samuel and Graesser, Arthur C. and Scheiter, Katharina and Sailer, Michael},
  date = {2025-06},
  journaltitle = {Educational Psychology Review},
  shortjournal = {Educ Psychol Rev},
  volume = {37},
  number = {2},
  pages = {45},
  issn = {1040-726X, 1573-336X},
  doi = {10.1007/s10648-025-10020-8},
  url = {https://link.springer.com/10.1007/s10648-025-10020-8},
  urldate = {2025-05-28},
  abstract = {Artificial intelligence (AI) holds significant potential for enhancing student learning. This reflection critically examines the promises and limitations of AI for cognitive learning processes and outcomes, drawing on empirical evidence and theoretical insights from research on AI-enhanced education and digital learning technologies. We critically discuss current publication trends in research on AI-enhanced learning and rather than assuming inherent benefits, we emphasize the role of instructional implementation and the need for systematic investigations that build on insights from existing research on the role of technology in instructional effectiveness. Building on this foundation, we introduce the ISAR model, which differentiates four types of AI effects on learning compared to learning conditions without AI, namely inversion, substitution, augmentation, and redefinition. Specifically, AI can substitute existing instructional approaches while maintaining equivalent instructional functionality, augment instruction by providing additional cognitive learning support, or redefine tasks to foster deep learning processes. However, the implementation of AI must avoid potential inversion effects, such as over-reliance leading to reduced cognitive engagement. Additionally, successful AI integration depends on moderating factors, including students’ AI literacy and educators’ technological and pedagogical skills. Our discussion underscores the need for a systematic and evidence-based approach to AI in education, advocating for rigorous research and informed adoption to maximize its potential while mitigating possible risks.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T11:04:42.165Z},
  file = {/Users/andrew/Zotero/storage/IZD2CVJT/Bauer et al. - 2025 - Looking Beyond the Hype Understanding the Effects of AI on Learning.pdf}
}

@article{bauerLookingHypeUnderstanding2025a,
  title = {Looking {{Beyond}} the {{Hype}}: {{Understanding}} the {{Effects}} of {{AI}} on {{Learning}}},
  shorttitle = {Looking {{Beyond}} the {{Hype}}},
  author = {Bauer, Elisabeth and Greiff, Samuel and Graesser, Arthur C. and Scheiter, Katharina and Sailer, Michael},
  date = {2025-04-24},
  journaltitle = {Educational Psychology Review},
  shortjournal = {Educ Psychol Rev},
  volume = {37},
  number = {2},
  pages = {45},
  issn = {1573-336X},
  doi = {10.1007/s10648-025-10020-8},
  url = {https://doi.org/10.1007/s10648-025-10020-8},
  urldate = {2025-08-13},
  abstract = {Artificial intelligence (AI) holds significant potential for enhancing student learning. This reflection critically examines the promises and limitations of AI for cognitive learning processes and outcomes, drawing on empirical evidence and theoretical insights from research on AI-enhanced education and digital learning technologies. We critically discuss current publication trends in research on AI-enhanced learning and rather than assuming inherent benefits, we emphasize the role of instructional implementation and the need for systematic investigations that build on insights from existing research on the role of technology in instructional effectiveness. Building on this foundation, we introduce the ISAR model, which differentiates four types of AI effects on learning compared to learning conditions without AI, namely inversion, substitution, augmentation, and redefinition. Specifically, AI can substitute existing instructional approaches while maintaining equivalent instructional functionality, augment instruction by providing additional cognitive learning support, or redefine tasks to foster deep learning processes. However, the implementation of AI must avoid potential inversion effects, such as over-reliance leading to reduced cognitive engagement. Additionally, successful AI integration depends on moderating factors, including students’ AI literacy and educators’ technological and pedagogical skills. Our discussion underscores the need for a systematic and evidence-based approach to AI in education, advocating for rigorous research and informed adoption to maximize its potential while mitigating possible risks.},
  langid = {english},
  keywords = {/unread,Artificial intelligence,Educational technology,Effectiveness,Evidence-based design,Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-13T09:34:37.431Z},
  file = {/Users/andrew/Zotero/storage/LWL3TCWR/Bauer et al. - 2025 - Looking Beyond the Hype Understanding the Effects of AI on Learning.pdf}
}

@inproceedings{beckIdentifiabilityFundamentalProblem2007,
  title = {Identifiability: {{A Fundamental Problem}} of {{Student Modeling}}},
  shorttitle = {Identifiability},
  booktitle = {User {{Modeling}} 2007},
  author = {Beck, Joseph E. and Chang, Kai-min},
  editor = {Conati, Cristina and McCoy, Kathleen and Paliouras, Georgios},
  date = {2007},
  pages = {137--146},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-73078-1_17},
  abstract = {In this paper we show how model identifiabilityis an issue for student modeling: observed student performance corresponds to an infinite family of possible model parameter estimates, all of which make identical predictions about student performance. However, these parameter estimates make different claims, some of which are clearly incorrect, about the student’s unobservable internal knowledge. We propose methods for evaluating these models to find ones that are more plausible. Specifically, we present an approach using Dirichlet priors to bias model search that results in a statistically reliable improvement in predictive accuracy (AUC of 0.620 ± 0.002 vs. 0.614 ± 0.002). Furthermore, the parameters associated with this model provide more plausible estimates of student learning, and better track with known properties of students’ background knowledge. The main conclusion is that prior beliefs are necessary to bias the student modeling search, and even large quantities of performance data alone are insufficient to properly estimate the model.},
  isbn = {978-3-540-73078-1},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T22:18:18.656Z}
}

@online{BiggestRiskDoing,
  title = {‘{{The}} Biggest Risk Is Doing Nothing’: Insights from Early Adopters of Artificial Intelligence in Schools and Further Education Colleges},
  shorttitle = {‘{{The}} Biggest Risk Is Doing Nothing’},
  url = {https://www.gov.uk/government/publications/ai-in-schools-and-further-education-findings-from-early-adopters/the-biggest-risk-is-doing-nothing-insights-from-early-adopters-of-artificial-intelligence-in-schools-and-further-education-colleges},
  urldate = {2025-07-02},
  langid = {english},
  organization = {GOV.UK},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-07-02T05:43:09.479Z}
}

@incollection{bjorkMakingThingsHard2011,
  title = {Making Things Hard on Yourself, but in a Good Way: {{Creating}} Desirable Difficulties to Enhance Learning},
  shorttitle = {Making Things Hard on Yourself, but in a Good Way},
  booktitle = {Psychology and the Real World: {{Essays}} Illustrating Fundamental Contributions to Society},
  author = {Bjork, Elizabeth Ligon and Bjork, Robert A.},
  date = {2011},
  pages = {56--64},
  publisher = {Worth Publishers},
  location = {New York, NY, US},
  abstract = {The basic problem learners confront is that we can easily be misled as to whether we are learning effectively and have or have not achieved a level of learning and comprehension that will support our subsequent access to information or skills we are trying to learn. We can be misled by our subjective impressions. Rereading a chapter a second time, for example, can provide a sense of familiarity or perceptual fluency that we interpret as understanding or comprehension, but may actually be a product of low-level perceptual priming. Similarly, information coming readily to mind can be interpreted as evidence of learning, but could instead be a product of cues that are present in the study situation, but that are unlikely to be present at a later time. We can also be misled by our current performance. Conditions of learning that make performance improve rapidly often fail to support long-term retention and transfer, whereas conditions that create challenges and slow the rate of apparent learning often optimize long-term retention and transfer. At a theoretical level, we (Bjork \& Bjork, 1992) distinguish between the storage strength and the retrieval strength of information or skills stored in memory. Storage strength reflects how entrenched or interassociated a memory representation is with related knowledge and skills, whereas retrieval strength reflects the current activation or accessibility of that representation and is heavily influenced by factors such as situational cues and recency of study or exposure. Importantly, we assume that current performance is entirely a function of current retrieval strength, but that storage strength acts to retard the loss (forgetting) and enhance the gain (relearning) of retrieval strength. The key idea for present purposes is that conditions that most rapidly increase retrieval strength differ from the conditions that maximize the gain of storage strength. In other words, if learners interpret current retrieval strength as storage strength, they become susceptible to preferring poorer conditions of learning to better conditions of learning. So what are these better conditions of learning that, while apparently creating difficulty, actually lead to more durable and flexible learning? Such desirable difficulties (Bjork, 1994) include varying the conditions of learning, rather than keeping them constant and predictable; interleaving instruction on separate topics, rather than grouping instruction by topic (called blocking); spacing, rather than massing, study sessions on a given topic; and using tests, rather than presentations, as study events. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  isbn = {978-1-4292-3043-8},
  keywords = {/unread,Applied Psychology,Learning,Learning Strategies},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-21T22:07:35.694Z},
  file = {/Users/andrew/Zotero/storage/G6FEHI5P/2011-19926-008.html}
}

@incollection{bjorkMemoryMetamemoryConsiderations1994,
  title = {Memory and Metamemory Considerations in the Training of Human Beings},
  booktitle = {Metacognition:  {{Knowing}} about Knowing},
  author = {Bjork, Robert A.},
  date = {1994},
  pages = {185--205},
  publisher = {The MIT Press},
  location = {Cambridge, MA, US},
  doi = {10.7551/mitpress/4561.001.0001},
  abstract = {examine 2 . . . contributors to nonoptimal training: (1) the learner's own misreading of his or her progress and current state of knowledge during training, and (2) nonoptimal relationships between the conditions of training and the conditions that can be expected to prevail in the posttraining real-world environment / [explore memory and metamemory considerations in training] (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  isbn = {978-0-262-13298-5},
  keywords = {/unread,Education,Memory,Metacognition},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-21T22:06:07.733Z},
  file = {/Users/andrew/Zotero/storage/C9MI8UGR/1994-97967-009.html}
}

@article{bloom2SigmaProblem1984,
  title = {The 2 {{Sigma Problem}}: {{The Search}} for {{Methods}} of {{Group Instruction}} as {{Effective}} as {{One-to-One Tutoring}}},
  shorttitle = {The 2 {{Sigma Problem}}},
  author = {BLOOM, BENJAMIN S.},
  date = {1984-06-01},
  journaltitle = {Educational Researcher},
  volume = {13},
  number = {6},
  pages = {4--16},
  publisher = {American Educational Research Association},
  issn = {0013-189X},
  doi = {10.3102/0013189X013006004},
  url = {https://doi.org/10.3102/0013189X013006004},
  urldate = {2025-03-14},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T14:12:16.910Z},
  file = {/Users/andrew/Zotero/storage/CU9SMA58/BLOOM - 1984 - The 2 Sigma Problem The Search for Methods of Group Instruction as Effective as One-to-One Tutoring.pdf}
}

@online{bocktingSimulationBasedPriorKnowledge2024,
  title = {Simulation-{{Based Prior Knowledge Elicitation}} for {{Parametric Bayesian Models}}},
  author = {Bockting, Florence and Radev, Stefan T. and Bürkner, Paul-Christian},
  date = {2024-04-15},
  eprint = {2308.11672},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2308.11672},
  url = {http://arxiv.org/abs/2308.11672},
  urldate = {2024-11-14},
  abstract = {A central characteristic of Bayesian statistics is the ability to consistently incorporate prior knowledge into various modeling processes. In this paper, we focus on translating domain expert knowledge into corresponding prior distributions over model parameters, a process known as prior elicitation. Expert knowledge can manifest itself in diverse formats, including information about raw data, summary statistics, or model parameters. A major challenge for existing elicitation methods is how to effectively utilize all of these different formats in order to formulate prior distributions that align with the expert's expectations, regardless of the model structure. To address these challenges, we develop a simulation-based elicitation method that can learn the hyperparameters of potentially any parametric prior distribution from a wide spectrum of expert knowledge using stochastic gradient descent. We validate the effectiveness and robustness of our elicitation method in four representative case studies covering linear models, generalized linear models, and hierarchical models. Our results support the claim that our method is largely independent of the underlying model structure and adaptable to various elicitation techniques, including quantile-based, moment-based, and histogram-based methods.},
  pubstate = {prepublished},
  keywords = {/unread,Statistics - Machine Learning,Statistics - Methodology},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.461Z},
  file = {/Users/andrew/Zotero/storage/GK9X5YR4/Bockting et al. - 2024 - Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models.pdf;/Users/andrew/Zotero/storage/2TPTP6JK/2308.html}
}

@book{brownMakeItStick2014,
  title = {Make {{It Stick}}: {{The Science}} of {{Successful Learning}}},
  shorttitle = {Make {{It Stick}}},
  author = {Brown, Peter C. and III, Henry L. Roediger and McDaniel, Mark A.},
  date = {2014},
  publisher = {Belknap Press: An Imprint of Harvard University Press},
  location = {Cambridge, Massachusetts},
  abstract = {The international bestseller that has helped millions of students, teachers, and lifelong learners use proven approaches to learn better and remember longer. “We have made Make It Stick a touchstone for our instructors … to gain a real advantage for our learners as they tackle some of the toughest work in the world.” ―Carl Czech, former Senior Instructional Systems Specialist/Advisor, US Navy SEALsAre you tired of forgetting what you learn? This groundbreaking book, based on the latest research in cognitive science, offers powerful strategies to boost memory and learning. To most of us, learning something “the hard way” means wasted time and effort. Good teaching, many believe, should be tailored to the different learning styles of students and should use strategies that make learning easier. Make It Stick turns fashionable ideas like these on their head. Drawing on recent discoveries in cognitive psychology and a ten-year collaboration among some of the world’s leading experts on human learning and memory, the authors explain what really drives successful learning. With clear, real-world examples, they show how we can confidently hone our skills and learn more effectively.Many common study habits simply don’t work. Underlining, highlighting, rereading, cramming, and single-minded repetition of new skills create the illusion of mastery, but gains fade quickly. Science shows that more durable learning comes from self-testing, introducing certain difficulties in practice, waiting to re-study new material until a little forgetting has occurred, and interleaving the practice of one skill or topic with another. Make It Stick breaks down these proven approaches in compelling ways and offers concrete techniques for becoming more productive learners. Full of eye-opening and inspiring stories for students, educators, and parents, Make It Stick is an indispensable guide for all those interested in the challenge of lifelong learning and self-improvement.},
  isbn = {978-0-674-72901-8},
  langid = {english},
  pagetotal = {336},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-09-18T22:01:22.415Z},
  file = {/Users/andrew/Zotero/storage/6SP8LRL2/Brown et al. - 2014 - Make It Stick The Science of Successful Learning.pdf}
}

@online{bubeckEarlyScienceAcceleration2025,
  title = {Early Science Acceleration Experiments with {{GPT-5}}},
  author = {Bubeck, Sébastien and Coester, Christian and Eldan, Ronen and Gowers, Timothy and Lee, Yin Tat and Lupsasca, Alexandru and Sawhney, Mehtaab and Scherrer, Robert and Sellke, Mark and Spears, Brian K. and Unutmaz, Derya and Weil, Kevin and Yin, Steven and Zhivotovskiy, Nikita},
  date = {2025-11-20},
  url = {https://arxiv.org/abs/2511.16072v1},
  urldate = {2025-12-08},
  abstract = {AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.},
  langid = {english},
  organization = {arXiv.org},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-08T14:50:19.809Z},
  file = {/Users/andrew/Zotero/storage/M4X8Y7G3/Bubeck et al. - 2025 - Early science acceleration experiments with GPT-5.pdf}
}

@article{bulutIntroductionBayesianKnowledge2023,
  title = {An {{Introduction}} to {{Bayesian Knowledge Tracing}} with {{pyBKT}}},
  author = {Bulut, Okan and Shin, Jinnie and Yildirim-Erbasli, Seyma N. and Gorgun, Guher and Pardos, Zachary A.},
  date = {2023-07-23},
  journaltitle = {Psych},
  shortjournal = {Psych},
  volume = {5},
  number = {3},
  pages = {770--786},
  issn = {2624-8611},
  doi = {10.3390/psych5030050},
  url = {https://www.mdpi.com/2624-8611/5/3/50},
  urldate = {2024-09-12},
  abstract = {This study aims to introduce Bayesian Knowledge Tracing (BKT), a probabilistic model used in educational data mining to estimate learners’ knowledge states over time. It also provides a practical guide to estimating BKT models using the pyBKT library available in Python. The first section presents an overview of BKT by explaining its theoretical foundations and advantages in modeling individual learning processes. In the second section, we describe different variants of the standard BKT model based on item response theory (IRT). Next, we demonstrate the estimation of BKT with the pyBKT library in Python, outlining data pre-processing steps, parameter estimation, and model evaluation. Different cases of knowledge tracing tasks illustrate how BKT estimates learners’ knowledge states and evaluates prediction accuracy. The results highlight the utility of BKT in capturing learners’ knowledge states dynamically. We also show that the model parameters of BKT resemble the parameters from logistic IRT models.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/TJ6MCDDE/Bulut et al. - 2023 - An Introduction to Bayesian Knowledge Tracing with pyBKT.pdf}
}

@online{caoMamba4KTEfficientEffective2024,
  title = {{{Mamba4KT}}:{{An Efficient}} and {{Effective Mamba-based Knowledge Tracing Model}}},
  shorttitle = {{{Mamba4KT}}},
  author = {Cao, Yang and Zhang, Wei},
  date = {2024-05-26},
  eprint = {2405.16542},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.16542},
  url = {http://arxiv.org/abs/2405.16542},
  urldate = {2025-06-09},
  abstract = {Knowledge tracing (KT) enhances student learning by leveraging past performance to predict future performance. Current research utilizes models based on attention mechanisms and recurrent neural network structures to capture long-term dependencies and correlations between exercises, aiming to improve model accuracy. Due to the growing amount of data in smart education scenarios, this poses a challenge in terms of time and space consumption for knowledge tracing models. However, existing research often overlooks the efficiency of model training and inference and the constraints of training resources. Recognizing the significance of prioritizing model efficiency and resource usage in knowledge tracing, we introduce Mamba4KT. This novel model is the first to explore enhanced efficiency and resource utilization in knowledge tracing. We also examine the interpretability of the Mamba structure both sequence-level and exercise-level to enhance model interpretability. Experimental findings across three public datasets demonstrate that Mamba4KT achieves comparable prediction accuracy to state-of-the-art models while significantly improving training and inference efficiency and resource utilization. As educational data continues to grow, our work suggests a promising research direction for knowledge tracing that improves model prediction accuracy, model efficiency, resource utilization, and interpretability simultaneously.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T21:59:05.710Z},
  file = {/Users/andrew/Zotero/storage/PLE5S5UE/Cao and Zhang - 2024 - Mamba4KTAn Efficient and Effective Mamba-based Knowledge Tracing Model.pdf;/Users/andrew/Zotero/storage/FTRPLWD3/2405.html}
}

@online{centreforeducationstatisticsandevaluationCognitiveLoadTheory2023,
  title = {Cognitive Load Theory: {{Research}} That Teachers Really Need to Understand},
  shorttitle = {Cognitive Load Theory},
  author = {{Centre for Education Statistics and Evaluation}},
  date = {2023-06-13T14:21:31.512+10:00},
  publisher = {NSW Department of Education},
  url = {https://education.nsw.gov.au/about-us/education-data-and-research/cese/publications/literature-reviews/cognitive-load-theory.html},
  urldate = {2025-11-17},
  abstract = {This paper describes the research on cognitive load theory and what it means for more effective teaching practice.},
  langid = {english},
  keywords = {/unread},
  annotation = {Last Modified: 2023-06-13T14:21:31.512+10:00\\
Read\_Status: New\\
Read\_Status\_Date: 2025-11-17T20:07:14.232Z},
  file = {/Users/andrew/Zotero/storage/5TT4L7TU/Evaluation - 2023 - Cognitive load theory Research that teachers really need to understand.pdf;/Users/andrew/Zotero/storage/UPTGIT3D/Evaluation - 2023 - Cognitive load theory Research that teachers really need to understand.pdf;/Users/andrew/Zotero/storage/HM29WUFB/cognitive-load-theory.html}
}

@article{cepedaDistributedPracticeVerbal2006,
  title = {Distributed Practice in Verbal Recall Tasks: {{A}} Review and Quantitative Synthesis},
  shorttitle = {Distributed Practice in Verbal Recall Tasks},
  author = {Cepeda, Nicholas J. and Pashler, Harold and Vul, Edward and Wixted, John T. and Rohrer, Doug},
  date = {2006-05},
  journaltitle = {Psychological Bulletin},
  shortjournal = {Psychol Bull},
  volume = {132},
  number = {3},
  eprint = {16719566},
  eprinttype = {pubmed},
  pages = {354--380},
  issn = {0033-2909},
  doi = {10.1037/0033-2909.132.3.354},
  abstract = {The authors performed a meta-analysis of the distributed practice effect to illuminate the effects of temporal variables that have been neglected in previous reviews. This review found 839 assessments of distributed practice in 317 experiments located in 184 articles. Effects of spacing (consecutive massed presentations vs. spaced learning episodes) and lag (less spaced vs. more spaced learning episodes) were examined, as were expanding interstudy interval (ISI) effects. Analyses suggest that ISI and retention interval operate jointly to affect final-test retention; specifically, the ISI producing maximal retention increased as retention interval increased. Areas needing future research and theoretical implications are discussed.},
  langid = {english},
  keywords = {/unread,Humans,Mental Recall,Practice Psychological,Verbal Behavior},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T21:47:35.240Z},
  file = {/Users/andrew/Zotero/storage/NLEATCU5/Cepeda et al. - 2006 - Distributed practice in verbal recall tasks A review and quantitative synthesis.pdf}
}

@article{chasePerceptionChess1973,
  title = {Perception in Chess},
  author = {Chase, William G. and Simon, Herbert A.},
  date = {1973},
  journaltitle = {Cognitive Psychology},
  volume = {4},
  number = {1},
  pages = {55--81},
  publisher = {Elsevier Science},
  location = {Netherlands},
  issn = {1095-5623},
  doi = {10.1016/0010-0285(73)90004-2},
  abstract = {Develops a technique for isolating and studying the perceptual structures that chess players perceive. Three chess players of varying strength-from master to novice-were confronted with 2 tasks: a perception task, where the player reproduces a chess position in plain view; and A. D. de Groot's 1965 short-term recall task, where the player reproduces a chess position after viewing it for 5 sec. The successive glances at the position in the perceptual task and long pauses in the memory task were used to segment the structures in the reconstruction protocol. The size and nature of these structures are analyzed as a function of chess skill. (17 ref.) (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {/unread,Chess,Cognitive Ability,Perception,Short Term Memory},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T11:14:54.398Z},
  file = {/Users/andrew/Zotero/storage/SXNWAHRP/1973-22240-001.html}
}

@article{chiElicitingSelfExplanationsImproves1994,
  title = {Eliciting {{Self-Explanations Improves Understanding}}},
  author = {Chi, Michelene T.H. and De Leeuw, Nicholas and Chiu, Mei-Hung and Lavancher, Christian},
  date = {1994},
  journaltitle = {Cognitive Science},
  volume = {18},
  number = {3},
  pages = {439--477},
  issn = {1551-6709},
  doi = {10.1207/s15516709cog1803_3},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1803_3},
  urldate = {2025-06-13},
  abstract = {Learning involves the integration of new information into existing knowledge. Generating explanations to oneself (self-explaining) facilitates that integration process. Previously, self-explanation has been shown to improve the acquisition of problem-solving skills when studying worked-out examples. This study extends that finding, showing that self-explanation can also be facilitative when it is explicitly promoted, in the context of learning declarative knowledge from an expository text. Without any extensive training, 14 eighth-grade students were merely asked to self-explain after reading each line of a passage on the human circulatory system. Ten students in the control group read the same text twice, but were not prompted to self-explain. All of the students were tested for their circulatory system knowledge before and after reading the text. The prompted group had a greater gain from the pretest to the posttest. Moreover, prompted students who generated a large number of self-explanations (the high explainers) learned with greater understanding than low explainers. Understanding was assessed by answering very complex questions and inducing the function of a component when it was only implicitly stated. Understanding was further captured by a mental model analysis of the self-explanation protocols. High explainers all achieved the correct mental model of the circulatory system, whereas many of the unprompted students as well as the low explainers did not. Three processing characteristics of self-explaining are considered as reasons for the gains in deeper understanding.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-13T10:18:02.223Z},
  file = {/Users/andrew/Zotero/storage/6EUN5NRT/Chi et al. - 1994 - Eliciting Self-Explanations Improves Understanding.pdf;/Users/andrew/Zotero/storage/3BAE645E/s15516709cog1803_3.html}
}

@article{chiriattiCaseHumanAI2024,
  title = {The Case for Human–{{AI}} Interaction as System 0 Thinking},
  author = {Chiriatti, Massimo and Ganapini, Marianna and Panai, Enrico and Ubiali, Mario and Riva, Giuseppe},
  date = {2024-10},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  volume = {8},
  number = {10},
  pages = {1829--1830},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-024-01995-5},
  url = {https://www.nature.com/articles/s41562-024-01995-5},
  urldate = {2025-03-14},
  langid = {english},
  keywords = {Human behaviour,Information systems and information technology,Information technology},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T14:12:17.072Z},
  file = {/Users/andrew/Zotero/storage/PPFT84YK/Chiriatti et al. - 2024 - The case for human–AI interaction as system 0 thinking.pdf}
}

@inproceedings{christieUncertaintypreservingDeepKnowledge2024,
  title = {Uncertainty-Preserving Deep Knowledge Tracing with State-Space Models},
  author = {Christie, S. Thomas and Cook, Carson and Rafferty, Anna N.},
  date = {2024},
  pages = {909--914},
  doi = {10.5281/zenodo.12729995},
  url = {https://educationaldatamining.org/edm2024/proceedings/2024.EDM-posters.108/index.html},
  urldate = {2025-06-07},
  eventtitle = {Proceedings of the 17th {{International Conference}} on {{Educational Data Mining}}},
  langid = {american},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T21:59:05.710Z},
  file = {/Users/andrew/Zotero/storage/AICCK3JS/Christie et al. - 2024 - Uncertainty-preserving deep knowledge tracing with state-space models.pdf}
}

@article{clarkExtendingMindsGenerative2025,
  title = {Extending {{Minds}} with {{Generative AI}}},
  author = {Clark, Andy},
  date = {2025-05-19},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {16},
  number = {1},
  pages = {4627},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-025-59906-9},
  url = {https://www.nature.com/articles/s41467-025-59906-9},
  urldate = {2025-05-24},
  abstract = {As human-AI collaborations become the norm, we should remind ourselves that it is our basic nature to build hybrid thinking systems – ones that fluidly incorporate non-biological resources. Recognizing this invites us to change the way we think about both the threats and promises of the coming age.},
  langid = {english},
  keywords = {/unread,Intelligence,Interdisciplinary studies},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-19T14:38:36.990Z},
  file = {/Users/andrew/Zotero/storage/UCMY9ZWJ/Clark - 2025 - Extending Minds with Generative AI.pdf}
}

@article{cooperEffectsSchemaAcquisition1987,
  title = {Effects of Schema Acquisition and Rule Automation on Mathematical Problem-Solving Transfer},
  author = {Cooper, Graham and Sweller, John},
  date = {1987},
  journaltitle = {Journal of Educational Psychology},
  volume = {79},
  number = {4},
  pages = {347--362},
  publisher = {American Psychological Association},
  location = {US},
  issn = {1939-2176},
  doi = {10.1037/0022-0663.79.4.347},
  abstract = {Hypothesized that schema acquisition would precede rule automation and that it would have a strong effect on problems similar to initial acquisition problems. We further hypothesized that rule automation would have its primary effect on transfer and that the use of worked examples could facilitate both transfer and performance on similar problems. Experiments 1 and 2 contained simple algebra transformation problems involving the changing of the subject of an equation. The results indicated that subjects whose training included a heavy emphasis on worked examples or an extended acquisition period were better able to solve both similar and transfer problems than were those subjects trained with conventional problems. In Experiment 3, the use of verbal protocols gave some support to the hypotheses. Experiment 4, using algebra word problems, yielded data supporting the hypotheses. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  keywords = {/unread,High School Students,Junior High School Students,Mathematics Education,Problem Solving,Schema,Teaching Methods,Transfer (Learning)},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-11-19T02:13:44.673Z},
  file = {/Users/andrew/Zotero/storage/SZ7T3RXC/1988-21573-001.html}
}

@article{corbettKnowledgeTracingModeling1994,
  title = {Knowledge Tracing: {{Modeling}} the Acquisition of Procedural Knowledge},
  shorttitle = {Knowledge Tracing},
  author = {Corbett, Albert T. and Anderson, John R.},
  date = {1994-12-01},
  journaltitle = {User Modeling and User-Adapted Interaction},
  shortjournal = {User Model User-Adap Inter},
  volume = {4},
  number = {4},
  pages = {253--278},
  issn = {1573-1391},
  doi = {10.1007/BF01099821},
  url = {https://doi.org/10.1007/BF01099821},
  urldate = {2025-06-11},
  abstract = {This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.},
  langid = {english},
  keywords = {/unread,Computer Science Logic and Foundations of Programming,empirical validity,individual differences,Instructional Theory,intelligent tutoring systems,learning,Learning and Instruction,Learning Process,Learning Theory,mastery learning,Models of Computation,procedural knowledge,Student modeling},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T22:18:57.995Z},
  file = {/Users/andrew/Zotero/storage/5PJQ2BFN/Corbett and Anderson - 1994 - Knowledge tracing Modeling the acquisition of procedural knowledge.pdf}
}

@online{cuiEffectsGenerativeAI2024,
  type = {SSRN Scholarly Paper},
  title = {The {{Effects}} of {{Generative AI}} on {{High Skilled Work}}: {{Evidence}} from {{Three Field Experiments}} with {{Software Developers}}},
  shorttitle = {The {{Effects}} of {{Generative AI}} on {{High Skilled Work}}},
  author = {Cui, Zheyuan (Kevin) and Demirer, Mert and Jaffe, Sonia and Musolff, Leon and Peng, Sida and Salz, Tobias},
  date = {2024-09-03},
  number = {4945566},
  eprint = {4945566},
  eprinttype = {Social Science Research Network},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4945566},
  url = {https://papers.ssrn.com/abstract=4945566},
  urldate = {2024-11-09},
  abstract = {This study evaluates the impact of generative AI on software developer productivity by analyzing data from three randomized controlled trials conducted at Microsoft, Accenture, and an anonymous Fortune 100 electronics manufacturing company. These field experiments, which were run by the companies as part of their ordinary course of business, provided a randomly selected subset of developers with access to GitHub Copilot, an AI-based coding assistant that suggests intelligent code completions. Though each separate experiment is noisy, combined across all three experiments and 4,867 software developers, our analysis reveals a 26.08\% increase (SE: 10.3\%) in the number of completed tasks among developers using the AI tool. Notably, less experienced developers showed higher adoption rates and greater productivity gains.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {/unread,Leon Musolff,Mert Demirer,Sida Peng,Sonia Jaffe,SSRN,The Effects of Generative AI on High Skilled Work: Evidence from Three Field Experiments with Software Developers,Tobias Salz,Zheyuan (Kevin) Cui},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-17T20:01:37.028Z},
  file = {/Users/andrew/Zotero/storage/7SP899NY/Cui et al. - 2024 - The Effects of Generative AI on High Skilled Work Evidence from Three Field Experiments with Softwa.pdf}
}

@article{dahmaniHabitualUseGPS2020,
  title = {Habitual Use of {{GPS}} Negatively Impacts Spatial Memory during Self-Guided Navigation},
  author = {Dahmani, Louisa and Bohbot, Véronique D.},
  date = {2020-04-14},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {10},
  number = {1},
  pages = {6310},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-62877-0},
  url = {https://www.nature.com/articles/s41598-020-62877-0},
  urldate = {2025-12-10},
  abstract = {Global Positioning System (GPS) navigation devices and applications have become ubiquitous over the last decade. However, it is unclear whether using GPS affects our own internal navigation system, or spatial memory, which critically relies on the hippocampus. We assessed the lifetime GPS experience of 50 regular drivers as well as various facets of spatial memory, including spatial memory strategy use, cognitive mapping, and landmark encoding using virtual navigation tasks. We first present cross-sectional results that show that people with greater lifetime GPS experience have worse spatial memory during self-guided navigation, i.e. when they are required to navigate without GPS. In a follow-up session, 13 participants were retested three years after initial testing. Although the longitudinal sample was small, we observed an important effect of GPS use over time, whereby greater GPS use since initial testing was associated with a steeper decline in hippocampal-dependent spatial memory. Importantly, we found that those who used GPS more did not do so because they felt they had a poor sense of direction, suggesting that extensive GPS use led to a decline in spatial memory rather than the other way around. These findings are significant in the context of society’s increasing reliance on GPS.},
  langid = {english},
  keywords = {/unread,Human behaviour,Spatial memory},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T13:42:04.995Z},
  file = {/Users/andrew/Zotero/storage/HGLQHTF5/Dahmani and Bohbot - 2020 - Habitual use of GPS negatively impacts spatial memory during self-guided navigation.pdf}
}

@article{daiKnowledgeTracingReview2021,
  title = {Knowledge {{Tracing}}: {{A Review}} of {{Available Technologies}}},
  shorttitle = {Knowledge {{Tracing}}},
  author = {Dai, Miao and Hung, Jui-Long and Du, Xu and Tang, Hengtao and Li, Hao},
  date = {2021},
  journaltitle = {Journal of Educational Technology Development and Exchange},
  shortjournal = {JETDE},
  volume = {14},
  number = {2},
  pages = {1--20},
  issn = {19418035},
  doi = {10.18785/jetde.1402.01},
  url = {https://aquila.usm.edu/jetde/vol14/iss2/1/},
  urldate = {2024-11-16},
  abstract = {As a student modeling technique, knowledge tracing is widely used by various intelligent tutoring systems to infer and trace the individual’s knowledge state during the learning process. In recent years, various models were proposed to get accurate and easy-to-interpret results. To make sense of the wide Knowledge tracing (KT) modeling landscape, this paper conducts a systematic review to provide a detailed and nuanced discussion of relevant KT techniques from the perspective of assumptions, data, and algorithms. The results show that most existing KT models consider only a fragment of the assumptions that relate to the knowledge components within items and student’s cognitive process. Almost all types of KT models take “quize data” as input, although it is insufficient to reflect a clear picture of students’ learning process. Dynamic Bayesian network, logistic regression and deep learning are the main algorithms used by various knowledge tracing models. Some open issues are identified based on the analytics of the reviewed works and discussed potential future research directions.},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.461Z},
  file = {/Users/andrew/Zotero/storage/23T4EGF6/Dai et al. - 2021 - Knowledge Tracing A Review of Available Technologies.pdf}
}

@article{dellacquaNavigatingJaggedTechnological2023,
  title = {Navigating the {{Jagged Technological Frontier}}: {{Field Experimental Evidence}} of the {{Effects}} of {{AI}} on {{Knowledge Worker Productivity}} and {{Quality}}},
  shorttitle = {Navigating the {{Jagged Technological Frontier}}},
  author = {Dell'Acqua, Fabrizio and McFowland, Edward and Mollick, Ethan R. and Lifshitz-Assaf, Hila and Kellogg, Katherine and Rajendran, Saran and Krayer, Lisa and Candelon, François and Lakhani, Karim R.},
  date = {2023},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.4573321},
  url = {https://www.ssrn.com/abstract=4573321},
  urldate = {2024-11-09},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-17T20:01:20.564Z},
  file = {/Users/andrew/Zotero/storage/7U2THPQG/Dell'Acqua et al. - 2023 - Navigating the Jagged Technological Frontier Field Experimental Evidence of the Effects of AI on Kn.pdf}
}

@article{dengDoesChatGPTEnhance2025,
  title = {Does {{ChatGPT}} Enhance Student Learning? {{A}} Systematic Review and Meta-Analysis of Experimental Studies},
  shorttitle = {Does {{ChatGPT}} Enhance Student Learning?},
  author = {Deng, Ruiqi and Jiang, Maoli and Yu, Xinlu and Lu, Yuyan and Liu, Shasha},
  date = {2025-04-01},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {227},
  pages = {105224},
  issn = {0360-1315},
  doi = {10.1016/j.compedu.2024.105224},
  url = {https://www.sciencedirect.com/science/article/pii/S0360131524002380},
  urldate = {2025-06-09},
  abstract = {Chat Generative Pre-Trained Transformer (ChatGPT) has generated excitement and concern in education. While cross-sectional studies have highlighted correlations between ChatGPT use and learning performance, they fall short of establishing causality. This review examines experimental studies on ChatGPT's impact on student learning to address this gap. A comprehensive search across five databases identified 69 articles published between 2022 and 2024 for analysis. The findings reveal that ChatGPT interventions are predominantly implemented at the university level, cover various subject areas focusing on language education, are integrated into classroom environments as part of regular educational practices, and primarily involve direct student use of ChatGPT. Overall, ChatGPT improves academic performance, affective-motivational states, and higher-order thinking propensities; it reduces mental effort and has no significant effect on self-efficacy. However, methodological limitations, such as the lack of power analysis and concerns regarding post-intervention assessments, warrant cautious interpretation of results. This review presents four propositions from the findings: (1) distinguish between the quality of ChatGPT outputs and the positive effects of interventions on academic performance by shifting from well-defined problems in post-intervention assessments to more complex, project-based assessments that require skill demonstration, adopting proctored assessments, or incorporating metrics such as originality alongside quality; (2) evaluate long-term impacts to determine whether the positive effects on affective-motivational states are sustained or merely owing to novelty effect; (3) prioritise objective measures to complement subjective assessments of higher-order thinking; and (4) use power analysis to determine adequate sample sizes to avoid Type II errors and provide reliable effect size estimates. This review provides valuable insights for researchers, instructors, and policymakers evaluating the effectiveness of generative AI integration in educational practice.},
  keywords = {Elementary education,Improve classroom teaching,Post-secondary education,Secondary education,Teaching/learning strategies},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:32:15.269Z},
  file = {/Users/andrew/Zotero/storage/MH7FL8LR/S0360131524002380.html}
}

@incollection{dennenCognitiveApprenticeshipEducational2004,
  title = {Cognitive {{Apprenticeship}} in {{Educational Practice}}: {{Research}} on {{Scaffolding}}, {{Modeling}}, {{Mentoring}}, and {{Coaching}} as {{Instructional Strategies}}},
  shorttitle = {Cognitive {{Apprenticeship}} in {{Educational Practice}}},
  booktitle = {Handbook of {{Research}} on {{Educational Communications}} and {{Technology}}},
  author = {Dennen, Vanessa Paz},
  date = {2004},
  edition = {2},
  publisher = {Routledge},
  abstract = {Apprenticeship is an inherently social learning method with a long history of helping novices become experts in fields as diverse as midwifery, construction, and law. At the center of apprenticeship is the concept of more experienced people assisting less experienced ones, providing structure and examples to support the attainment of goals. Traditionally apprenticeship has been associated with learning in the context of becoming skilled in a trade or craft-a task that typically requires both the acquisition of knowledge, concepts, and perhaps psychomotor skills and the development of the ability to apply the knowledge and skills in a context-appropriate manner-and far predates formal schooling as it is known today. In many nonindustrializednations apprenticeship remains thepredominantmethodof teaching and learning. However, the overall concept of learning from experts through social interactions is not one that should be relegated to vocational and trade-based training while K-12 and higher educational institutions seek to prepare students for operating in an information-based society. Apprenticeship as a method of teaching and learning is just as relevant within the cognitive and metacognitive domain as it is in the psychomotor domain.},
  isbn = {978-1-4106-0951-9},
  pagetotal = {16},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-13T10:19:44.106Z}
}

@article{deonovicLearningMeetsAssessment2018,
  title = {Learning Meets Assessment: {{On}} the Relation between Item Response Theory and {{Bayesian}} Knowledge Tracing},
  shorttitle = {Learning Meets Assessment},
  author = {Deonovic, Benjamin and Yudelson, Michael and Bolsinova, Maria and Attali, Meirav and Maris, Gunter},
  date = {2018-10},
  journaltitle = {Behaviormetrika},
  shortjournal = {Behaviormetrika},
  volume = {45},
  number = {2},
  pages = {457--474},
  issn = {0385-7417, 1349-6964},
  doi = {10.1007/s41237-018-0070-z},
  url = {http://link.springer.com/10.1007/s41237-018-0070-z},
  urldate = {2025-06-11},
  abstract = {Few models have been more ubiquitous in their respective fields than Bayesian knowledge tracing and item response theory. Both these models were developed to analyze data on learners. However, the study designs that these models are designed for differ; Bayesian knowledge tracing is designed to analyze longitudinal data while item response theory is built for cross-sectional data. This paper illustrates a fundamental connection between these two models. Specifically, the stationary distribution of the latent variable and the observed response variable in Bayesian knowledge Tracing are related to an item response theory model. This connection between these two models highlights a key missing component: the role of education in these models. A research agenda is outlined which answers how to move forward with modeling learner data.},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T22:30:06.180Z},
  file = {/Users/andrew/Zotero/storage/AYQXN52N/Deonovic et al. - 2018 - Learning meets assessment On the relation between item response theory and Bayesian knowledge traci.pdf}
}

@report{digiustoMultipleChoiceAufgabenTeachingGuide2018,
  title = {Multiple-Choice-Aufgaben : Teaching Guide for Higher \& Professional Education},
  shorttitle = {Multiple-Choice-Aufgaben},
  author = {Di Giusto, Flavio and Müller Werder, Claude and Reichmuth, Andrea},
  date = {2018},
  institution = {ZHAW Zürcher Hochschule für Angewandte Wissenschaften},
  doi = {10.21256/zhaw-3404},
  url = {https://digitalcollection.zhaw.ch/handle/11475/14508},
  urldate = {2025-03-14},
  abstract = {Multiple-Choice-Aufgaben sind an Hochschulen ebenso verbreitet wie umstritten. Sie gelten als ökonomisch, scheinen aber den Fokus zu stark auf Wissensabfragen zu richten. Dass es auch differenzierter geht, zeigt der neue Teaching Guide for Higher \& Professional Education «Multiple-Choice-Aufgaben» des Zentrums für Innovative Didaktik der ZHAW School of Management and Law. Die Publikation liefert einen Überblick zu den diversen MC-Aufgabentypen und gibt praktische Hinweise zur Eignung sowie Gestaltung von MC-Items. Eine Vorlage und Checkliste zur Erstellung von MC-Aufgaben runden das Angebot des Teaching Guides ab.},
  langid = {ngerman},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T16:38:21.247Z},
  file = {/Users/andrew/Zotero/storage/UL32IH7Q/Di Giusto et al. - 2018 - Multiple-Choice-Aufgaben  Teaching Guide for Higher & Professional Education.pdf}
}

@online{DissociatingLanguageThought,
  title = {Dissociating Language and Thought in Large Language Models},
  url = {https://ar5iv.labs.arxiv.org/html/2301.06627},
  urldate = {2025-06-09},
  abstract = {Large language models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their linguistic and cognitive capabilities remain split. Here, we evaluate LLMs using a distincti…},
  langid = {english},
  organization = {ar5iv},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:16:05.672Z},
  file = {/Users/andrew/Zotero/storage/36S2PS8B/2301.html}
}

@article{duHumanlikeObjectConcept2025,
  title = {Human-like Object Concept Representations Emerge Naturally in Multimodal Large Language Models},
  author = {Du, Changde and Fu, Kaicheng and Wen, Bincheng and Sun, Yi and Peng, Jie and Wei, Wei and Gao, Ying and Wang, Shengpei and Zhang, Chuncheng and Li, Jinpeng and Qiu, Shuang and Chang, Le and He, Huiguang},
  date = {2025-06-09},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  pages = {1--16},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-025-01049-z},
  url = {https://www.nature.com/articles/s42256-025-01049-z},
  urldate = {2025-06-09},
  abstract = {Understanding how humans conceptualize and categorize natural objects offers critical insights into perception and cognition. With the advent of large language models (LLMs), a key question arises: can these models develop human-like object representations from linguistic and multimodal data? Here we combined behavioural and neuroimaging analyses to explore the relationship between object concept representations in LLMs and human cognition. We collected 4.7 million triplet judgements from LLMs and multimodal LLMs to derive low-dimensional embeddings that capture the similarity structure of 1,854 natural objects. The resulting 66-dimensional embeddings were stable, predictive and exhibited semantic clustering similar to human mental representations. Remarkably, the dimensions underlying these embeddings were interpretable, suggesting that LLMs and multimodal LLMs develop human-like conceptual representations of objects. Further analysis showed strong alignment between model embeddings and neural activity patterns in brain regions such as the extrastriate body area, parahippocampal place area, retrosplenial cortex and fusiform face area. This provides compelling evidence that the object representations in LLMs, although not identical to human ones, share fundamental similarities that reflect key aspects of human conceptual knowledge. Our findings advance the understanding of machine intelligence and inform the development of more human-like artificial cognitive systems.},
  langid = {english},
  keywords = {Computational science,Human behaviour,Learning algorithms,Neural encoding},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T18:58:10.142Z},
  file = {/Users/andrew/Zotero/storage/6XF8AW79/Du et al. - 2025 - Human-like object concept representations emerge naturally in multimodal large language models.pdf}
}

@article{dunloskyImprovingStudentsLearning2013,
  title = {Improving {{Students}}' {{Learning With Effective Learning Techniques}}: {{Promising Directions From Cognitive}} and {{Educational Psychology}}},
  shorttitle = {Improving {{Students}}' {{Learning With Effective Learning Techniques}}},
  author = {Dunlosky, John and Rawson, Katherine A. and Marsh, Elizabeth J. and Nathan, Mitchell J. and Willingham, Daniel T.},
  date = {2013-01},
  journaltitle = {Psychological Science in the Public Interest: A Journal of the American Psychological Society},
  shortjournal = {Psychol Sci Public Interest},
  volume = {14},
  number = {1},
  eprint = {26173288},
  eprinttype = {pubmed},
  pages = {4--58},
  issn = {1529-1006},
  doi = {10.1177/1529100612453266},
  abstract = {Many students are being left behind by an educational system that some people believe is in crisis. Improving educational outcomes will require efforts on many fronts, but a central premise of this monograph is that one part of a solution involves helping students to better regulate their learning through the use of effective learning techniques. Fortunately, cognitive and educational psychologists have been developing and evaluating easy-to-use learning techniques that could help students achieve their learning goals. In this monograph, we discuss 10 learning techniques in detail and offer recommendations about their relative utility. We selected techniques that were expected to be relatively easy to use and hence could be adopted by many students. Also, some techniques (e.g., highlighting and rereading) were selected because students report relying heavily on them, which makes it especially important to examine how well they work. The techniques include elaborative interrogation, self-explanation, summarization, highlighting (or underlining), the keyword mnemonic, imagery use for text learning, rereading, practice testing, distributed practice, and interleaved practice. To offer recommendations about the relative utility of these techniques, we evaluated whether their benefits generalize across four categories of variables: learning conditions, student characteristics, materials, and criterion tasks. Learning conditions include aspects of the learning environment in which the technique is implemented, such as whether a student studies alone or with a group. Student characteristics include variables such as age, ability, and level of prior knowledge. Materials vary from simple concepts to mathematical problems to complicated science texts. Criterion tasks include different outcome measures that are relevant to student achievement, such as those tapping memory, problem solving, and comprehension. We attempted to provide thorough reviews for each technique, so this monograph is rather lengthy. However, we also wrote the monograph in a modular fashion, so it is easy to use. In particular, each review is divided into the following sections: General description of the technique and why it should work How general are the effects of this technique? {$\quad$}2a. Learning conditions {$\quad$}2b. Student characteristics {$\quad$}2c. Materials {$\quad$}2d. Criterion tasks Effects in representative educational contexts Issues for implementation Overall assessment The review for each technique can be read independently of the others, and particular variables of interest can be easily compared across techniques. To foreshadow our final recommendations, the techniques vary widely with respect to their generalizability and promise for improving student learning. Practice testing and distributed practice received high utility assessments because they benefit learners of different ages and abilities and have been shown to boost students' performance across many criterion tasks and even in educational contexts. Elaborative interrogation, self-explanation, and interleaved practice received moderate utility assessments. The benefits of these techniques do generalize across some variables, yet despite their promise, they fell short of a high utility assessment because the evidence for their efficacy is limited. For instance, elaborative interrogation and self-explanation have not been adequately evaluated in educational contexts, and the benefits of interleaving have just begun to be systematically explored, so the ultimate effectiveness of these techniques is currently unknown. Nevertheless, the techniques that received moderate-utility ratings show enough promise for us to recommend their use in appropriate situations, which we describe in detail within the review of each technique. Five techniques received a low utility assessment: summarization, highlighting, the keyword mnemonic, imagery use for text learning, and rereading. These techniques were rated as low utility for numerous reasons. Summarization and imagery use for text learning have been shown to help some students on some criterion tasks, yet the conditions under which these techniques produce benefits are limited, and much research is still needed to fully explore their overall effectiveness. The keyword mnemonic is difficult to implement in some contexts, and it appears to benefit students for a limited number of materials and for short retention intervals. Most students report rereading and highlighting, yet these techniques do not consistently boost students' performance, so other techniques should be used in their place (e.g., practice testing instead of rereading). Our hope is that this monograph will foster improvements in student learning, not only by showcasing which learning techniques are likely to have the most generalizable effects but also by encouraging researchers to continue investigating the most promising techniques. Accordingly, in our closing remarks, we discuss some issues for how these techniques could be implemented by teachers and students, and we highlight directions for future research.},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T20:12:24.601Z}
}

@software{elsayedMohmdelsayedStreamingdrl2024,
  title = {Mohmdelsayed/Streaming-Drl},
  author = {Elsayed, Mohamed},
  date = {2024-11-25T09:17:53Z},
  origdate = {2024-11-10T20:59:48Z},
  url = {https://github.com/mohmdelsayed/streaming-drl},
  urldate = {2024-11-25},
  abstract = {Deep reinforcement learning without experience replay, target networks, or batch updates.},
  keywords = {deep-learning,deep-reinforcement-learning,machine-learning,neural-networks,reinforcement-learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.461Z},
  file = {/Users/andrew/Zotero/storage/7W8CUBMN/101_Deep_Reinforcement_Learnin.pdf}
}

@online{faveroAITutorsEmpower2025,
  title = {Do {{AI}} Tutors Empower or Enslave Learners? {{Toward}} a Critical Use of {{AI}} in Education},
  shorttitle = {Do {{AI}} Tutors Empower or Enslave Learners?},
  author = {Favero, Lucile and Pérez-Ortiz, Juan-Antonio and Käser, Tanja and Oliver, Nuria},
  date = {2025-07-09},
  eprint = {2507.06878},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2507.06878},
  url = {http://arxiv.org/abs/2507.06878},
  urldate = {2025-10-09},
  abstract = {The increasing integration of AI tools in education presents both opportunities and challenges, particularly regarding the development of the students' critical thinking skills. This position paper argues that while AI can support learning, its unchecked use may lead to cognitive atrophy, loss of agency, emotional risks, and ethical concerns, ultimately undermining the core goals of education. Drawing on cognitive science and pedagogy, the paper explores how over-reliance on AI can disrupt meaningful learning, foster dependency and conformity, undermine the students' self-efficacy, academic integrity, and well-being, and raise concerns about questionable privacy practices. It also highlights the importance of considering the students' perspectives and proposes actionable strategies to ensure that AI serves as a meaningful support rather than a cognitive shortcut. The paper advocates for an intentional, transparent, and critically informed use of AI that empowers rather than diminishes the learner.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-10-09T14:54:04.615Z},
  file = {/Users/andrew/Zotero/storage/AEEETMX9/Favero et al. - 2025 - Do AI tutors empower or enslave learners Toward a critical use of AI in education.pdf;/Users/andrew/Zotero/storage/LB2VYYLT/2507.html}
}

@online{faveroEnhancingCriticalThinking2024,
  title = {Enhancing {{Critical Thinking}} in {{Education}} by Means of a {{Socratic Chatbot}}},
  author = {Favero, Lucile and Pérez-Ortiz, Juan Antonio and Käser, Tanja and Oliver, Nuria},
  date = {2024-09-09},
  eprint = {2409.05511},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.05511},
  url = {http://arxiv.org/abs/2409.05511},
  urldate = {2025-10-09},
  abstract = {While large language models (LLMs) are increasingly playing a pivotal role in education by providing instantaneous, adaptive responses, their potential to promote critical thinking remains understudied. In this paper, we fill such a gap and present an innovative educational chatbot designed to foster critical thinking through Socratic questioning. Unlike traditional intelligent tutoring systems, including educational chatbots, that tend to offer direct answers, the proposed Socratic tutor encourages students to explore various perspectives and engage in self-reflection by posing structured, thought-provoking questions. Our Socratic questioning is implemented by fine and prompt-tuning the open-source pretrained LLM with a specialized dataset that stimulates critical thinking and offers multiple viewpoints. In an effort to democratize access and to protect the students' privacy, the proposed tutor is based on small LLMs (Llama2 7B and 13B-parameter models) that are able to run locally on off-the-shelf hardware. We validate our approach in a battery of experiments consisting of interactions between a simulated student and the chatbot to evaluate its effectiveness in enhancing critical thinking skills. Results indicate that the Socratic tutor supports the development of reflection and critical thinking significantly better than standard chatbots. Our approach opens the door for improving educational outcomes by cultivating active learning and encouraging intellectual autonomy.},
  pubstate = {prepublished},
  keywords = {Computer Science - Human-Computer Interaction},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-10-09T14:52:49.432Z},
  file = {/Users/andrew/Zotero/storage/QBBWGG2L/Favero et al. - 2024 - Enhancing Critical Thinking in Education by means of a Socratic Chatbot.pdf;/Users/andrew/Zotero/storage/D84VLLFD/2409.html}
}

@article{filipovicKuenstlicheIntelligenzGrundlagen2025,
  title = {Künstliche Intelligenz: Grundlagen für das Handeln in der Hochschullehre},
  author = {Filipović, Alexander and Burchardt, Aljoscha and Hirsbrunner, Simon and Michel, Antje and Puzio, Anna and Reinmann, Gabi and Schaumann, Philipp and Schroll, Anja-Lisa and Wan, Martin and Wilder, Nicolaus},
  date = {2025},
  journaltitle = {Künstliche Intelligenz},
  langid = {ngerman},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-23T19:33:23.989Z},
  file = {/Users/andrew/Zotero/storage/4N8A54DN/Filipović et al. - 2025 - Künstliche Intelligenz Grundlagen für das Handeln in der Hochschullehre.pdf}
}

@article{fleckensteinTeachersSpotAI2024,
  title = {Do Teachers Spot {{AI}}? {{Evaluating}} the Detectability of {{AI-generated}} Texts among Student Essays},
  shorttitle = {Do Teachers Spot {{AI}}?},
  author = {Fleckenstein, Johanna and Meyer, Jennifer and Jansen, Thorben and Keller, Stefan D. and Köller, Olaf and Möller, Jens},
  date = {2024-06},
  journaltitle = {Computers and Education: Artificial Intelligence},
  shortjournal = {Computers and Education: Artificial Intelligence},
  volume = {6},
  pages = {100209},
  issn = {2666920X},
  doi = {10.1016/j.caeai.2024.100209},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2666920X24000109},
  urldate = {2024-05-27},
  abstract = {The potential application of generative artificial intelligence (AI) in schools and universities poses great chal­ lenges, especially for the assessment of students’ texts. Previous research has shown that people generally have difficulty distinguishing AI-generated from human-written texts; however, the ability of teachers to identify an AI-generated text among student essays has not yet been investigated. Here we show in two experimental studies that novice (N = 89) and experienced teachers (N = 200) could not identify texts generated by ChatGPT among student-written texts. However, there are some indications that more experienced teachers made more differ­ entiated and more accurate judgments. Furthermore, both groups were overconfident in their judgments. Effects of real and assumed source on quality assessment were heterogeneous. Our findings demonstrate that with relatively little prompting, current AI can generate texts that are not detectable for teachers, which poses a challenge to schools and universities in grading student essays. Our study provides empirical evidence for the current debate regarding exam strategies in schools and universities in light of the latest technological developments.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-17T16:26:17.282Z},
  file = {/Users/andrew/Zotero/storage/V577EGIV/Fleckenstein et al. - 2024 - Do teachers spot AI Evaluating the detectability .pdf}
}

@article{foxStudentPerspectivesIndependent2019,
  title = {Student Perspectives of Independent and Collaborative Learning in a Flipped Foundational Engineering Course},
  author = {Fox, Wendy H. and Docherty, Paul David},
  date = {2019-01-16},
  journaltitle = {Australasian Journal of Educational Technology},
  volume = {35},
  number = {5},
  pages = {79--94},
  issn = {1449-5554},
  doi = {10.14742/ajet.3804},
  url = {https://ajet.org.au/index.php/AJET/article/view/3804},
  urldate = {2025-03-14},
  abstract = {Flipped teaching and learning approaches are being increasingly used in higher education. Some advantages associated with the approach include providing opportunity for self-directed learning and enhanced collaboration between students. In this study, an implementation of a flipped approach in a first year foundational engineering dynamics course was researched to investigate student views on independent and collaborative learning inherent in flipped learning. Eighteen undergraduate students (11 male and 7 female) participated in this qualitative study. The flipped part of the course was designed to include self-paced independent learning and in-class learning, with opportunities to collaborate, ask questions, and work on examples. Data were collected using semi-structured interviews. The results of the study indicated that students universally enjoyed learning independently and appreciated the increased collaboration induced by the flipped approach. The flexibility of the approach enabled a range of approaches to independent learning and collaboration, and students were able to find learning styles that suited them. This article concludes with a range of recommendations for practice to further support independent and collaborative learning with the use of flipped approaches.},
  issue = {5},
  langid = {english},
  keywords = {collaboration,engineering education,flipped classroom,higher education,independent learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T14:12:16.820Z},
  file = {/Users/andrew/Zotero/storage/GAESULKR/Fox and Docherty - 2019 - Student perspectives of independent and collaborative learning in a flipped foundational engineering.pdf}
}

@online{geyerZettelnPrompts2025,
  type = {Substack newsletter},
  title = {Von {{Zetteln}} Zu {{Prompts}}},
  author = {Geyer, Barbara},
  date = {2025-07-14},
  url = {https://barbarageyer.substack.com/p/von-zetteln-zu-prompts},
  urldate = {2025-08-17},
  abstract = {Warum mein Zettelkasten scheiterte – und wie KI mein Lernen revolutionierte},
  organization = {KI in Lehre und Weiterbildung},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-17T17:02:42.589Z},
  file = {/Users/andrew/Zotero/storage/8ZP96WN2/von-zetteln-zu-prompts.html}
}

@book{grootThoughtChoiceChess1978,
  title = {Thought and {{Choice}} in {{Chess}}},
  author = {Groot, Adriaan D. De and family=Groot, given=Adrianus Dingeman, prefix=de, useprefix=false},
  date = {1978},
  eprint = {EI4gr42NwDQC},
  eprinttype = {googlebooks},
  publisher = {Walter de Gruyter},
  abstract = {No detailed description available for "Thought and Choice in Chess".},
  isbn = {978-90-279-7914-8},
  langid = {english},
  pagetotal = {492},
  keywords = {/unread,Games & Activities / Chess,Psychology / General,Reference / General,Reference / Handbooks & Manuals,Science / General,Social Science / Sociology / General},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T14:30:06.385Z}
}

@online{guMambaLinearTimeSequence2024,
  title = {Mamba: {{Linear-Time Sequence Modeling}} with {{Selective State Spaces}}},
  shorttitle = {Mamba},
  author = {Gu, Albert and Dao, Tri},
  date = {2024-05-31},
  eprint = {2312.00752},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.00752},
  url = {http://arxiv.org/abs/2312.00752},
  urldate = {2024-09-13},
  abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simplified end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5\$\textbackslash times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/DS2Z9SC5/Gu and Dao - 2024 - Mamba Linear-Time Sequence Modeling with Selective State Spaces.pdf;/Users/andrew/Zotero/storage/8ZSN2U3P/2312.html}
}

@article{hattiePowerFeedback2007,
  title = {The {{Power}} of {{Feedback}}},
  author = {Hattie, John and Timperley, Helen},
  date = {2007-03-01},
  journaltitle = {Review of Educational Research},
  volume = {77},
  number = {1},
  pages = {81--112},
  publisher = {American Educational Research Association},
  issn = {0034-6543},
  doi = {10.3102/003465430298487},
  url = {https://doi.org/10.3102/003465430298487},
  urldate = {2025-06-12},
  abstract = {Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T21:57:38.417Z}
}

@online{HowCanEducators,
  title = {How Can Educators Respond to Students Presenting {{AI-generated}} Content as Their Own? | {{OpenAI Help Center}}},
  shorttitle = {How Can Educators Respond to Students Presenting {{AI-generated}} Content as Their Own?},
  url = {https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own},
  urldate = {2025-03-14},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T14:12:16.963Z},
  file = {/Users/andrew/Zotero/storage/GYZUT5CG/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own.html}
}

@article{imundoExpertThinkingGenerative2024a,
  title = {Expert Thinking with Generative Chatbots},
  author = {Imundo, Megan N. and Watanabe, Micah and Potter, Andrew H. and Gong, Jiachen and Arner, Tracy and McNamara, Danielle S.},
  date = {2024},
  journaltitle = {Journal of Applied Research in Memory and Cognition},
  volume = {13},
  number = {4},
  pages = {465--484},
  publisher = {Educational Publishing Foundation},
  location = {US},
  issn = {2211-369X},
  doi = {10.1037/mac0000199},
  abstract = {Artificial intelligence (AI)-driven generative chatbots can produce large quantities of text instantly across a range of domains, using authoritative tones that create the perception of expertise. This critical synthesis compares artificial expertise and human expertise and examines ways in which generative chatbots can support cognition using an expert thinking framework. Findings indicate that generative chatbots may support experts’ cognition as a collaborator or to offload lower level tasks. Moreover, generative chatbots are a promising training tool in developing future experts in part because they can provide learning models and practice opportunities. The use of generative chatbots to offload lower level tasks, however, may harm expert development by disrupting knowledge communities. Finally, a lack of domain knowledge in nonexpert users may limit the effectiveness of generative chatbots in supporting higher level cognition and agency. Overall, existing research suggests that the potential for generative chatbots to support users’ cognition depends on a user’s level of expertise. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  keywords = {Chatbots,Experience Level,Generative Artificial Intelligence,Practice,Problem Solving,Thinking},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-25T19:24:01.036Z},
  file = {/Users/andrew/Zotero/storage/8BCFNRC5/doiLanding.html}
}

@article{joseOutsourcingCognitionPsychological2025,
  title = {Outsourcing Cognition: The Psychological Costs of {{AI-era}} Convenience},
  shorttitle = {Outsourcing Cognition},
  author = {Jose, Binny and Joseph, Deepak and Mohan, Visakh and Alexander, Elizabeth and Varghese, Subi K. and Roy, Abhijith},
  date = {2025-12-05},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {16},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2025.1645237},
  url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1645237/full},
  urldate = {2025-12-10},
  abstract = {While AI technology is increasingly integrated into all aspects of thinking, learning, and decisionmaking, the technologies supporting those processes are going from simply enhancing our cognitive abilities to changing them. Such technologies as generative writing, searching for information on the Internet, voice recognition systems, and adaptive tutoring systems; all have made possible unprecedented efficiency in doing so. However, the increasing use of such technology has raised questions about the relationship between the field of psychology and the impact of such technology. In particular, if the need to remember, to think about what we have done, or to engage in higher order thought is lessened by the use of AI technology, then are we creating a culture of convenience that reduces our ability to be resilient cognitively?This article examines the developing trend of \&quot;cognitive off-loading\&quot; through the use of AI technology, and the implications for the memory, attention, metacognition, and identity domains that collectively define cognitive autonomy. The approach of this article is integration; that combines current findings in cognitive offloading with existing psychological theories related to memory, metacognition and motivation. A systematic taxonomy of different forms of offloading is analyzed, distinguishing between assistive, substitutive, and disruptive forms of delegating tasks, and examining the psychological costs associated with each. This paper, as an Opinion Article aims to synthesize emerging psychological frameworks and empirical findings on cognitive offloading to propose an integrative conceptual taxonomy.Cognitive offloading refers to using external tools to ease internal cognitive demands. Classic research such as the \&quot;Google Effect\&quot; demonstrated that when people expect information to be easily accessible online, they are less likely to remember it themselves (Sparrow et al., 2011). Later replication studies revealed that people tend to remember where information is stored rather than what it is (Camerer et al., 2016). Building on these findings, Risko and Gilbert (2016) argued that digital technologies not only alter memory but also redistribute attention and mental effort. More recent work extends this to AI tools, showing shifts in memory encoding, problem-solving strategies, and even goal formation (Grinschgl \&amp; Neubauer, 2022).The research shows there is a spectrum of how much an external aid will affect someone\&\#39;s cognition (assistive, substitutive and sometimes disruptive). Assistive offloading happens when technology helps cognition but does not interfere with cognition (example would be reminders apps or digital sticky note reminders for memory cues).Substitutive offloading occurs when technology replaces cognition; examples include auto-suggest or predictive search which reduces cognitive processing, thus also reducing the amount of cognitive energy applied to the original source material. Disruptive offloading is the same as substitutive offloading, however, it encourages a paradigm of passive interaction where one loses their ability to mentally control what they think about and the ability to reflect upon what they think about through automated results.Eventually regular reliance on AI for basic cognitive tasks, over time, can cause the relationship between external help and internal mental control to become unbalanced. In turn, the type of thinking people develop can become optimized for speed rather than comprehension. Understanding the differences in levels of influence for technology is important in determining when a person relies on technology to assist their cognition versus when technology substitutes for cognition.Historically, cognition was supplemented by tools like notebooks or calculators. These served as scaffolds-tools external to cognition but that facilitated greater internal processing. Contemporary AI tools, however, circumvent as opposed to augment internal cognition. Models like ChatGPT aid in essay writing, choice making, and problem solving and operate as cognitive surrogates rather than as scaffolds providing ready-made solutions. Unlike the past generation of instruments that required the active participation of the user, and a high level of critical and reflective thought to produce original output; generative AI systems are able to automatically generate output with minimal need for ideation or reflection on part of the user. An example is the difference between an outline software that assists the user in creating ideas, and an AI tool capable of producing a full essay without the need for any thought at all. Users who start with AI generated work may avoid some of the important cognitive processes that occur when writing, such as synthesizing new thoughts, or revising existing ones (Huff \&amp; Ulak\&\#231;ı, 2024). These lost cognitive processes can also cause the loss of neural pathways associated with higher order thought over time, particularly if the user uses the AI tools frequently and with no discretion.The use of cognitive offloading is detrimental to the ability to remember information long-term (Lu et al., 2020), as well as the willingness to become engaged in content (Kelly \&amp; Risko, 2022) because individuals will have an expectation that the information is being held outside of themselves and therefore will be less likely to commit it to memory. A relationship exists between excessive use of artificially generated answers in educational environments, and surface-level learning, poor self-evaluation, and shallow conceptual understanding (Chiu, 2024).Furthermore, the retrieval process -a critical component of durable learning (Karpicke \&amp; Blunt, 2011)-will most certainly be avoided if a learner relies on artificial intelligence-based explanations for their work instead of generating the knowledge through independent means. AI systems that are designed to emphasize correct answers at the expense of cognitive expenditure may also facilitate this trend, and encourage learners to move away from the pursuit of expertise toward the production of answers. Together, these patterns of digital memory use reveal that offloading rarely affects recall in isolation; it reshapes how attention is allocated to information in the first place.Cognitive offloading is successful based on metacognitive regulation -The ability to observe and control when and how you are going to offload your cognitive workload. The AI system creates an illusion of competence and contributes to a user overestimating their awareness of what was generated and/or reviewed by the AI system. As a result, introspection accuracy and user control decrease (Hoch et al., 2023). Both decreased introspection accuracy and user control impede adolescents and young adults whose executive functioning has not yet been developed (Iley \&amp; Medimorec, 2024;X. Sun, 2024).The results of research conducted using Judgment Of Learning (JOL) tests reveal that users typically overestimate the amount of knowledge they possess regarding the output produced by an AI (Hu et al., 2019). This miscalibration may reduce the need for feedback loop revisions, and therefore limit the depth of learning. In addition, as AI continues to eliminate ambiguity, the users will become increasingly intolerant of ambiguity -reducing the developmental potential of epistemological resilience. As metacognitive regulation becomes increasingly externalized, the broader question arises of how such dependency influences sustained attention and the capacity for self-directed learning.As people routinely use AI tools for their everyday needs, their mental expectations about how much effort is required to accomplish something are altered. As an example, when there is an abundance of accessible information, what constitutes \&quot;effort\&quot; becomes elevated. In addition, as AI tools become easier to use and provide instant gratification, many will choose to avoid those activities that appear to require higher levels of cognitive engagement. Research has demonstrated that frequent exposure to digital multitasking and continuous availability of information negatively affect sustained attention and cognitive flexibility. Multitasking in a digital environment creates an unstable state of affairs among the various attentional networks. This instability makes maintaining focus and adapting to changing cognitive requirements more difficult (Lee \&amp; Schumacher, 2024).On the other hand, while some individuals may rapidly respond to a multitude of tasks simultaneously, research indicates these same individuals make more mistakes and demonstrate poorer attentional control (Figueroa et al., 2014). Developmentally-based research also supports the idea that sustained attention is fundamental to developing cognitive flexibility, therefore early or prolonged distractions can have negative long-term effects (Benitez et al., 2017). The reward systems used by AI tools (i.e., rapid feedback, little resistance, and expected outcomes) create an inclination toward ease versus depth. When ease is attained with less effort (e.g., difficulty in formulating a question), one may discontinue engaging in high-level thinking. These patterns of attentional adaptation under AI influence set the stage for understanding how developing minds, particularly adolescents, navigate delegated cognition.Cognitive offloading impacts all age ranges; however, it is possible that cognitive offloading has a greater impact on individuals at developmental stages where their Executive Functions are continuing to develop (Meunier-Duperray et al., 2025). Therefore, while there are many different types of developmental stages that exist in terms of how the brain develops and matures, adolescence represents a unique example of a developmental stage -where both the substitutes and disruptions of offloading can have significant and lasting impacts on the individual\&\#39;s cognitive abilities and identity formation (Bai et al., 2023).During adolescence, many adolescents use AI technology for both academic and recreational uses; therefore, they are often among the first generation of \&quot;early adopters\&quot; of delegated cognition. The core executive functions (i.e., planning, impulse control, and self-regulation), which are the foundation of many of the cognitive processes necessary for effective learning and decisionmaking, are still developing throughout adolescence (Iley \&amp; Medimorec, 2024). Therefore, relying consistently on AI to either generate, organize, or evaluate information may interfere with the normal maturation process of these skills. This type of phenomenon represents what we have termed a developmental displacement effect, which refers to a situation where one of the fundamental cognitive processes (in this case, internal processing) is externally displaced prior to achieving internal mastery (X. Sun, 2024).There are now empirical studies that have demonstrated this phenomenon. For example, a study by Sun et al. (2024) found that heavy AI use in school-related tasks resulted in lower levels of selfmonitoring and poorer metacognitive accuracy over time. The results of this study represent one of the examples of the Disruptive Offloading level of our taxonomy, which involves the substitution of automation for internal regulation and reflection. In addition to the negative impact that premature delegation can have on short-term learning, it also can result in delayed development of independent cognitive agency, which is an important aspect of both autonomy and motivation.Therefore, framing adolescence as a specific example to illustrate our points does not limit, but instead supports our position that the psychological consequences of cognitive offloading are developmentally graded, and that understanding these gradients is essential to creating educational and technological systems that foster -and do not impede -mental independence and selfreliance. These developmental differences highlight why a structured taxonomy of cognitive offloading is necessary-to clarify when delegation supports growth and when it begins to undermine cognitive autonomy.Cognitive offloading is not a homogeneous process, and its psychological effects depend on the number of internal operations replaced and which cognitive operations are operant. Drawing on previous literature, we present a taxonomy which separates three kinds of offloading-assistive, substitutive and disruptive-and relates each type to the different basic domains of cognition: memory, metacognition, attention, and learning autonomy. (Jose et al., 2025). Supports focus by reducing overload without fragmenting attention (Bai et al., 2023). Strengthens autonomy through scaffolding; tool remains under conscious control.Encoding and retrieval decline when AI provides ready answers. (Risko \&amp; Gilbert, 2016) Creates an illusion of competence; users overestimate understanding. (Tezer, 2025) Promotes shallow engagement or multitasking (Jose et al., 2025).Reduces agency as effort shifts to the system rather than the self (Bai et al., 2023).Long-term recall and reconstruction skills erode through chronic reliance.Self-monitoring diminishes; reflection loops collapse. (Jose et al., 2025) Attention becomes externally driven and rewardseeking (Murtaza et al., 2022).Undermines selfregulation, fostering dependency and passivity (Murtaza et al., 2022).The three types of assistive off-loading that occur are in-line with the principles of scaffolded learning as they provide an increase in task performance with a continued level of internal engagement by the learner.Substitute off-loading has identified the presence of measurable cognitive cost associated with using off-loads. This finding is consistent with research concerning the Google Effect and the reduction in semantic effort (Kelly \&amp; Risko, 2022;Sparrow et al., 2011).Disruptive off-loading is a form of off-loading which results in a qualitatively different type of impact than either of the two other forms of off-loading. Specifically, Disruptive off-loading results in an undermining of metacognitive accuracy and sustained attention as well as creating a higher risk of cognitive disengagement among developing minds (J. Sun et al., 2024b).Using this taxonomy allows researchers to develop a theoretical framework to examine how technology is used to delegate tasks, as well as when the use of technology for delegating tasks is likely to be beneficial or detrimental to learners\&\#39; cognitive development. In addition, future empirical studies will be able to operationalize the levels of off-loading, to help define at what point in time each of the three levels of off-loading result in an increase in task completion, but also an increase in cognitive costs, and to ultimately guide educators in designing responsible and effective technologies for supporting learners.A visual overview of the proposed taxonomy is presented in Figure 1 The figure illustrates the continuum of cognitive offloading from assistive to disruptive forms, showing how increasing external automation progressively reduces internal control. Each level interacts with four core cognitive domains-memory, metacognition, attention, and learning autonomy-indicating that as offloading becomes more substitutive or disruptive, dependence on internal processes declines.Designers will have to consider both what current AI systems enable as well as what they might replace when AI becomes integrated into our day-to-day decision making. As it relates to psychology, one of the primary concerns has been the potential for AI based decision support tools to gradually reduce the amount of effortful thinking required of users through their very nature as being low-friction and fast to produce results. Cognitive Load Theory (Sweller, 1988), for example, stresses the importance of achieving a cognitive \&quot;balance\&quot; of mental effort in order to optimize learning. Self-Determination Theory (Deci \&amp; Ryan, 2013), on the other hand, emphasizes that users require both competence and autonomy in order to develop motivationally and psychologically. If AI-based design consistently thwart this \&quot;cognitive balance,\&quot; then the likelihood increases that AI-based design could create an environment that encourages efficiency at the expense of personal growth and development.In order to promote cognitive sustainability, AI-based interfaces need to incorporate \&quot;constructive friction\&quot; (Estaphan et al., 2025) -features that momentarily halt user interactions and prompt users to reflect upon their thoughts and/or recall past experiences. For example, AI-based interfaces could utilize delayed automatic suggested responses, confidence rating mechanisms, or brief prompts for minimal reflection before presenting AI-generated content. While these types of interface features may assist in maintaining cognitive engagement with users, they do so without hindering accessibility. Therefore, future research needs to assess how these seemingly minor design decisions affect cognitive processes in educational and health care environments, where internal agency is most important.In order to diminish reliance on AI, all future psychological interventions will focus on utilizing internal cognitive approaches that support a variety of cognitive processes. The following methods are examples of cognitive interventions that provide evidence of cognitive control; metacognitive training (Hertzog \&amp; Dunlosky, 2011), retrieval based learning and productive struggle. All digital literacy efforts should focus on providing more than technical ability. Efforts to develop \&quot;AI aware cognition\&quot; -the ability to identify when to use AI and when to continue with an effort-will foster learning resilience in an increasingly AI-enriched environment.While Cognitive Offloading is an intuitive and adaptable feature of human intelligence, it now represents a significant escalation in terms of frequency, scale, and psychological impact as a result of AI tools. The proposed conceptual framework identifies three forms of cognitive offloading (assistive, substitutive, and disruptive) to help clarify the ways in which delegating tasks can either support, replace, or diminish cognitive integrity. While the nature of the relationship between offloading and cognitive integrity is not directly relevant to the type of offloading occurring (i.e., assistive, substitutive, etc.), the degree to which individuals are aware of their actions and the extent to which they engage in such behavior are both crucial factors.As we move through the four domains of memory, metacognition, attention and learning autonomy, the potential risks associated with offloading without purposeful consideration of the consequences become increasingly apparent. The cognitive tools that replace rather than enhance internal cognitive effort, also modify user\&\#39;s conceptions of task difficulty and distort perceptions of competence. Although adolescence presents a prime example of the potential for early delegation to impede the development of self-regulation and independent thought, these characteristics are not unique to adolescents; they represent a broad human tendency towards convenient cognition.Psychologically speaking, these findings suggest a transition from a focus on the benefits of intelligent systems to the need for a new paradigm of cognitive sustainability; i.e., designing technologies and learning environments that preserve the effortful aspects of mental processing, promote reflection, and foster agency. Intelligent systems must therefore be judged not solely based upon their performance, but based on their impact on the quality of human thought surrounding that performance (Norman, 2024). There are many ways to encourage users to pause and reflect, including using interface features such as delayed suggestions, confidence checks, or reflection prompts, as well as integrating metacognitive training and retrieval-based learning into educational practices, to improve users\&\#39; abilities to differentiate between times when to delegate and times when to continue the effortful mental work.Ultimately, the future of human cognition in a world saturated with artificial intelligence will depend on the integration of both technological innovation and psychologically informed design. As we increasingly rely on machines to handle more of our mental lives, the fundamental question becomes: How much of our thinking should remain our own? In practical terms, this framework highlights the need for digital-literacy education that strengthens reflection rather than passive reliance. Educational policy should aim for cognitive sustainability, ensuring that AI systems are designed to complement, not replace, human learning and self-regulation.},
  langid = {english},
  keywords = {/unread,assistive,cognitive autonomy,cognitive off-loading,identity domains,substitutive},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T13:43:06.168Z},
  file = {/Users/andrew/Zotero/storage/IDZAB5MR/Jose et al. - 2025 - Outsourcing cognition the psychological costs of AI-era convenience.pdf}
}

@article{kalaiWhyLanguageModels,
  title = {Why {{Language Models Hallucinate}}},
  author = {Kalai, Adam Tauman and Nachum, Ofir and Vempala, Santosh S and Zhang, Edwin},
  abstract = {Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such “hallucinations” persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious—they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded—language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This “epidemic” of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-09-16T12:42:32.817Z},
  file = {/Users/andrew/Zotero/storage/BQ77THRN/Kalai et al. - Why Language Models Hallucinate.pdf}
}

@incollection{kalyugaExpertiseReversalEffect2009,
  title = {The {{Expertise Reversal Effect}}},
  booktitle = {Managing {{Cognitive Load}} in {{Adaptive Multimedia Learning}}},
  author = {Kalyuga, Slava},
  date = {2009},
  pages = {58--80},
  publisher = {IGI Global Scientific Publishing},
  doi = {10.4018/978-1-60566-048-6.ch003},
  url = {https://www.igi-global.com/chapter/expertise-reversal-effect/www.igi-global.com/chapter/expertise-reversal-effect/25732},
  urldate = {2025-06-12},
  abstract = {Cognitive studies of expertise that were reviewed in Chapter I indicated that prior knowledge is the most important 1earner characteristic that influences learning processes. Recently, it has been established that learning procedures and techniques that are beneficial for learners with low levels of...},
  isbn = {978-1-60566-048-6},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T20:12:24.721Z}
}

@article{kapurExaminingProductiveFailure2016,
  title = {Examining {{Productive Failure}}, {{Productive Success}}, {{Unproductive Failure}}, and {{Unproductive Success}} in {{Learning}}},
  author = {Kapur, Manu},
  date = {2016-04-02},
  journaltitle = {Educational Psychologist},
  volume = {51},
  number = {2},
  pages = {289--299},
  publisher = {Routledge},
  issn = {0046-1520},
  doi = {10.1080/00461520.2016.1155457},
  url = {https://doi.org/10.1080/00461520.2016.1155457},
  urldate = {2025-06-12},
  abstract = {Learning and performance are not always commensurable. Conditions that maximize performance in the initial learning may not maximize learning in the longer term. I exploit this incommensurability to theoretically and empirically interrogate four possibilities for design: productive success, productive failure, unproductive success, and unproductive failure. Instead of only looking at extreme comparisons between discovery learning and direct instruction, an analysis of the four design possibilities suggests a vast design space in between the two extremes that may be more productive for learning than the extremes. I show that even though direct instruction can be conceived as a productive success compared to discovery learning, theoretical and empirical analyses suggests that it may well be an unproductive success compared with examples of productive failure and productive success. Implications for theory and the design of instruction are discussed.},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T18:25:38.225Z}
}

@online{kestin*AITutoringOutperforms2024,
  title = {{{AI Tutoring Outperforms Active Learning}}},
  author = {Kestin*, Gregory and Miller*, Kelly and Klales, Anna and Milbourne, Timothy and Ponti, Gregorio},
  date = {2024-05-14},
  eprinttype = {Research Square},
  issn = {2693-5015},
  doi = {10.21203/rs.3.rs-4243877/v1},
  url = {https://www.researchsquare.com/article/rs-4243877/v1},
  urldate = {2025-01-23},
  abstract = {Advances in generative artificial intelligence (GAI) show great potential for improving education. Yet little is known about how this new technology should be used and how effective it can be. Here we report a randomized, controlled study measuring college students’ learning and their perceptions when content is presented through an AI-powered tutor compared with an active learning class. The AI tutor was developed with the same pedagogical best practices as the lectures. We find that students learn more than twice as much in less time when using an AI tutor, compared with the active learning class. They also feel more engaged and more motivated. These findings offer empirical evidence for the efficacy of a widely accessible AI-powered pedagogy in significantly enhancing learning outcomes, presenting a compelling case for its broad adoption in learning environments. *These authors contributed equally to this work. Additionally, please note that Gregory Kestin is the corresponding author.},
  pubstate = {prepublished},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T14:12:35.215Z},
  file = {/Users/andrew/Zotero/storage/3AP24BFL/Kestin et al. - 2024 - AI Tutoring Outperforms Active Learning.pdf;/Users/andrew/Zotero/storage/LCK4V3KH/Kestin et al. - 2024 - AI Tutoring Outperforms Active Learning.docx}
}

@incollection{khanMultimodalBehavioralAnalytics2017,
  title = {Multimodal {{Behavioral Analytics}} in {{Intelligent Learning}} and {{Assessment Systems}}},
  booktitle = {Innovative {{Assessment}} of {{Collaboration}}},
  author = {Khan, Saad M.},
  editor = {Von Davier, Alina A. and Zhu, Mengxiao and Kyllonen, Patrick C.},
  date = {2017},
  pages = {173--184},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-33261-1_11},
  url = {http://link.springer.com/10.1007/978-3-319-33261-1_11},
  urldate = {2025-06-12},
  isbn = {978-3-319-33259-8 978-3-319-33261-1},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T19:12:29.634Z}
}

@article{kirk-johnsonPerceivingEffortPoor2019,
  title = {Perceiving Effort as Poor Learning: {{The}} Misinterpreted-Effort Hypothesis of How Experienced Effort and Perceived Learning Relate to Study Strategy Choice},
  shorttitle = {Perceiving Effort as Poor Learning},
  author = {Kirk-Johnson, Afton and Galla, Brian M. and Fraundorf, Scott H.},
  date = {2019-12-01},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {115},
  pages = {101237},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2019.101237},
  url = {https://www.sciencedirect.com/science/article/pii/S0010028519302270},
  urldate = {2025-08-24},
  abstract = {How do learners make decisions about how, what, and when to study, and why are their decisions sometimes ineffective for learning? In three studies, learners experienced a pair of contrasting study strategies (Study 1: interleaved vs. blocked schedule; Studies 2 \& 3: retrieval practice vs. restudy) and rated their perceptions of each strategy before choosing one for future use. In all three studies, mediation analysis revealed that participants who perceived a strategy as more effortful rated it as less effective for learning and, in turn, were less likely to choose it for future study. Further, choosing the more effortful strategy was associated with better long-term retention (Study 3), contrary to participants’ judgments. A final fourth study suggested that these relationships were not driven by the mere act of providing ratings. Our results thus support a misinterpreted-effort hypothesis in which the mental effort associated with many normatively effective learning strategies (desirable difficulties; Bjork \& Bjork, 1992) leads learners to misinterpret them as ineffective for learning and consequently not to employ them in self- regulated learning.},
  keywords = {Mediation,Metacognition,Self-regulated learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-24T20:17:05.589Z},
  file = {/Users/andrew/Zotero/storage/QZXDZIWZ/Kirk-Johnson et al. - 2019 - Perceiving effort as poor learning The misinterpreted-effort hypothesis of how experienced effort a.pdf;/Users/andrew/Zotero/storage/88KDDXS4/S0010028519302270.html}
}

@online{kirschnerChatGPTEducation2025,
  type = {Substack newsletter},
  title = {{{ChatGPT}} in {{Education}}},
  author = {Kirschner, Paul},
  date = {2025-08-14},
  url = {https://paulkirschner173727.substack.com/p/chatgpt-in-education},
  urldate = {2025-08-16},
  abstract = {An Effect in Search of a Cause?},
  organization = {Paul Kirschner},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-16T11:16:15.321Z},
  file = {/Users/andrew/Zotero/storage/T8AH32WU/chatgpt-in-education.html}
}

@incollection{kirschnerCognitiveLoadTheory2009,
  title = {Cognitive Load Theory},
  booktitle = {Psychology of Classroom Learning},
  author = {Kirschner, Paul A. and Kirschner, Femke and Paas, Fred},
  editor = {Anderman, E.M. and Anderman, L.H.},
  date = {2009},
  volume = {1 (a-j)},
  pages = {205--209},
  publisher = {Macmillan Reference},
  location = {Detroit},
  abstract = {Cognitive load theory (CLT) can provide guidelines to assist in the presentation of information in a manner that encourages learner activities that optimize intellectual performance. Central to CLT is the notion that human cognitive architecture should be a major consideration when designing instruction. This cognitive architecture consists of a limited working memory (WM), which interacts with a comparatively unlimited long-term memory (LTM). The limited WM carries the risk of learners being cognitively overloaded when performing a high complexity task. According to the theory, the limitations of working memory can be circumvented by coding multiple elements of information as one element in cognitive schemata, by automating rules, and by using  more than one presentation modality.},
  keywords = {/unread,Cognitive architecture,Cognitive load theory,short term memory,Task complexity Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-07-02T11:56:34.772Z}
}

@book{kirschnerHowLearningHappens2024,
  title = {How {{Learning Happens}}: {{Seminal Works}} in {{Educational Psychology}} and {{What They Mean}} in {{Practice}}},
  shorttitle = {How {{Learning Happens}}},
  author = {Kirschner, Paul A. and Hendrick, Carl},
  date = {2024-03-29},
  edition = {2},
  publisher = {Routledge},
  location = {London},
  doi = {10.4324/9781003395713},
  abstract = {How Learning Happens introduces 32 giants of educational research and their findings on how we learn and what we need to know to learn effectively, efficiently, and enjoyably. Many of these works have inspired researchers and teachers all around the world and have left a mark on how we teach today. Now updated to include a new section on Memory and Cognition with five new chapters, this revised second edition explores a selection of the key works on learning and teaching, chosen from the fields of educational psychology and cognitive psychology. It offers a roadmap of the most important discoveries in the way learning happens, with each chapter examining a different work and explaining its significance before describing the research, its implications for practice, and how it can be used in the classroom – including the key takeaways for teachers. Clearly divided into seven sections, the book covers: Memory and cognition How the brain works Prerequisites for learning How learning can be supported Teacher activities Learning in context Cautionary tales Written by two leading experts and illustrated by Oliver Caviglioli, this is essential reading for teachers wanting to fully engage with and understand educational research as well as undergraduate students in the fields of education, educational psychology, and the learning sciences.},
  isbn = {978-1-003-39571-3},
  pagetotal = {416},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T15:07:59.158Z},
  file = {/Users/andrew/Zotero/storage/F73DD9ZD/Kirschner and Hendrick - 2024 - How Learning Happens Seminal Works in Educational Psychology and What They Mean in Practice.pdf}
}

@book{kirschnerHowTeachingHappens2022,
  title = {How {{Teaching Happens}}: {{Seminal Works}} in {{Teaching}} and {{Teacher Effectiveness}} and {{What They Mean}} in {{Practice}}},
  shorttitle = {How {{Teaching Happens}}},
  author = {Kirschner, Paul and Hendrick, Carl and Heal, Jim},
  date = {2022-06-23},
  publisher = {Routledge},
  location = {London},
  doi = {10.4324/9781003228165},
  abstract = {Building on their bestselling book How Learning Happens, Paul A. Kirschner and Carl Hendrick are joined by Jim Heal to explore how teaching happens. The book seeks to closely examine what makes for effective teaching in the classroom and how research on expert teaching can be used in practice.  Introducing 30 seminal works from the field of education psychology research, the learning sciences, and teaching effectiveness studies, each chapter takes an important work and illustrates clearly and concisely what the research means and how it can be used in daily practice. Divided into six sections the book covers:  • Teacher Effectiveness, Development, and Growth • Curriculum Development / Instructional Design  • Teaching Techniques • Pedagogical Content Knowledge • In the Classroom  • Assessment The book ends with a final chapter on "What’s Missing?" in how teachers learn to teach.~ Written by three leading experts in the field with illustrations by Oliver Cavigioli, How Teaching Happens provides a clear roadmap for classroom teachers, school leaders, and teacher trainers/trainees on what effective teaching looks like in practice.},
  isbn = {978-1-003-22816-5},
  pagetotal = {374},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T14:55:32.218Z},
  file = {/Users/andrew/Zotero/storage/AWY3IP2U/Kirschner et al. - 2022 - How Teaching Happens Seminal Works in Teaching and Teacher Effectiveness and What They Mean in Prac.pdf}
}

@article{kirschnerWhyMinimalGuidance2006,
  title = {Why {{Minimal Guidance During Instruction Does Not Work}}: {{An Analysis}} of the {{Failure}} of {{Constructivist}}, {{Discovery}}, {{Problem-Based}}, {{Experiential}}, and {{Inquiry-Based Teaching}}},
  shorttitle = {Why {{Minimal Guidance During Instruction Does Not Work}}},
  author = {Kirschner, Paul A. and , John, Sweller and family=Clark, given=Richard E., prefix=and, useprefix=true},
  date = {2006-06-01},
  journaltitle = {Educational Psychologist},
  volume = {41},
  number = {2},
  pages = {75--86},
  publisher = {Routledge},
  issn = {0046-1520},
  doi = {10.1207/s15326985ep4102_1},
  url = {https://doi.org/10.1207/s15326985ep4102_1},
  urldate = {2025-06-12},
  abstract = {Evidence for the superiority of guided instruction is explained in the context of our knowledge of human cognitive architecture, expert–novice differences, and cognitive load. Although unguided or minimally guided instructional approaches are very popular and intuitively appealing, the point is made that these approaches ignore both the structures that constitute human cognitive architecture and evidence from empirical studies over the past half-century that consistently indicate that minimally guided instruction is less effective and less efficient than instructional approaches that place a strong emphasis on guidance of the student learning process. The advantage of guidance begins to recede only when learners have sufficiently high prior knowledge to provide "internal" guidance. Recent developments in instructional research and instructional design models that support guidance during instruction are briefly described.},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T19:45:54.361Z},
  file = {/Users/andrew/Zotero/storage/3C3VNH5D/Kirschner et al. - 2006 - Why Minimal Guidance During Instruction Does Not Work An Analysis of the Failure of Constructivist,.pdf}
}

@online{kosmynaYourBrainChatGPT2025,
  title = {Your {{Brain}} on {{ChatGPT}}: {{Accumulation}} of {{Cognitive Debt}} When {{Using}} an {{AI Assistant}} for {{Essay Writing Task}}},
  shorttitle = {Your {{Brain}} on {{ChatGPT}}},
  author = {Kosmyna, Nataliya and Hauptmann, Eugene and Yuan, Ye Tong and Situ, Jessica and Liao, Xian-Hao and Beresnitzky, Ashly Vivian and Braunstein, Iris and Maes, Pattie},
  date = {2025-06-10},
  eprint = {2506.08872},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2506.08872},
  url = {http://arxiv.org/abs/2506.08872},
  urldate = {2025-06-15},
  abstract = {This study explores the neural and behavioral consequences of LLM-assisted essay writing. Participants were divided into three groups: LLM, Search Engine, and Brain-only (no tools). Each completed three sessions under the same condition. In a fourth session, LLM users were reassigned to Brain-only group (LLM-to-Brain), and Brain-only users were reassigned to LLM condition (Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18 completing session 4. We used electroencephalography (EEG) to assess cognitive load during essay writing, and analyzed essays using NLP, as well as scoring essays with the help from human teachers and an AI judge. Across groups, NERs, n-gram patterns, and topic ontology showed within-group homogeneity. EEG revealed significant differences in brain connectivity: Brain-only participants exhibited the strongest, most distributed networks; Search Engine users showed moderate engagement; and LLM users displayed the weakest connectivity. Cognitive activity scaled down in relation to external tool use. In session 4, LLM-to-Brain participants showed reduced alpha and beta connectivity, indicating under-engagement. Brain-to-LLM users exhibited higher memory recall and activation of occipito-parietal and prefrontal areas, similar to Search Engine users. Self-reported ownership of essays was the lowest in the LLM group and the highest in the Brain-only group. LLM users also struggled to accurately quote their own work. While LLMs offer immediate convenience, our findings highlight potential cognitive costs. Over four months, LLM users consistently underperformed at neural, linguistic, and behavioral levels. These results raise concerns about the long-term educational implications of LLM reliance and underscore the need for deeper inquiry into AI's role in learning.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-15T23:24:21.472Z},
  file = {/Users/andrew/Zotero/storage/ZIPLEUL8/Kosmyna et al. - 2025 - Your Brain on ChatGPT Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing T.pdf;/Users/andrew/Zotero/storage/EBVGHLIR/2506.html}
}

@article{krathwohlRevisionBloomsTaxonomy2002,
  title = {A {{Revision}} of {{Bloom}}'s {{Taxonomy}}: {{An Overview}}},
  shorttitle = {A {{Revision}} of {{Bloom}}'s {{Taxonomy}}},
  author = {Krathwohl, David R.},
  date = {2002-11},
  journaltitle = {Theory Into Practice},
  volume = {41},
  number = {4},
  pages = {212--218},
  publisher = {Routledge},
  issn = {0040-5841},
  doi = {10.1207/s15430421tip4104_2},
  url = {https://www.tandfonline.com/doi/abs/10.1207/s15430421tip4104_2},
  urldate = {2025-06-13},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-13T12:41:41.006Z},
  file = {/Users/andrew/Zotero/storage/TXZBPY8M/Krathwohl - 2002 - A Revision of Bloom's Taxonomy An Overview.pdf}
}

@article{kuperbergTeaMilkHierarchical2021,
  title = {Tea {{With Milk}}? {{A Hierarchical Generative Framework}} of {{Sequential Event Comprehension}}},
  shorttitle = {Tea {{With Milk}}?},
  author = {Kuperberg, Gina R.},
  date = {2021},
  journaltitle = {Topics in Cognitive Science},
  volume = {13},
  number = {1},
  pages = {256--298},
  issn = {1756-8765},
  doi = {10.1111/tops.12518},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12518},
  urldate = {2024-11-20},
  abstract = {To make sense of the world around us, we must be able to segment a continual stream of sensory inputs into discrete events. In this review, I propose that in order to comprehend events, we engage hierarchical generative models that “reverse engineer” the intentions of other agents as they produce sequential action in real time. By generating probabilistic predictions for upcoming events, generative models ensure that we are able to keep up with the rapid pace at which perceptual inputs unfold. By tracking our certainty about other agents' goals and the magnitude of prediction errors at multiple temporal scales, generative models enable us to detect event boundaries by inferring when a goal has changed. Moreover, by adapting flexibly to the broader dynamics of the environment and our own comprehension goals, generative models allow us to optimally allocate limited resources. Finally, I argue that we use generative models not only to comprehend events but also to produce events (carry out goal-relevant sequential action) and to continually learn about new events from our surroundings. Taken together, this hierarchical generative framework provides new insights into how the human brain processes events so effortlessly while highlighting the fundamental links between event comprehension, production, and learning.},
  langid = {english},
  keywords = {/unread,Bayesian,Late positivity,Monitoring,N400,Prediction,Prediction error,Predictive coding,Temporal receptive field},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.461Z},
  file = {/Users/andrew/Zotero/storage/KCHEIKT6/Kuperberg - 2021 - Tea With Milk A Hierarchical Generative Framework of Sequential Event Comprehension.pdf;/Users/andrew/Zotero/storage/SAE3CQ9Q/tops.html}
}

@online{langCheatingLessons2013,
  title = {Cheating {{Lessons}}},
  author = {Lang, James M.},
  date = {2013},
  url = {https://www.hup.harvard.edu/books/9780674724631},
  urldate = {2024-06-26},
  abstract = {Nearly three-quarters of college students cheat during their undergraduate careers, a startling number attributed variously to the laziness of today’s students, their lack of a moral compass, or the demands of a hypercompetitive society. For James Lang, cultural or sociological explanations like these are red herrings. His provocative new research indicates that students often cheat because their learning environments give them ample incentives to try—and that strategies which make cheating less worthwhile also improve student learning. Cheating Lessons is a practical guide to tackling academic dishonesty at its roots.Drawing on an array of findings from cognitive theory, Lang analyzes the specific, often hidden features of course design and daily classroom practice that create opportunities for cheating. Courses that set the stakes of performance very high, that rely on single assessment mechanisms like multiple-choice tests, that have arbitrary grading criteria: these are the kinds of conditions that breed cheating. Lang seeks to empower teachers to create more effective learning environments that foster intrinsic motivation, promote mastery, and instill the sense of self-efficacy that students need for deep learning.Although cheating is a persistent problem, the prognosis is not dire. The good news is that strategies which reduce cheating also improve student performance overall. Instructors who learn to curb academic dishonesty will have done more than solve a course management problem—they will have become better educators all around.},
  langid = {english},
  organization = {Harvard University Press},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T14:25:28.840Z},
  file = {/Users/andrew/Zotero/storage/BIGQTBTM/9780674724631.html}
}

@inproceedings{leeImpactGenerativeAI2025,
  title = {The {{Impact}} of {{Generative AI}} on {{Critical Thinking}}: {{Self-Reported Reductions}} in {{Cognitive Effort}} and {{Confidence Effects From}} a {{Survey}} of {{Knowledge Workers}}},
  shorttitle = {The {{Impact}} of {{Generative AI}} on {{Critical Thinking}}},
  author = {Lee, Hao-Ping (Hank) and Sarkar, Advait and Tankelevitch, Lev and Drosos, Ian and Rintel, Sean and Banks, Richard and Wilson, Nicholas},
  date = {2025-04-01},
  url = {https://www.microsoft.com/en-us/research/publication/the-impact-of-generative-ai-on-critical-thinking-self-reported-reductions-in-cognitive-effort-and-confidence-effects-from-a-survey-of-knowledge-workers/},
  urldate = {2025-03-12},
  abstract = {The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared […]},
  eventtitle = {Proceedings of the {{ACM CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  langid = {american},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T16:47:26.854Z},
  file = {/Users/andrew/Zotero/storage/FFLD8D2L/Lee et al. - 2025 - The Impact of Generative AI on Critical Thinking Self-Reported Reductions in Cognitive Effort and C.pdf}
}

@article{leeStudentLearningWhat2013,
  title = {Student {{Learning}}: {{What Has Instruction Got}} to {{Do With It}}?},
  shorttitle = {Student {{Learning}}},
  author = {Lee, Hee Seung and Anderson, John R.},
  date = {2013-01-03},
  journaltitle = {Annual Review of Psychology},
  shortjournal = {Annu. Rev. Psychol.},
  volume = {64},
  number = {1},
  pages = {445--469},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-113011-143833},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143833},
  urldate = {2025-06-18},
  abstract = {A seemingly unending controversy in the field of instruction science concerns how much instructional guidance needs to be provided in a learning environment. At the one extreme lies the claim that it is important for students to explore and construct knowledge for themselves, which is often called discovery learning, and at the other extreme lies the claim that providing direct instruction is more beneficial than withholding it. In this article, evidence and arguments that support either of the approaches are reviewed. Also, we review how different instructional approaches interact with other instructional factors that have been known to be important, such as individual difference, selfexplanation, and comparison. The efforts to combine different instructional approaches suggest alternative ways to conceive of learning and to test it.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-18T05:59:25.736Z},
  file = {/Users/andrew/Zotero/storage/3BDDFHM6/Lee and Anderson - 2013 - Student Learning What Has Instruction Got to Do With It.pdf}
}

@online{legrandPyhgfNeuralNetwork2024,
  title = {Pyhgf: {{A}} Neural Network Library for Predictive Coding},
  shorttitle = {Pyhgf},
  author = {Legrand, Nicolas and Weber, Lilian and Waade, Peter Thestrup and Daugaard, Anna Hedvig Møller and Khodadadi, Mojtaba and Mikuš, Nace and Mathys, Chris},
  date = {2024-10-11},
  eprint = {2410.09206},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.09206},
  url = {http://arxiv.org/abs/2410.09206},
  urldate = {2024-11-02},
  abstract = {Bayesian models of cognition have gained considerable traction in computational neuroscience and psychiatry. Their scopes are now expected to expand rapidly to artificial intelligence, providing general inference frameworks to support embodied, adaptable, and energy-efficient autonomous agents. A central theory in this domain is predictive coding, which posits that learning and behaviour are driven by hierarchical probabilistic inferences about the causes of sensory inputs. Biological realism constrains these networks to rely on simple local computations in the form of precision-weighted predictions and prediction errors. This can make this framework highly efficient, but its implementation comes with unique challenges on the software development side. Embedding such models in standard neural network libraries often becomes limiting, as these libraries' compilation and differentiation backends can force a conceptual separation between optimization algorithms and the systems being optimized. This critically departs from other biological principles such as self-monitoring, self-organisation, cellular growth and functional plasticity. In this paper, we introduce \textbackslash texttt\{pyhgf\}: a Python package backed by JAX and Rust for creating, manipulating and sampling dynamic networks for predictive coding. We improve over other frameworks by enclosing the network components as transparent, modular and malleable variables in the message-passing steps. The resulting graphs can implement arbitrary computational complexities as beliefs propagation. But the transparency of core variables can also translate into inference processes that leverage self-organisation principles, and express structure learning, meta-learning or causal discovery as the consequence of network structural adaptation to surprising inputs. The code, tutorials and documentation are hosted at: https://github.com/ilabcode/pyhgf.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/NKQG3RC7/Legrand et al. - 2024 - pyhgf A neural network library for predictive coding.pdf;/Users/andrew/Zotero/storage/JZVXULET/2410.html}
}

@article{loongControlKnowledgeTracing2024,
  title = {Control Knowledge Tracing: {{Modeling}} Students' Learning Dynamics from a Control-Theory Perspective},
  shorttitle = {Control Knowledge Tracing},
  author = {Loong, Cheng Ning and Chang, Chih-Chen},
  date = {2024-12},
  journaltitle = {Computers and Education: Artificial Intelligence},
  shortjournal = {Computers and Education: Artificial Intelligence},
  volume = {7},
  pages = {100292},
  issn = {2666920X},
  doi = {10.1016/j.caeai.2024.100292},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2666920X2400095X},
  urldate = {2025-06-06},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T21:59:05.710Z},
  file = {/Users/andrew/Zotero/storage/LT5IZEZH/Loong and Chang - 2024 - Control knowledge tracing Modeling students' learning dynamics from a control-theory perspective.pdf}
}

@article{lortie-forguesConceptualKnowledgeDecimal2017,
  title = {Conceptual Knowledge of Decimal Arithmetic.},
  author = {Lortie-Forgues, Hugues and Siegler, Robert S.},
  date = {2017-04},
  journaltitle = {Journal of Educational Psychology},
  shortjournal = {Journal of Educational Psychology},
  volume = {109},
  number = {3},
  pages = {374--386},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/edu0000148},
  url = {https://doi.apa.org/doi/10.1037/edu0000148},
  urldate = {2025-12-10},
  abstract = {In 2 studies (Ns = 55 and 54), we examined a basic form of conceptual understanding of rational number arithmetic, the direction of effect of decimal arithmetic operations, at a level of detail useful for informing instruction. Middle school students were presented tasks examining knowledge of the direction of effects (e.g., “True or false: 0.77 * 0.63 {$>$} 0.77"), knowledge of decimal magnitudes, and knowledge of decimal arithmetic procedures. Their confidence in their direction of effect judgments was also assessed. The authors found (a) most students incorrectly predicted the direction of effect of multiplication and division with decimals below 1; (b) this pattern held for students who accurately compared the magnitudes of individual decimals and correctly executed decimal arithmetic operations; (c) explanations of direction of effect judgments that cited both the arithmetic operation and the numbers’ magnitudes were strongly associated with accurate judgments; and (d) judgments were more accurate when multiplication problems involved a whole number and a decimal below 1 than with 2 decimals below 1. Implications of the findings for instruction are discussed.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T13:44:07.332Z},
  file = {/Users/andrew/Zotero/storage/BKWXRG5J/Lortie-Forgues and Siegler - 2017 - Conceptual knowledge of decimal arithmetic..pdf}
}

@article{maoDeepLearningVs2018,
  title = {Deep {{Learning}} vs. {{Bayesian Knowledge Tracing}}: {{Student Models}} for {{Interventions}}},
  shorttitle = {Deep {{Learning}} vs. {{Bayesian Knowledge Tracing}}},
  author = {Mao, Ye and Lin, Chen and Chi, Min},
  date = {2018-10-25},
  journaltitle = {Journal of Educational Data Mining},
  shortjournal = {JEDM},
  volume = {10},
  number = {2},
  pages = {28--54},
  issn = {2157-2100},
  doi = {10.5281/zenodo.3554691},
  url = {https://jedm.educationaldatamining.org},
  urldate = {2023-01-09},
  abstract = {Bayesian Knowledge Tracing (BKT) is a commonly used approach for student modeling, and Long Short Term Memory (LSTM) is a versatile model that can be applied to a wide range of tasks, such as language translation. In this work, we directly compared three models: BKT, its variant Intervention-BKT (IBKT), and LSTM, on two types of student modeling tasks: post-test scores prediction and learning gains prediction. Additionally, while previous work on student learning has often used skill/knowledge components identified by domain experts, we incorporated an automatic skill discovery method (SK), which includes a nonparametric prior over the exercise-skill assignments, to all three models. Thus, we explored a total of six models: BKT, BKT+SK, IBKT, IBKT+SK, LSTM, and LSTM+SK. Two training datasets were employed, one was collected from a natural language physics intelligent tutoring system named Cordillera, and the other was from a standard probability intelligent tutoring system named Pyrenees. Overall, our results showed that BKT and BKT+SK outperformed the others on predicting post-test scores, whereas LSTM and LSTM+SK achieved the highest accuracy, F1-measure, and area under the ROC curve (AUC) on predicting learning gains. Furthermore, we demonstrated that by combining SK with the BKT model, BKT+SK could reliably predict post-test scores using only the earliest 50\% of the entire training sequences. For learning gain early prediction, using the earliest 70\% of the entire sequences, LSTM can deliver a comparable prediction as using the entire training sequences. The findings yield a learning environment that can foretell students’ performance and learning gains early, and can render adaptive pedagogical strategy accordingly.},
  issue = {2},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/9FZBFTB2/Mao et al. - 2018 - Deep Learning vs. Bayesian Knowledge Tracing Stud.pdf}
}

@article{mcgrathGenerativeAIChatbots2024,
  title = {Generative {{AI}} Chatbots in Higher Education: A Review of an Emerging Research Area},
  shorttitle = {Generative {{AI}} Chatbots in Higher Education},
  author = {McGrath, Cormac and Farazouli, Alexandra and Cerratto-Pargman, Teresa},
  date = {2024-08-24},
  journaltitle = {Higher Education},
  shortjournal = {High Educ},
  issn = {1573-174X},
  doi = {10.1007/s10734-024-01288-w},
  url = {https://doi.org/10.1007/s10734-024-01288-w},
  urldate = {2025-06-09},
  abstract = {Artificial intelligence (AI) chatbots trained on large language models are an example of generative AI which brings promises and threats to the higher education sector. In this study, we~examine the emerging research area of AI chatbots in higher education (HE), focusing specifically on empirical studies conducted since the release of ChatGPT.~Our review includes~23 research articles published between December 2022 and December 2023 exploring the use of AI chatbots in HE settings. We take a three-pronged approach to the empirical data. We first examine the state of the emerging field of AI chatbots in HE. Second, we identify the~theories of learning~used in the empirical studies on AI chatbots in HE. Third, we scrutinise the~discourses~of AI in HE framing the latest empirical work on AI chatbots. Our findings contribute to a better understanding of the eclectic state of the nascent research area of AI chatbots in HE, the lack of common conceptual groundings about human learning, and the presence of both dystopian and utopian discourses about the future role of AI chatbots in HE.},
  langid = {english},
  keywords = {AI chatbots,Artificial Intelligence,Computational Intelligence,Digital Humanities,Discourses,eLearning,Generative AI,Human-Computer Studies,Large language models,Philosophy of Artificial Intelligence,Theories of learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:34:04.268Z},
  file = {/Users/andrew/Zotero/storage/FYE5NT48/McGrath et al. - 2024 - Generative AI chatbots in higher education a review of an emerging research area.pdf}
}

@online{michaeltrucanoAINextDigital2023,
  title = {{{AI}} and the next Digital Divide in Education},
  author = {{Michael Trucano}},
  date = {2023-10-07},
  url = {https://www.brookings.edu/articles/ai-and-the-next-digital-divide-in-education/},
  urldate = {2025-12-10},
  abstract = {Michael Trucano discusses AI in educationand the potential for a third wave of the worldwide "digital divide."},
  langid = {american},
  organization = {Brookings},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T13:48:45.070Z}
}

@article{mitchellArtificialIntelligenceLearns2025,
  title = {Artificial Intelligence Learns to Reason},
  author = {Mitchell, Melanie},
  date = {2025-03-20},
  journaltitle = {Science},
  volume = {387},
  number = {6740},
  pages = {eadw5211},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.adw5211},
  url = {https://www.science.org/doi/10.1126/science.adw5211},
  urldate = {2025-03-21},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-21T09:26:49.149Z}
}

@article{nguyenEchoChambersEpistemic2020,
  title = {Echo Chambers and {{Epistemic Bubbles}}},
  author = {Nguyen, C. Thi},
  date = {2020-06},
  journaltitle = {Episteme},
  volume = {17},
  number = {2},
  pages = {141--161},
  issn = {1742-3600, 1750-0117},
  doi = {10.1017/epi.2018.32},
  url = {https://www.cambridge.org/core/journals/episteme/article/abs/echo-chambers-and-epistemic-bubbles/5D4AC3A808C538E17C50A7C09EC706F0},
  urldate = {2025-11-26},
  abstract = {Discussion of the phenomena of post-truth and fake news often implicates the closed epistemic networks of social media. The recent conversation has, however, blurred two distinct social epistemic phenomena. An epistemic bubble is a social epistemic structure in which other relevant voices have been left out, perhaps accidentally. An echo chamber is a social epistemic structure from which other relevant voices have been actively excluded and discredited. Members of epistemic bubbles lack exposure to relevant information and arguments. Members of echo chambers, on the other hand, have been brought to systematically distrust all outside sources. In epistemic bubbles, other voices are not heard; in echo chambers, other voices are actively undermined. It is crucial to keep these phenomena distinct. First, echo chambers can explain the post-truth phenomena in a way that epistemic bubbles cannot. Second, each type of structure requires a distinct intervention. Mere exposure to evidence can shatter an epistemic bubble, but may actually reinforce an echo chamber. Finally, echo chambers are much harder to escape. Once in their grip, an agent may act with epistemic virtue, but social context will pervert those actions. Escape from an echo chamber may require a radical rebooting of one's belief system.},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-11-26T08:38:29.830Z},
  file = {/Users/andrew/Zotero/storage/G8YHT8PC/Nguyen - 2020 - ECHO CHAMBERS AND EPISTEMIC BUBBLES.pdf}
}

@article{nussbaumPromotingArgumentCounterargumentIntegration2007,
  title = {Promoting {{Argument-Counterargument Integration}} in {{Students}}' {{Writing}}},
  author = {Nussbaum, E. Michael and family=Schraw, given=Gregory, prefix=and, useprefix=true},
  date = {2007-10-01},
  journaltitle = {The Journal of Experimental Education},
  volume = {76},
  number = {1},
  pages = {59--92},
  publisher = {Routledge},
  issn = {0022-0973},
  doi = {10.3200/JEXE.76.1.59-92},
  url = {https://doi.org/10.3200/JEXE.76.1.59-92},
  urldate = {2025-06-12},
  abstract = {It is important, when writing opinion essays, for students to consider and integrate both arguments and counterarguments to develop a final conclusion. In this article, the authors explored the effect of criteria instruction and a graphic organizer to promote integration of arguments and counterarguments. The researchers randomly assigned 84 participants from an undergraduate educational psychology course to 1 of 4 conditions: training only, organizer only, combined, and control. The graphic organizer resulted in more refutations of counterarguments. However, criteria instruction resulted in better integration of argument and counterargument (with stronger rebuttals and more balanced reasoning). The authors discussed how the 2 interventions may have activated somewhat different argumentation schema in students.},
  keywords = {argument,argumentation,critical thinking,graphic organizers,writing},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T21:57:38.053Z}
}

@online{oakleyMemoryParadoxWhy2025,
  title = {The {{Memory Paradox}}: {{Why Our Brains Need Knowledge}} in an {{Age}} of {{AI}}},
  shorttitle = {The {{Memory Paradox}}},
  author = {Oakley, Barbara and Johnston, Michael and Chen, Kenzen and Jung, Eulho and Sejnowski, Terrence},
  date = {2025-05-12},
  eprinttype = {OSF},
  doi = {10.31234/osf.io/3xye5_v2},
  url = {https://osf.io/3xye5_v2},
  urldate = {2025-06-08},
  abstract = {This chapter offers the first neuroscience-based theory linking the reversal of the Flynn Effect—documented declines in IQ scores across high-income countries since the 1970s—to the growing prevalence of cognitive offloading and pedagogical trends that minimize direct knowledge acquisition. Drawing on cognitive neuroscience, learning theory, and memory systems research, we argue that widespread underuse of the brain’s declarative and procedural systems has weakened internal representations—schemata—that are essential for reasoning, intuition, and expertise. We examine how shifts toward digital dependency and constructivist educational models have reduced opportunities for repeated retrieval, proceduralization, and the formation of robust engrams and neural manifolds. These trends disrupt the consolidation and automatization of biologically secondary knowledge, impairing schema-driven prediction, error correction, and transfer. We propose that the weakening of these memory systems—long before neurodegeneration sets in—may explain recent cognitive declines more plausibly than purely environmental or genetic accounts. The chapter closes by outlining implications for cognitive theory, educational practice, and AI-era learning environments. Rather than viewing memory as outdated in a world of instant information access, we argue that internal knowledge remains foundational for deep learning and that cognitive augmentation requires—not replaces—biological memory.},
  langid = {american},
  pubstate = {prepublished},
  keywords = {/unread,artificial intelligence,Cognitive offloading,Engram,Flynn Effect,genAI,Intelligence decline,Memory,neuroscience of education,Schema formation},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2025-06-09T21:57:09.600Z},
  file = {/Users/andrew/Zotero/storage/HR9ANBS7/Oakley et al. - 2025 - The Memory Paradox Why Our Brains Need Knowledge in an Age of AI.pdf}
}

@misc{openaiDRThoughtsAI2025,
  title = {{{DR}}: {{Thoughts}} of {{AI}} vs {{Human}}},
  shorttitle = {{{ChatGPT Deep Research}}: {{Thougts AI}} vs {{Human}}},
  author = {OpenAI, DeepResearch},
  date = {2025-06-09},
  url = {https://chatgpt.com/share/e/6847354d-951c-8012-961d-fb766500f189},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:26:55.433Z}
}

@online{PapersCodeDeepIRT,
  title = {Papers with {{Code}} - {{Deep-IRT}}: {{Make Deep Learning Based Knowledge Tracing Explainable Using Item Response Theory}}},
  shorttitle = {Papers with {{Code}} - {{Deep-IRT}}},
  url = {https://paperswithcode.com/paper/deep-irt-make-deep-learning-based-knowledge},
  urldate = {2023-02-02},
  abstract = {Implemented in 2 code libraries.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/PBB99XXF/deep-irt-make-deep-learning-based-knowledge.html}
}

@inproceedings{pardosAdaptingBayesianKnowledge2013,
  title = {Adapting {{Bayesian Knowledge Tracing}} to a {{Massive Open Online Course}} in {{edX}}},
  author = {Pardos, Z. and Bergner, Yoav and Seaton, Daniel T. and Pritchard, David E.},
  date = {2013},
  url = {https://www.semanticscholar.org/paper/Adapting-Bayesian-Knowledge-Tracing-to-a-Massive-in-Pardos-Bergner/2e21ae27d4ed14de53a6b0e291dc67ef358bbe07},
  urldate = {2025-06-11},
  abstract = {Open Online Courses (MOOCs) are an increasingly pervasive newcomer to the virtual landscape of higher-education, delivering a wide variety of topics in science, engineering, and the humanities. However, while technological innovation is enabling unprecedented open access to high quality educational material, these systems generally inherit similar homework, exams, and instructional resources to that of their classroom counterparts and currently lack an underlying model with which to talk about learning. In this paper we will show how existing learner modeling techniques based on Bayesian Knowledge Tracing can be adapted to the inaugural course, 6.002x: circuit design, on the edX MOOC platform. We identify three distinct challenges to modeling MOOC data and provide predictive evaluations of the respective modeling approach to each challenge. The challenges identified are; lack of an explicit knowledge component model, allowance for unpenalized multiple problem attempts, and multiple pathways through the system that allow for learning influences outside of the current assessment.},
  eventtitle = {Educational {{Data Mining}}},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T22:20:10.150Z},
  file = {/Users/andrew/Zotero/storage/2DCYKCA3/Pardos et al. - 2013 - Adapting Bayesian Knowledge Tracing to a Massive Open Online Course in edX.pdf}
}

@online{piechDeepKnowledgeTracing2015,
  title = {Deep {{Knowledge Tracing}}},
  author = {Piech, Chris and Spencer, Jonathan and Huang, Jonathan and Ganguli, Surya and Sahami, Mehran and Guibas, Leonidas and Sohl-Dickstein, Jascha},
  date = {2015-06-19},
  eprint = {1506.05908},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1506.05908},
  url = {http://arxiv.org/abs/1506.05908},
  urldate = {2023-02-02},
  abstract = {Knowledge tracing---where a machine models the knowledge of a student as they interact with coursework---is a well established problem in computer supported education. Though effectively modeling student knowledge would have high educational impact, the task has many inherent challenges. In this paper we explore the utility of using Recurrent Neural Networks (RNNs) to model student learning. The RNN family of models have important advantages over previous methods in that they do not require the explicit encoding of human domain knowledge, and can capture more complex representations of student knowledge. Using neural networks results in substantial improvements in prediction performance on a range of knowledge tracing datasets. Moreover the learned model can be used for intelligent curriculum design and allows straightforward interpretation and discovery of structure in student tasks. These results suggest a promising new line of research for knowledge tracing and an exemplary application task for RNNs.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,K.3.1},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/85ZBLP5C/Piech et al. - 2015 - Deep Knowledge Tracing.pdf;/Users/andrew/Zotero/storage/EGWXWAIV/Piech et al. - 2015 - Deep Knowledge Tracing.pdf;/Users/andrew/Zotero/storage/7P27ER3Y/1506.html}
}

@article{rainforthModernBayesianExperimental2024,
  title = {Modern {{Bayesian Experimental Design}}},
  author = {Rainforth, Tom and Foster, Adam and Ivanova, Desi R. and Smith, Freddie Bickford},
  date = {2024-02},
  journaltitle = {Statistical Science},
  volume = {39},
  number = {1},
  pages = {100--114},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/23-STS915},
  url = {https://projecteuclid.org/journals/statistical-science/volume-39/issue-1/Modern-Bayesian-Experimental-Design/10.1214/23-STS915.full},
  urldate = {2025-06-12},
  abstract = {Bayesian experimental design (BED) provides a powerful and general framework for optimizing the design of experiments. However, its deployment often poses substantial computational challenges that can undermine its practical use. In this review, we outline how recent advances have transformed our ability to overcome these challenges and thus utilize BED effectively, before discussing some areas for future development in the field.},
  keywords = {/unread,Active learning,Bayesian adaptive design,Bayesian optimal design,information maximization},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T19:21:53.594Z}
}

@book{reichFailureDisruptWhy2020,
  title = {Failure to {{Disrupt}}: {{Why Technology Alone Can}}’t {{Transform Education}}},
  shorttitle = {Failure to {{Disrupt}}},
  author = {Reich, Justin},
  date = {2020},
  publisher = {Harvard University Press},
  location = {Cambridge London},
  abstract = {A leader in educational technology separates truth from hype, explaining what tech can―and can’t―do to transform our classrooms.Proponents of large-scale learning have boldly promised that technology can disrupt traditional approaches to schooling, radically accelerating learning and democratizing education. Much-publicized experiments, often underwritten by Silicon Valley entrepreneurs, have been launched at elite universities and in elementary schools in the poorest neighborhoods. Such was the excitement that, in 2012, the New York Times declared the “year of the MOOC.” Less than a decade later, that pronouncement seems premature.In Failure to Disrupt: Why Technology Alone Can’t Transform Education, Justin Reich delivers a sobering report card on the latest supposedly transformative educational technologies. Reich takes readers on a tour of MOOCs, autograders, computerized “intelligent tutors,” and other educational technologies whose problems and paradoxes have bedeviled educators. Learning technologies―even those that are free to access―often provide the greatest benefit to affluent students and do little to combat growing inequality in education. And institutions and investors often favor programs that scale up quickly, but at the expense of true innovation. It turns out that technology cannot by itself disrupt education or provide shortcuts past the hard road of institutional change.Technology does have a crucial role to play in the future of education, Reich concludes. We still need new teaching tools, and classroom experimentation should be encouraged. But successful reform efforts will focus on incremental improvements, not the next killer app.},
  isbn = {978-0-674-08904-4},
  langid = {english},
  pagetotal = {336},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T12:27:10.273Z}
}

@online{reichNewTheoryArrival2024,
  title = {Toward a {{New Theory}} of {{Arrival Technologies}}},
  author = {Reich, Justin and Dukes, Jesse},
  date = {2024-11-14},
  eprinttype = {OSF},
  doi = {10.35542/osf.io/x6vn7},
  url = {https://osf.io/x6vn7},
  urldate = {2024-11-21},
  abstract = {We propose a distinction between adoption technologies and arrival technologies, and we call for the development of a new theory of arrival technologies. Most education technologies are adopted through a process of planning and procurement. By contrast, ChatGPT arrived. It entered schools without evaluation, assessment of risks and benefits, training for educators, or any other adoption steps that historically would have been considered indispensable to effective technology integration. The emergence of ubiquitous, individual mobile technologies owned by secondary and post-secondary students suggests that ChatGPT may be only the first in a parade of arrival technologies in the years ahead. A new theory of arrival technologies, grounded in the experience of students, teachers, and school leaders managing the arrival of ChatGPT, may prove essential to the future of education technology practice, policy, and research.},
  langid = {american},
  pubstate = {prepublished},
  keywords = {/unread,AI,ChatGPT,education technology,genAI,theory},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T12:21:15.098Z},
  file = {/Users/andrew/Zotero/storage/ACP8U9FK/Reich and Dukes - 2024 - Toward a New Theory of Arrival Technologies.pdf}
}

@article{rittle-johnsonElicitingExplanationsConstraints2017,
  title = {Eliciting Explanations: {{Constraints}} on When Self-Explanation Aids Learning},
  shorttitle = {Eliciting Explanations},
  author = {Rittle-Johnson, Bethany and Loehr, Abbey M.},
  date = {2017-10-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {24},
  number = {5},
  pages = {1501--1510},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1079-5},
  url = {https://doi.org/10.3758/s13423-016-1079-5},
  urldate = {2025-06-13},
  abstract = {Generating explanations for oneself in an attempt to make sense of new information (i.e., self-explanation) is often a powerful learning technique. Despite its general effectiveness, in a growing number of studies, prompting for self-explanation improved some aspects of learning, but reduced learning of other aspects. Drawing on this recent research, as well as on research comparing self-explanation under different conditions, we propose four constraints on the effectiveness of self-explanation. First, self-explanation promotes attention to particular types of information, so it is better suited to promote particular learning outcomes in particular types of domains, such as transfer in domains guided by general principles or heuristics. Second, self-explaining a variety of types of information can improve learning, but explaining one’s own solution methods or choices may reduce learning under certain conditions. Third, explanation prompts focus effort on particular aspects of the to-be-learned material, potentially drawing effort away from other important information. Explanation prompts must be carefully designed to align with target learning outcomes. Fourth, prompted self-explanation often promotes learning better than unguided studying, but alternative instructional techniques may be more effective under some conditions. Attention to these constraints should optimize the effectiveness of self-explanation as an instructional technique in future research and practice.},
  langid = {english},
  keywords = {/unread,Instructional methods,Instructional Theory,Learning and Instruction,Learning Psychology,Learning techniques,Self incompatability,Self-efficacy,Self-explanation,Self-Regulation,Transfer and retention},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-13T10:11:29.371Z},
  file = {/Users/andrew/Zotero/storage/BDVMIMY2/Rittle-Johnson and Loehr - 2017 - Eliciting explanations Constraints on when self-explanation aids learning.pdf}
}

@article{roedigerCriticalRoleRetrieval2011,
  title = {The Critical Role of Retrieval Practice in Long-Term Retention},
  author = {Roediger, Henry L. and Butler, Andrew C.},
  date = {2011-01-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {15},
  number = {1},
  pages = {20--27},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2010.09.003},
  url = {https://www.sciencedirect.com/science/article/pii/S1364661310002081},
  urldate = {2025-06-12},
  abstract = {Learning is usually thought to occur during episodes of studying, whereas retrieval of information on testing simply serves to assess what was learned. We review research that contradicts this traditional view by demonstrating that retrieval practice is actually a powerful mnemonic enhancer, often producing large gains in long-term retention relative to repeated studying. Retrieval practice is often effective even without feedback (i.e. giving the correct answer), but feedback enhances the benefits of testing. In addition, retrieval practice promotes the acquisition of knowledge that can be flexibly retrieved and transferred to different contexts. The power of retrieval practice in consolidating memories has important implications for both the study of memory and its application to educational practice.},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T20:12:24.815Z},
  file = {/Users/andrew/Zotero/storage/R9GL8BUK/Roediger and Butler - 2011 - The critical role of retrieval practice in long-term retention.pdf;/Users/andrew/Zotero/storage/EKJVB2HJ/S1364661310002081.html}
}

@article{roedigerTestenhancedLearningTaking2006,
  title = {Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention},
  shorttitle = {Test-Enhanced Learning},
  author = {Roediger, Henry L. and Karpicke, Jeffrey D.},
  date = {2006-03},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {17},
  number = {3},
  eprint = {16507066},
  eprinttype = {pubmed},
  pages = {249--255},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2006.01693.x},
  abstract = {Taking a memory test not only assesses what one knows, but also enhances later retention, a phenomenon known as the testing effect. We studied this effect with educationally relevant materials and investigated whether testing facilitates learning only because tests offer an opportunity to restudy material. In two experiments, students studied prose passages and took one or three immediate free-recall tests, without feedback, or restudied the material the same number of times as the students who received tests. Students then took a final retention test 5 min, 2 days, or 1 week later. When the final test was given after 5 min, repeated studying improved recall relative to repeated testing. However, on the delayed tests, prior testing produced substantially greater retention than studying, even though repeated studying increased students' confidence in their ability to remember the material. Testing is a powerful means of improving learning, not just assessing it.},
  langid = {english},
  keywords = {/unread,Educational Measurement,Humans,Learning,Memory,Mental Recall,Neuropsychological Tests,Practice Psychological,Retention Psychology,Students,Time Factors},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T21:48:54.316Z}
}

@article{rohrerInterleavingHelpsStudents2012,
  title = {Interleaving {{Helps Students Distinguish}} among {{Similar Concepts}}},
  author = {Rohrer, Doug},
  date = {2012-09-01},
  journaltitle = {Educational Psychology Review},
  shortjournal = {Educ Psychol Rev},
  volume = {24},
  number = {3},
  pages = {355--367},
  issn = {1573-336X},
  doi = {10.1007/s10648-012-9201-3},
  url = {https://doi.org/10.1007/s10648-012-9201-3},
  urldate = {2025-06-22},
  abstract = {When students encounter a set of concepts (or terms or principles) that are similar in some way, they often confuse one with another. For instance, they might mistake one word for another word with a similar spelling (e.g., allusion instead of illusion) or choose the wrong strategy for a mathematics problem because it resembles a different kind of problem. By one proposition explored in this review, these kinds of errors occur more frequently when all exposures to one of the concepts are grouped together. For instance, in most middle school science texts, the questions in each assignment are devoted to the same concept, and this blocking of exposures ensures that students need not learn to distinguish between two similar concepts. In an alternative approach described in this review, exposures to each concept are interleaved with exposures to other concepts, so that a question on one concept is followed by a question on a different concept. In a number of experiments that have compared interleaving and blocking, interleaving produced better scores on final tests of learning. The evidence is limited, though, and ecologically valid studies are needed. Still, a prudent reading of the data suggests that at least a portion of the exposures should be interleaved.},
  langid = {english},
  keywords = {/unread,Blocked,Concept Formation,Conceptual Analysis,Interleave,Intermediality,Learning,Learning and Instruction,Learning Process,Math,Problem Solving,Spacing},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T21:51:58.581Z},
  file = {/Users/andrew/Zotero/storage/URA2I5V3/Rohrer - 2012 - Interleaving Helps Students Distinguish among Similar Concepts.pdf}
}

@online{scarlatosExploringKnowledgeTracing2024,
  title = {Exploring {{Knowledge Tracing}} in {{Tutor-Student Dialogues}} Using {{LLMs}}},
  author = {Scarlatos, Alexander and Baker, Ryan S. and Lan, Andrew},
  date = {2024-12-10},
  eprint = {2409.16490},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.16490},
  url = {http://arxiv.org/abs/2409.16490},
  urldate = {2025-06-07},
  abstract = {Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn, i.e., a tutor utterance posing a task or a student utterance that responds to it. We also evaluate whether the student responds correctly to the tutor and verify the LLM's accuracy using human expert annotations. We then apply a range of knowledge tracing (KT) methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogueKT and outline multiple avenues for future work.},
  pubstate = {prepublished},
  version = {2},
  keywords = {/unread,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Machine Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T21:59:05.710Z},
  file = {/Users/andrew/Zotero/storage/K9IGXR9P/Scarlatos et al. - 2024 - Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs.pdf;/Users/andrew/Zotero/storage/2XSDQ3MF/2409.html}
}

@article{scarlatosExploringKnowledgeTracing2024a,
  title = {Exploring {{Knowledge Tracing}} in {{Tutor-Student Dialogues}}},
  author = {Scarlatos, Alexander and Lan, Andrew S.},
  date = {2024-01-01},
  journaltitle = {CoRR},
  url = {https://openreview.net/forum?id=wz9AccYbb4},
  urldate = {2025-06-11},
  abstract = {Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have primarily studied how to make LLMs follow tutoring principles but not how to model student behavior in dialogues. However, analyzing student dialogue turns can serve as a formative assessment, since open-ended student discourse may indicate their knowledge levels and reveal specific misconceptions. In this work, we present a first attempt at performing knowledge tracing (KT) in tutor-student dialogues. We propose LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn and diagnose whether the student responds correctly to the tutor, and verify the LLM's effectiveness via an expert human evaluation. We then apply a range of KT methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogue KT and outline multiple avenues for future work.},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T22:51:49.896Z},
  file = {/Users/andrew/Zotero/storage/I2JV4XL4/Scarlatos and Lan - 2024 - Exploring Knowledge Tracing in Tutor-Student Dialogues.pdf}
}

@inproceedings{scarlatosExploringKnowledgeTracing2025,
  title = {Exploring {{Knowledge Tracing}} in {{Tutor-Student Dialogues}} Using {{LLMs}}},
  booktitle = {Proceedings of the 15th {{International Learning Analytics}} and {{Knowledge Conference}}},
  author = {Scarlatos, Alexander and Baker, Ryan S. and Lan, Andrew},
  date = {2025-03-03},
  eprint = {2409.16490},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {249--259},
  doi = {10.1145/3706468.3706501},
  url = {http://arxiv.org/abs/2409.16490},
  urldate = {2025-10-08},
  abstract = {Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn, i.e., a tutor utterance posing a task or a student utterance that responds to it. We also evaluate whether the student responds correctly to the tutor and verify the LLM's accuracy using human expert annotations. We then apply a range of knowledge tracing (KT) methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogueKT and outline multiple avenues for future work.},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Machine Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-10-08T15:17:42.873Z},
  file = {/Users/andrew/Zotero/storage/9R2G88XZ/Scarlatos et al. - 2025 - Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs.pdf;/Users/andrew/Zotero/storage/VXI84DUR/2409.html}
}

@article{schulzSchlussberichtKIKompetenzenIngenieursStudierenden,
  title = {Schlussbericht: KI-Kompetenzen von Ingenieurs-Studierenden (KI-King)},
  author = {Schulz, Nicola and Rehm, Silvan},
  langid = {ngerman},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-03-14T14:12:17.016Z},
  file = {/Users/andrew/Zotero/storage/RP2TQ5S2/Schulz and Rehm - Schlussbericht KI-Kompetenzen von Ingenieurs-Studierenden (KI-King).pdf}
}

@online{sharmaUnderstandingSycophancyLanguage2023,
  title = {Towards {{Understanding Sycophancy}} in {{Language Models}}},
  author = {Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and Duvenaud, David and Askell, Amanda and Bowman, Samuel R. and Cheng, Newton and Durmus, Esin and Hatfield-Dodds, Zac and Johnston, Scott R. and Kravec, Shauna and Maxwell, Timothy and McCandlish, Sam and Ndousse, Kamal and Rausch, Oliver and Schiefer, Nicholas and Yan, Da and Zhang, Miranda and Perez, Ethan},
  date = {2023-10-27},
  eprint = {2310.13548},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2310.13548},
  url = {http://arxiv.org/abs/2310.13548},
  urldate = {2024-09-08},
  abstract = {Human feedback is commonly utilized to finetune AI assistants. But human feedback may also encourage model responses that match user beliefs over truthful ones, a behaviour known as sycophancy. We investigate the prevalence of sycophancy in models whose finetuning procedure made use of human feedback, and the potential role of human preference judgments in such behavior. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophancy across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a non-negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of state-of-the-art AI assistants, likely driven in part by human preference judgments favoring sycophantic responses.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,I.2.6,Statistics - Machine Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-11-25T09:41:06.980Z},
  file = {/Users/andrew/Zotero/storage/9MVIZR3V/Sharma et al. - 2023 - Towards Understanding Sycophancy in Language Models.pdf;/Users/andrew/Zotero/storage/9L2IEHJ3/2310.html}
}

@article{shojaeeIllusionThinkingUnderstanding,
  title = {The {{Illusion}} of {{Thinking}}: {{Understanding}} the {{Strengths}} and {{Limitations}} of {{Reasoning Models}} via the {{Lens}} of {{Problem Complexity}}},
  author = {Shojaee, Parshin and Mirzadeh, Iman and Alizadeh, Keivan and Horton, Maxwell and Bengio, Samy and Farajtabar, Mehrdad},
  abstract = {Recent generations of frontier language models have introduced Large Reasoning Models (LRMs) that generate detailed thinking processes before providing answers. While these models demonstrate improved performance on reasoning benchmarks, their fundamental capabilities, scaling properties, and limitations remain insufficiently understood. Current evaluations primarily focus on established mathematical and coding benchmarks, emphasizing final answer accuracy. However, this evaluation paradigm often suffers from data contamination and does not provide insights into the reasoning traces’ structure and quality. In this work, we systematically investigate these gaps with the help of controllable puzzle environments that allow precise manipulation of compositional complexity while maintaining consistent logical structures. This setup enables the analysis of not only final answers but also the internal reasoning traces, offering insights into how LRMs “think”. Through extensive experimentation across diverse puzzles, we show that frontier LRMs face a complete accuracy collapse beyond certain complexities. Moreover, they exhibit a counterintuitive scaling limit: their reasoning effort increases with problem complexity up to a point, then declines despite having an adequate token budget. By comparing LRMs with their standard LLM counterparts under equivalent inference compute, we identify three performance regimes: (1) lowcomplexity tasks where standard models surprisingly outperform LRMs, (2) medium-complexity tasks where additional thinking in LRMs demonstrates advantage, and (3) high-complexity tasks where both models experience complete collapse. We found that LRMs have limitations in exact computation: they fail to use explicit algorithms and reason inconsistently across puzzles. We also investigate the reasoning traces in more depth, studying the patterns of explored solutions and analyzing the models’ computational behavior, shedding light on their strengths, limitations, and ultimately raising crucial questions about their true reasoning capabilities.},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:05:30.876Z},
  file = {/Users/andrew/Zotero/storage/NRJCQQPM/Shojaee et al. - The Illusion of Thinking Understanding the Strengths and Limitations of Reasoning Models via the Le.pdf}
}

@article{sinhaWhenProblemSolving2021,
  title = {When {{Problem Solving Followed}} by {{Instruction Works}}: {{Evidence}} for {{Productive Failure}}},
  shorttitle = {When {{Problem Solving Followed}} by {{Instruction Works}}},
  author = {Sinha, Tanmay and Kapur, Manu},
  date = {2021-10-01},
  journaltitle = {Review of Educational Research},
  volume = {91},
  number = {5},
  pages = {761--798},
  publisher = {American Educational Research Association},
  issn = {0034-6543},
  doi = {10.3102/00346543211019105},
  url = {https://doi.org/10.3102/00346543211019105},
  urldate = {2025-06-12},
  abstract = {When learning a new concept, should students engage in problem solving followed by instruction (PS-I) or instruction followed by problem solving (I-PS)? Noting that there is a passionate debate about the design of initial learning, we report evidence from a meta-analysis of 53 studies with 166 comparisons that compared PS-I with I-PS design. Our results showed a significant, moderate effect in favor of PS-I (Hedge’s g 0.36 [95\% confidence interval 0.20; 0.51]). The effects were even stronger (Hedge’s g ranging between 0.37 and 0.58) when PS-I was implemented with high fidelity to the principles of Productive Failure (PF), a subset variant of PS-I design. Students’ grade level, intervention time span, and its (quasi-)experimental nature contributed to the efficacy of PS-I over I-PS designs. Contrasting trends were, however, observed for younger age learners (second to fifth graders) and for the learning of domain-general skills, for which effect sizes favored I-PS. Overall, an estimation of true effect sizes after accounting for publication bias suggested a strong effect size favoring PS-I (Hedge’s g 0.87).},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T18:25:15.269Z},
  file = {/Users/andrew/Zotero/storage/KTT69ZXL/Sinha and Kapur - 2021 - When Problem Solving Followed by Instruction Works Evidence for Productive Failure.pdf}
}

@article{slameckaGenerationEffectDelineation1978,
  title = {The Generation Effect: {{Delineation}} of a Phenomenon},
  shorttitle = {The Generation Effect},
  author = {Slamecka, Norman J. and Graf, Peter},
  date = {1978},
  journaltitle = {Journal of Experimental Psychology: Human Learning and Memory},
  volume = {4},
  number = {6},
  pages = {592--604},
  publisher = {American Psychological Association},
  location = {US},
  issn = {0096-1515},
  doi = {10.1037/0278-7393.4.6.592},
  abstract = {Reports on 5 experiments with 96 undergraduates, comparing memory for words that were generated by the Ss themselves with the same words when they were simply presented to be read. In all cases, performance in the Generate condition was superior to that in the Read condition. This held for measures of cued and uncued recognition, free and cued recall, and confidence ratings. The phenomenon persisted across variations in encoding rules, timed or self-paced presentation, presence or absence of test information, and between- or within-Ss designs. The effect was specific to the response items under recognition testing but not under cued recall. A number of potential explanatory principles are considered and their difficulties enumerated. It is concluded that the generation effect is real and that it poses an interesting interpretative problem. (23 ref) (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
  keywords = {/unread,Recall (Learning),Short Term Memory,Words (Phonetic Units)},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T13:45:27.312Z},
  file = {/Users/andrew/Zotero/storage/QAVY3IIC/Slamecka and Graf - The Generation Effect Delineation of a Phenomenon.pdf;/Users/andrew/Zotero/storage/HHB9RPTW/1980-20399-001.html}
}

@article{sparrowGoogleEffectsMemory2011,
  title = {Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips},
  shorttitle = {Google Effects on Memory},
  author = {Sparrow, Betsy and Liu, Jenny and Wegner, Daniel M.},
  date = {2011-08-05},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {333},
  number = {6043},
  eprint = {21764755},
  eprinttype = {pubmed},
  pages = {776--778},
  issn = {1095-9203},
  doi = {10.1126/science.1207745},
  abstract = {The advent of the Internet, with sophisticated algorithmic search engines, has made accessing information as easy as lifting a finger. No longer do we have to make costly efforts to find the things we want. We can "Google" the old classmate, find articles online, or look up the actor who was on the tip of our tongue. The results of four studies suggest that when faced with difficult questions, people are primed to think about computers and that when people expect to have future access to information, they have lower rates of recall of the information itself and enhanced recall instead for where to access it. The Internet has become a primary form of external or transactive memory, where information is stored collectively outside ourselves.},
  langid = {english},
  keywords = {/unread,Cognition,Computers,Cues,Female,Humans,Information Storage and Retrieval,Internet,Male,Memory,Mental Recall,Reaction Time,Search Engine,Stroop Test},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T13:47:22.849Z}
}

@article{stadlerCognitiveEaseCost2024,
  title = {Cognitive Ease at a Cost: {{LLMs}} Reduce Mental Effort but Compromise Depth in Student Scientific Inquiry},
  shorttitle = {Cognitive Ease at a Cost},
  author = {Stadler, Matthias and Bannert, Maria and Sailer, Michael},
  date = {2024-11-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {160},
  pages = {108386},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2024.108386},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563224002541},
  urldate = {2025-08-21},
  abstract = {This study explores the cognitive load and learning outcomes associated with using large language models (LLMs) versus traditional search engines for information gathering during learning. A total of 91 university students were randomly assigned to either use ChatGPT3.5 or Google to research the socio-scientific issue of nanoparticles in sunscreen to derive valid recommendations and justifications. The study aimed to investigate potential differences in cognitive load, as well as the quality and homogeneity of the students' recommendations and justifications. Results indicated that students using LLMs experienced significantly lower cognitive load. However, despite this reduction, these students demonstrated lower-quality reasoning and argumentation in their final recommendations compared to those who used traditional search engines. Further, the homogeneity of the recommendations and justifications did not differ significantly between the two groups, suggesting that LLMs did not restrict the diversity of students’ perspectives. These findings highlight the nuanced implications of digital tools on learning, suggesting that while LLMs can decrease the cognitive burden associated with information gathering during a learning task, they may not promote deeper engagement with content necessary for high-quality learning per se.},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-21T20:08:00.956Z},
  file = {/Users/andrew/Zotero/storage/3IR5NTFH/Stadler et al. - 2024 - Cognitive ease at a cost LLMs reduce mental effort but compromise depth in student scientific inqui.pdf;/Users/andrew/Zotero/storage/BTKNIRJD/S0747563224002541.html}
}

@book{surmaDevelopingCurriculumDeep2025,
  title = {Developing {{Curriculum}} for {{Deep Thinking}}: {{The Knowledge Revival}}},
  shorttitle = {Developing {{Curriculum}} for {{Deep Thinking}}},
  author = {Surma, Tim and Vanhees, Claudio and Wils, Michiel and Nijlunsing, Jasper and Crato, Nuno and Hattie, John and Muijs, Daniel and Rata, Elizabeth and Wiliam, Dylan and Kirschner, Paul A.},
  date = {2025},
  series = {{{SpringerBriefs}} in {{Education}}},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-74661-1},
  url = {https://link.springer.com/10.1007/978-3-031-74661-1},
  urldate = {2025-07-02},
  isbn = {978-3-031-74660-4 978-3-031-74661-1},
  langid = {english},
  keywords = {Building knowledge rich curriculum,Cognitive psychology in curriculum design,Cognitive psychology in knowledge-rich curricula,Curriculum building with case studies,Effective curriculum design for deep learning,Enhancing critical thinking through knowledge,Enhancing problem solving through knowledge,Global trends in educational curricula,Implementing knowledge-rich curricula,Knowledge in curricula,Knowledge rich curriculum,Knowledge-rich curriculum development,Open Access,Powerful knowledge theory in education},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-07-02T11:38:43.251Z},
  file = {/Users/andrew/Zotero/storage/LYTCEFDI/Surma et al. - 2025 - Developing Curriculum for Deep Thinking The Knowledge Revival.pdf}
}

@article{swellerCognitiveLoadProblem1988,
  title = {Cognitive Load during Problem Solving: {{Effects}} on Learning},
  shorttitle = {Cognitive Load during Problem Solving},
  author = {Sweller, John},
  date = {1988-04-01},
  journaltitle = {Cognitive Science},
  shortjournal = {Cognitive Science},
  volume = {12},
  number = {2},
  pages = {257--285},
  issn = {0364-0213},
  doi = {10.1016/0364-0213(88)90023-7},
  url = {https://www.sciencedirect.com/science/article/pii/0364021388900237},
  urldate = {2025-11-19},
  abstract = {Considerable evidence indicates that domain specific knowledge in the form of schemas is the primary factor distinguishing experts from novices in problem-solving skill. Evidence that conventional problem-solving activity is not effective in schema acquisition is also accumulating. It is suggested that a major reason for the ineffectiveness of problem solving as a learning device, is that the cognitive processes required by the two activities overlap insufficiently, and that conventional problem solving in the form of means-ends analysis requires a relatively large amount of cognitive processing capacity which is consequently unavailable for schema acquisition. A computational model and experimental evidence provide support for this contention. Theoretical and practical implications are discussed.},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-11-19T03:14:30.123Z},
  file = {/Users/andrew/Zotero/storage/ZG8ZD59C/Sweller - 1988 - Cognitive load during problem solving Effects on learning.pdf;/Users/andrew/Zotero/storage/2MXGEZCP/0364021388900237.html}
}

@article{swellerCognitiveLoadTheory2024,
  title = {Cognitive Load Theory and Individual Differences},
  author = {Sweller, John},
  date = {2024-02-01},
  journaltitle = {Learning and Individual Differences},
  shortjournal = {Learning and Individual Differences},
  volume = {110},
  pages = {102423},
  issn = {1041-6080},
  doi = {10.1016/j.lindif.2024.102423},
  url = {https://www.sciencedirect.com/science/article/pii/S1041608024000165},
  urldate = {2025-06-22},
  abstract = {Cognitive load theory is an instructional theory based on the following assumptions. (1) Information can be divided into biologically primary information that we have evolved to process and acquire unconsciously, and secondary information that requires conscious effort. (2) Secondary information is either acquired during problem solving or from other people. It is processed by a limited capacity, limited duration working memory before being stored for subsequent use in long-term memory. Once stored, information may be transferred back to working memory to govern action relevant to the extant environment. Working memory has no known capacity or duration limits when dealing with information transferred back from long-term memory. (3) The major consequence that flows from instruction is the accumulation of information in long-term memory. (4) That differential knowledge results in individual differences in expertise and provides a major source, possibly the only source, of modifiable cognitive differences between learners. (5) Learners with differential knowledge held in long-term memory require different instructional procedures leading to the expertise reversal effects of cognitive load theory. Educational relevance Cognitive load theory is an instructional theory based on our knowledge of evolutionary psychology leading to human cognitive architecture. That architecture specifies individual differences due to either biological or environmental factors. Information held in long-term memory provides the major source of environmentally mediated individual differences. The theory uses randomised, controlled trials to determine instructional effectiveness.},
  keywords = {Cognitive load theory,Element interactivity,Individual differences through learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T14:00:42.126Z},
  file = {/Users/andrew/Zotero/storage/6VTN3QM7/S1041608024000165.html}
}

@article{swellerCognitiveLoadTheory2024a,
  title = {Cognitive Load Theory and Individual Differences},
  author = {Sweller, John},
  date = {2024-02-01},
  journaltitle = {Learning and Individual Differences},
  shortjournal = {Learning and Individual Differences},
  volume = {110},
  pages = {102423},
  issn = {1041-6080},
  doi = {10.1016/j.lindif.2024.102423},
  url = {https://www.sciencedirect.com/science/article/pii/S1041608024000165},
  urldate = {2025-09-15},
  abstract = {Cognitive load theory is an instructional theory based on the following assumptions. (1) Information can be divided into biologically primary information that we have evolved to process and acquire unconsciously, and secondary information that requires conscious effort. (2) Secondary information is either acquired during problem solving or from other people. It is processed by a limited capacity, limited duration working memory before being stored for subsequent use in long-term memory. Once stored, information may be transferred back to working memory to govern action relevant to the extant environment. Working memory has no known capacity or duration limits when dealing with information transferred back from long-term memory. (3) The major consequence that flows from instruction is the accumulation of information in long-term memory. (4) That differential knowledge results in individual differences in expertise and provides a major source, possibly the only source, of modifiable cognitive differences between learners. (5) Learners with differential knowledge held in long-term memory require different instructional procedures leading to the expertise reversal effects of cognitive load theory. Educational relevance Cognitive load theory is an instructional theory based on our knowledge of evolutionary psychology leading to human cognitive architecture. That architecture specifies individual differences due to either biological or environmental factors. Information held in long-term memory provides the major source of environmentally mediated individual differences. The theory uses randomised, controlled trials to determine instructional effectiveness.},
  keywords = {/unread,Cognitive load theory,Element interactivity,Individual differences through learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-09-15T20:26:50.447Z},
  file = {/Users/andrew/Zotero/storage/DH68HTTS/Sweller - 2024 - Cognitive load theory and individual differences.pdf;/Users/andrew/Zotero/storage/RVKMKWKN/S1041608024000165.html}
}

@article{swellerDevelopmentCognitiveLoad2023,
  title = {The {{Development}} of {{Cognitive Load Theory}}: {{Replication Crises}} and {{Incorporation}} of {{Other Theories Can Lead}} to {{Theory Expansion}}},
  shorttitle = {The {{Development}} of {{Cognitive Load Theory}}},
  author = {Sweller, John},
  date = {2023-09-19},
  journaltitle = {Educational Psychology Review},
  shortjournal = {Educ Psychol Rev},
  volume = {35},
  number = {4},
  pages = {95},
  issn = {1573-336X},
  doi = {10.1007/s10648-023-09817-2},
  url = {https://doi.org/10.1007/s10648-023-09817-2},
  urldate = {2025-06-20},
  abstract = {Cognitive load theory has been in development since the 1980s. Much of the impetus for that development has come from firstly, replication failures using randomised controlled trials and secondly, from the incorporation of other theories into cognitive load theory. Both have led to theory expansion. The immediate cause of the so-called “replication crisis” in psychology and other disciplines is a failure to replicate previous empirical findings. Using cognitive load theory as an example, I argue that the appearance of contradictory evidence does not necessarily derive from a failure to properly collect data. Rather, it can be caused by initially insufficiently detailed theories, with increasing detail often revealing the reason for a failure to replicate. For cognitive load theory, each failure to replicate, rather than being a negative, contributed to the further development of the theory. In addition, the theory has developed over many years by closely incorporating other theories associated with human cognitive architecture and evolutionary psychology. In this paper, I discuss some of the developmental milestones associated with cognitive load theory and how they were informed by replication failures and theory integration.},
  langid = {english},
  keywords = {Attribution Theory,Cognitive load theory,Cognitive Psychology,Development Theory,Evolution by natural selection,Evolutionary Theory,Human cognitive architecture,Instructional design,Instructional Theory,Long-term memory,Replication crisis,Theoretical Psychology,Working memory},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-20T07:36:10.645Z},
  file = {/Users/andrew/Zotero/storage/EEGS85FQ/Sweller - 2023 - The Development of Cognitive Load Theory Replication Crises and Incorporation of Other Theories Can.pdf}
}

@online{toner-rodgersArtificialIntelligenceScientific2025,
  title = {Artificial {{Intelligence}}, {{Scientific Discovery}}, and {{Product Innovation}}},
  author = {Toner-Rodgers, Aidan},
  date = {2025-05-20},
  eprint = {2412.17866},
  eprinttype = {arXiv},
  eprintclass = {econ},
  doi = {10.48550/arXiv.2412.17866},
  url = {http://arxiv.org/abs/2412.17866},
  urldate = {2025-08-17},
  abstract = {This paper studies the impact of artificial intelligence on innovation, exploiting the randomized introduction of a new materials discovery technology to 1,018 scientists in the R\&D lab of a large U.S. firm. AI-assisted researchers discover 44\% more materials, resulting in a 39\% increase in patent filings and a 17\% rise in downstream product innovation. These compounds possess more novel chemical structures and lead to more radical inventions. However, the technology has strikingly disparate effects across the productivity distribution: while the bottom third of scientists see little benefit, the output of top researchers nearly doubles. Investigating the mechanisms behind these results, I show that AI automates 57\% of "idea-generation" tasks, reallocating researchers to the new task of evaluating model-produced candidate materials. Top scientists leverage their domain knowledge to prioritize promising AI suggestions, while others waste significant resources testing false positives. Together, these findings demonstrate the potential of AI-augmented research and highlight the complementarity between algorithms and expertise in the innovative process. Survey evidence reveals that these gains come at a cost, however, as 82\% of scientists report reduced satisfaction with their work due to decreased creativity and skill underutilization.},
  pubstate = {prepublished},
  keywords = {/unread,Economics - General Economics,Quantitative Finance - Economics},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-17T20:02:24.530Z},
  file = {/Users/andrew/Zotero/storage/9Q2CS2MM/2412.html}
}

@article{vanlehnRelativeEffectivenessHuman2011,
  title = {The {{Relative Effectiveness}} of {{Human Tutoring}}, {{Intelligent Tutoring Systems}}, and {{Other Tutoring Systems}}},
  author = {family=VanLEHN, given=KURT, given-i=KURT},
  date = {2011-10-01},
  journaltitle = {Educational Psychologist},
  volume = {46},
  number = {4},
  pages = {197--221},
  publisher = {Routledge},
  issn = {0046-1520},
  doi = {10.1080/00461520.2011.611369},
  url = {https://doi.org/10.1080/00461520.2011.611369},
  urldate = {2025-12-10},
  abstract = {This article is a review of experiments comparing the effectiveness of human tutoring, computer tutoring, and no tutoring. “No tutoring” refers to instruction that teaches the same content without tutoring. The computer tutoring systems were divided by their granularity of the user interface interaction into answer-based, step-based, and substep-based tutoring systems. Most intelligent tutoring systems have step-based or substep-based granularities of interaction, whereas most other tutoring systems (often called CAI, CBT, or CAL systems) have answer-based user interfaces. It is widely believed as the granularity of tutoring decreases, the effectiveness increases. In particular, when compared to No tutoring, the effect sizes of answer-based tutoring systems, intelligent tutoring systems, and adult human tutors are believed to be d = 0.3, 1.0, and 2.0 respectively. This review did not confirm these beliefs. Instead, it found that the effect size of human tutoring was much lower: d = 0.79. Moreover, the effect size of intelligent tutoring systems was 0.76, so they are nearly as effective as human tutoring.},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-10T11:20:39.184Z}
}

@article{wangEffectChatGPTStudents2025,
  title = {The Effect of {{ChatGPT}} on Students’ Learning Performance, Learning Perception, and Higher-Order Thinking: Insights from a Meta-Analysis},
  shorttitle = {The Effect of {{ChatGPT}} on Students’ Learning Performance, Learning Perception, and Higher-Order Thinking},
  author = {Wang, Jin and Fan, Wenxiang},
  date = {2025-05-06},
  journaltitle = {Humanities and Social Sciences Communications},
  shortjournal = {Humanit Soc Sci Commun},
  volume = {12},
  number = {1},
  pages = {1--21},
  publisher = {Palgrave},
  issn = {2662-9992},
  doi = {10.1057/s41599-025-04787-y},
  url = {https://www.nature.com/articles/s41599-025-04787-y},
  urldate = {2025-06-09},
  abstract = {As a new type of artificial intelligence, ChatGPT is becoming widely used in learning. However, academic consensus regarding its efficacy remains elusive. This study aimed to assess the effectiveness of ChatGPT in improving students’ learning performance, learning perception, and higher-order thinking through a meta-analysis of 51 research studies published between November 2022 and February 2025. The results indicate that ChatGPT has a large positive impact on improving learning performance (g\,=\,0.867) and a moderately positive impact on enhancing learning perception (g\,=\,0.456) and fostering higher-order thinking (g\,=\,0.457). The impact of ChatGPT on learning performance was moderated by type of course (QB\,=\,64.249, P\,{$<$}\,0.001), learning model (QB\,=\,76.220, P\,{$<$}\,0.001), and duration (QB\,=\,55.998, P\,{$<$}\,0.001); its effect on learning perception was moderated by duration (QB\,=\,19.839, P\,{$<$}\,0.001); and its influence on the development of higher-order thinking was moderated by type of course (QB\,=\,7.811, P\,{$<$}\,0.05) and the role played by ChatGPT (QB\,=\,4.872, P\,{$<$}\,0.05). This study suggests that: (1) appropriate learning scaffolds or educational frameworks (e.g., Bloom’s taxonomy) should be provided when using ChatGPT to develop students’ higher-order thinking; (2) the broad use of ChatGPT at various grade levels and in different types of courses should be encouraged to support diverse learning needs; (3) ChatGPT should be actively integrated into different learning modes to enhance student learning, especially in problem-based learning; (4) continuous use of ChatGPT should be ensured to support student learning, with a recommended duration of 4–8 weeks for more stable effects; (5) ChatGPT should be flexibly integrated into teaching as an intelligent tutor, learning partner, and educational tool. Finally, due to the limited sample size for learning perception and higher-order thinking, and the moderately positive effect, future studies with expanded scope should further explore how to use ChatGPT more effectively to cultivate students’ learning perception and higher-order thinking.},
  langid = {english},
  keywords = {/unread,Education,Science,technology and society},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:20:03.582Z},
  file = {/Users/andrew/Zotero/storage/F99IHAN7/Wang and Fan - 2025 - The effect of ChatGPT on students’ learning performance, learning perception, and higher-order think.pdf}
}

@inproceedings{wangModelingStudentLearning2017,
  title = {Modeling Student Learning Outcomes in Studying Programming Language Course},
  booktitle = {2017 {{Seventh International Conference}} on {{Information Science}} and {{Technology}} ({{ICIST}})},
  author = {Wang, Shanshan and Han, Yong and Wu, Wenjun and Hu, Zhenghui},
  date = {2017-04},
  pages = {263--270},
  doi = {10.1109/ICIST.2017.7926768},
  url = {https://ieeexplore.ieee.org/document/7926768},
  urldate = {2025-04-30},
  abstract = {Learning outcome assessment is of great significance in the field of traditional on-campus teaching especially on the courses of programming languages. In this work, we take advantage of the data offered by our programming assignment judge system and propose a new IRT-BKT model for estimation of learning outcome. This new framework: Item Response Theory (IRT) model that estimates students' initial knowledge status, and joins it with the discrimination and difficulty of each skill estimated to evaluate the probability of knowing a skill before training it. We then estimate parameters learn, guess, and slip probabilities of Bayesian Knowledge Tracing (BKT) Model. Using real data, we show that IRT-BKT model outperforms Item Response Theory and Bayesian Knowledge Tracing in terms of prediction accuracy.},
  eventtitle = {2017 {{Seventh International Conference}} on {{Information Science}} and {{Technology}} ({{ICIST}})},
  keywords = {/unread,Bayes methods,Bayesian Knowledge Tracing,Computer languages,Data models,Decision support systems,Education,Estimation,Item Response Theory,Learning Outcome,Programming,Programming Language},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.461Z},
  file = {/Users/andrew/Zotero/storage/RI3BMZSA/Wang et al. - 2017 - Modeling student learning outcomes in studying programming language course.pdf}
}

@online{wangProblemOrientedSegmentationRetrieval2024,
  title = {Problem-{{Oriented Segmentation}} and {{Retrieval}}: {{Case Study}} on {{Tutoring Conversations}}},
  shorttitle = {Problem-{{Oriented Segmentation}} and {{Retrieval}}},
  author = {Wang, Rose E. and Wirawarn, Pawan and Lam, Kenny and Khattab, Omar and Demszky, Dorottya},
  date = {2024-11-12},
  eprint = {2411.07598},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2411.07598},
  urldate = {2024-11-14},
  abstract = {Many open-ended conversations (e.g., tutoring lessons or business meetings) revolve around pre-defined reference materials, like worksheets or meeting bullets. To provide a framework for studying such conversation structure, we introduce Problem-Oriented Segmentation \& Retrieval (POSR), the task of jointly breaking down conversations into segments and linking each segment to the relevant reference item. As a case study, we apply POSR to education where effectively structuring lessons around problems is critical yet difficult. We present LessonLink, the first dataset of real-world tutoring lessons, featuring 3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT math problems. We define and evaluate several joint and independent approaches for POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT), and large language models (LLMs) methods. Our results highlight that modeling POSR as one joint task is essential: POSR methods outperform independent segmentation and retrieval pipelines by up to +76\% on joint metrics and surpass traditional segmentation methods by up to +78\% on segmentation metrics. We demonstrate POSR's practical impact on downstream education applications, deriving new insights on the language and time use in real-world lesson structures.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/KTFXLVB2/Wang et al. - 2024 - Problem-Oriented Segmentation and Retrieval Case Study on Tutoring Conversations.pdf;/Users/andrew/Zotero/storage/PAUESAER/2411.html}
}

@online{weberGeneralizedHierarchicalGaussian2024,
  title = {The Generalized {{Hierarchical Gaussian Filter}}},
  author = {Weber, Lilian Aline and Waade, Peter Thestrup and Legrand, Nicolas and Møller, Anna Hedvig and Stephan, Klaas Enno and Mathys, Christoph},
  date = {2024-09-04},
  eprint = {2305.10937},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2305.10937},
  url = {http://arxiv.org/abs/2305.10937},
  urldate = {2024-11-02},
  abstract = {Hierarchical Bayesian models of perception and learning feature prominently in contemporary cognitive neuroscience where, for example, they inform computational concepts of mental disorders. This includes predictive coding and hierarchical Gaussian filtering (HGF), which differ in the nature of hierarchical representations. Predictive coding assumes that higher levels in a given hierarchy influence the state (value) of lower levels. In HGF, however, higher levels determine the rate of change at lower levels. Here, we extend the space of generative models underlying HGF to include a form of nonlinear hierarchical coupling between state values akin to predictive coding and artificial neural networks in general. We derive the update equations corresponding to this generalization of HGF and conceptualize them as connecting a network of (belief) nodes where parent nodes either predict the state of child nodes or their rate of change. This enables us to (1) create modular architectures with generic computational steps in each node of the network, and (2) disclose the hierarchical message passing implied by generalized HGF models and to compare this to comparable schemes under predictive coding. We find that the algorithmic architecture instantiated by the generalized HGF is largely compatible with that of predictive coding but extends it with some unique predictions which arise from precision and volatility related computations. Our developments enable highly flexible implementations of hierarchical Bayesian models for empirical data analysis and are available as open source software.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.462Z},
  file = {/Users/andrew/Zotero/storage/EJXRN5WT/Weber et al. - 2024 - The generalized Hierarchical Gaussian Filter.pdf;/Users/andrew/Zotero/storage/MXP9XFWZ/2305.html}
}

@article{weidlichChatGPTEducationEffect2025,
  title = {{{ChatGPT}} in {{Education}}: {{An Effect}} in {{Search}} of a {{Cause}}},
  shorttitle = {{{ChatGPT}} in {{Education}}},
  author = {Weidlich, J. and Gašević, D. and Drachsler, H. and Kirschner, P.},
  date = {2025},
  journaltitle = {Journal of Computer Assisted Learning},
  volume = {41},
  number = {5},
  pages = {e70105},
  issn = {1365-2729},
  doi = {10.1111/jcal.70105},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jcal.70105},
  urldate = {2025-08-16},
  abstract = {Background As researchers rush to investigate the potential of AI tools like ChatGPT to enhance learning, well-documented pitfalls threaten the validity of this emerging research. Issues of media comparison research, where the confounding of instructional methods and technological affordances is unrecognised, may render effects uninterpretable. Objectives Using a recent meta-analysis by Deng et al. (Computers \& Education, 227, 105224) as an example, we revisit key insights from the media/methods debate to highlight recurring conceptual challenges in ChatGPT efficacy studies. Methods This conceptual article contrasts nascent ChatGPT research with the more established literature on Intelligent Tutoring Systems to identify three non-negotiable considerations for interpretable effects: (1) descriptions of the precise nature of the experimental treatment and (2) the activities of the control group, as well as (3) outcome measures as valid indicators of learning. To provide some initial evidence, we audited a subset of primary experiments included in Deng et al.'s meta-analysis, demonstrating that only a small minority of studies satisfied all three non-negotiable considerations. Results and Conclusions Loosely defined treatments, mismatched or opaque controls, and outcome measures with unclear links to durable learning obscure causal claims of this emerging literature. Observed gains cannot, at this time, be confidently attributed to ChatGPT, and meta-analytics effect sizes may over- or understate its benefits. Progress, we argue, will require rigorous designs, transparent reporting, and a critical stance toward “fast science.”},
  langid = {english},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-08-16T10:30:32.774Z},
  file = {/Users/andrew/Zotero/storage/EPCGY4ZR/Weidlich et al. - 2025 - ChatGPT in Education An Effect in Search of a Cause.pdf;/Users/andrew/Zotero/storage/63FBQAHP/jcal.html}
}

@article{willinghamCriticalThinkingWhy2008,
  title = {Critical {{Thinking}}: {{Why Is It So Hard}} to {{Teach}}?},
  shorttitle = {Critical {{Thinking}}},
  author = {Willingham, Daniel T.},
  date = {2008-03},
  journaltitle = {Arts Education Policy Review},
  shortjournal = {Arts Education Policy Review},
  volume = {109},
  number = {4},
  pages = {21--32},
  issn = {1063-2913, 1940-4395},
  doi = {10.3200/AEPR.109.4.21-32},
  url = {http://www.tandfonline.com/doi/abs/10.3200/AEPR.109.4.21-32},
  urldate = {2025-12-09},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-09T09:13:16.294Z},
  file = {/Users/andrew/Zotero/storage/QC28H5P6/Willingham - 2008 - Critical Thinking Why Is It So Hard to Teach.pdf}
}

@article{willinghamOccasionalPaperSeries,
  title = {Occasional {{Paper Series}}: {{How}} to {{Teach Critical Thinking}}},
  author = {Willingham, Daniel T},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-12-09T13:27:16.852Z},
  file = {/Users/andrew/Zotero/storage/SBKDMA7B/Willingham - Occasional Paper Series How to Teach Critical Thinking.pdf}
}

@article{wisniewskiPowerFeedbackRevisited2020,
  title = {The {{Power}} of {{Feedback Revisited}}: {{A Meta-Analysis}} of {{Educational Feedback Research}}},
  shorttitle = {The {{Power}} of {{Feedback Revisited}}},
  author = {Wisniewski, Benedikt and Zierer, Klaus and Hattie, John},
  date = {2020-01-22},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {10},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.03087},
  url = {https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.03087/full},
  urldate = {2025-06-12},
  abstract = {A meta-analysis (435 studies, k = 994, N {$>$} 61,000) of empirical research on the effects of feedback on student learning was conducted with the purpose of replicating and expanding the Visible Learning research (Hattie \& Timperley, 2007; Hattie, 2009; Hattie \& Zierer, 2019) from meta-synthesis. Overall results based on a random-effects model indicate a medium effect (d = 0.48) of feedback on student learning, but the significant heterogeneity in the data shows that feedback cannot be understood as a single consistent form of treatment. A moderator analysis revealed that the impact is substantially influenced by the information content conveyed. Furthermore, feedback has higher impact on cognitive and motor skills outcomes than on motivational and behavioral outcomes. We discuss these findings in the light of the assumptions made in The power of feedback (Hattie \& Timperley, 2007). In general, the results suggest that feedback has rightly become a focus of teaching research and practice. However, they also point towards the necessity of interpreting different forms of feedback as independent measures.},
  langid = {english},
  keywords = {Feedback,Meta-analysis,Student achievement,Student learning (at school),Teaching},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T21:57:38.195Z},
  file = {/Users/andrew/Zotero/storage/LK7JZM43/Wisniewski et al. - 2020 - The Power of Feedback Revisited A Meta-Analysis of Educational Feedback Research.pdf}
}

@article{woodRoleTutoringProblem1976,
  title = {The Role of Tutoring in Problem Solving},
  author = {Wood, David and Bruner, Jerome S. and Ross, Gail},
  date = {1976},
  journaltitle = {Child Psychology \& Psychiatry \& Allied Disciplines},
  volume = {17},
  number = {2},
  pages = {89--100},
  publisher = {Pergamon Press},
  location = {United Kingdom},
  issn = {0021-9630},
  doi = {10.1111/j.1469-7610.1976.tb00381.x},
  abstract = {Studied the interactive, instructional relationship that exists during the tutoring process to determine its effects on the developing child in terms of skill acquisition and problem-solving. 30 3-, 4-, and 5-yr-olds were tutored in the task of constructing a pyramid from complex, interlocking constituent blocks. Results indicate some of the properties of an interactive system of exchange in which the tutor operates with an implicit theory of the learner's acts in order to recruit his attention, reduces degrees of freedom in the task to manageable limits, maintains "direction" in the problem solving, marks critical features, controls frustration, and demonstrates solutions when the learner can recognize them. (16 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {/unread,Interpersonal Interaction,Problem Solving,Skill Learning,Tutoring},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T19:28:47.059Z},
  file = {/Users/andrew/Zotero/storage/IYBWIKVT/Wood et al. - 1976 - The role of tutoring in problem solving.pdf;/Users/andrew/Zotero/storage/97MFKR9M/1976-24805-001.html}
}

@article{xuLargeLanguageModels2025,
  title = {Large Language Models without Grounding Recover Non-Sensorimotor but Not Sensorimotor Features of Human Concepts},
  author = {Xu, Qihui and Peng, Yingying and Nastase, Samuel A. and Chodorow, Martin and Wu, Minghua and Li, Ping},
  date = {2025-06-04},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  pages = {1--16},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-025-02203-8},
  url = {https://www.nature.com/articles/s41562-025-02203-8},
  urldate = {2025-06-09},
  abstract = {To what extent can language give rise to complex conceptual representation? Is multisensory experience essential? Recent large language models (LLMs) challenge the necessity of grounding for concept formation: whether LLMs without grounding nevertheless exhibit human-like representations. Here we compare multidimensional representations of \textasciitilde 4,442 lexical concepts between humans (the Glasgow Norms1, N\,=\,829; and the Lancaster Norms2, N\,=\,3,500) and state-of-the-art LLMs with and without visual learning, across non-sensorimotor, sensory and motor domains. We found that (1) the similarity between model and human representations decreases from non-sensorimotor to sensory domains and is minimal in motor domains, indicating a systematic divergence, and (2) models with visual learning exhibit enhanced similarity with human representations in visual-related dimensions. These results highlight the potential limitations of language in isolation for LLMs and that the integration of diverse modalities can potentially enhance alignment with human conceptual representation.},
  langid = {english},
  keywords = {Human behaviour,Language and linguistics,Science,technology and society},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-09T19:12:11.355Z},
  file = {/Users/andrew/Zotero/storage/5PHRJR2U/Xu et al. - 2025 - Large language models without grounding recover non-sensorimotor but not sensorimotor features of hu.pdf}
}

@article{yangEffectivenessChatGPTAssisting2025,
  title = {The Effectiveness of {{ChatGPT}} in Assisting High School Students in Programming Learning: Evidence from a Quasi-Experimental Research},
  shorttitle = {The Effectiveness of {{ChatGPT}} in Assisting High School Students in Programming Learning},
  author = {Yang, Tzu-Chi and Hsu, Yi-Chuan and Wu, Jiun-Yu},
  date = {2025-01-16},
  journaltitle = {Interactive Learning Environments},
  shortjournal = {Interactive Learning Environments},
  pages = {1--18},
  issn = {1049-4820, 1744-5191},
  doi = {10.1080/10494820.2025.2450659},
  url = {https://www.tandfonline.com/doi/full/10.1080/10494820.2025.2450659},
  urldate = {2025-06-22},
  langid = {english},
  keywords = {/unread},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T16:48:41.136Z},
  file = {/Users/andrew/Zotero/storage/49EQ89ER/Yang et al. - 2025 - The effectiveness of ChatGPT in assisting high school students in programming learning evidence fro.pdf}
}

@article{yangUsingSocraticQuestioning2005,
  title = {Using {{Socratic Questioning}} to {{Promote Critical Thinking Skills Through Asynchronous Discussion Forums}} in {{Distance Learning Environments}}},
  author = {Yang, Ya-Ting C. and , Timothy J., Newby and family=Bill, given=Robert L., prefix=and, useprefix=true},
  date = {2005-09-01},
  journaltitle = {American Journal of Distance Education},
  volume = {19},
  number = {3},
  pages = {163--181},
  publisher = {Routledge},
  issn = {0892-3647},
  doi = {10.1207/s15389286ajde1903_4},
  url = {https://doi.org/10.1207/s15389286ajde1903_4},
  urldate = {2025-06-12},
  abstract = {This study investigated the effects of using Socratic questioning to enhance students' critical thinking (CT) skills in asynchronous discussion forums (ADF) in university-level distance learning courses. The research effort empirically examined two coherent subjects: (a) the efficacy of teaching and modeling Socratic questioning for developing students' CT skills in ADF and (b) the persistence of students' CT skills following the teaching and modeling of Socratic questioning in the ADF. The results indicate (a) teaching and modeling of Socratic questioning helped students demonstrate a higher level of CT skills and (b) students maintained their CT skills after exposure to and modeling of Socratic questioning in the ADF.},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-12T21:57:38.318Z}
}

@online{zhengLiveCodeBenchProHow2025,
  title = {{{LiveCodeBench Pro}}: {{How Do Olympiad Medalists Judge LLMs}} in {{Competitive Programming}}?},
  shorttitle = {{{LiveCodeBench Pro}}},
  author = {Zheng, Zihan and Cheng, Zerui and Shen, Zeyu and Zhou, Shang and Liu, Kaiyuan and He, Hansen and Li, Dongruixuan and Wei, Stanley and Hao, Hangyi and Yao, Jianzhu and Sheng, Peiyao and Wang, Zixuan and Chai, Wenhao and Korolova, Aleksandra and Henderson, Peter and Arora, Sanjeev and Viswanath, Pramod and Shang, Jingbo and Xie, Saining},
  date = {2025-06-13},
  eprint = {2506.11928},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2506.11928},
  url = {http://arxiv.org/abs/2506.11928},
  urldate = {2025-06-22},
  abstract = {Recent reports claim that large language models (LLMs) now outperform elite humans in competitive programming. Drawing on knowledge from a group of medalists in international algorithmic contests, we revisit this claim, examining how LLMs differ from human experts and where limitations still remain. We introduce LiveCodeBench Pro, a benchmark composed of problems from Codeforces, ICPC, and IOI that are continuously updated to reduce the likelihood of data contamination. A team of Olympiad medalists annotates every problem for algorithmic categories and conducts a line-by-line analysis of failed model-generated submissions. Using this new data and benchmark, we find that frontier models still have significant limitations: without external tools, the best model achieves only 53\% pass@1 on medium-difficulty problems and 0\% on hard problems, domains where expert humans still excel. We also find that LLMs succeed at implementation-heavy problems but struggle with nuanced algorithmic reasoning and complex case analysis, often generating confidently incorrect justifications. High performance appears largely driven by implementation precision and tool augmentation, not superior reasoning. LiveCodeBench Pro thus highlights the significant gap to human grandmaster levels, while offering fine-grained diagnostics to steer future improvements in code-centric LLM reasoning.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Software Engineering},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-22T17:27:58.823Z},
  file = {/Users/andrew/Zotero/storage/HK5647VC/Zheng et al. - 2025 - LiveCodeBench Pro How Do Olympiad Medalists Judge LLMs in Competitive Programming.pdf;/Users/andrew/Zotero/storage/4YG2NPIV/2506.html}
}

@online{zhi-xuanPragmaticInstructionFollowing2024,
  title = {Pragmatic {{Instruction Following}} and {{Goal Assistance}} via {{Cooperative Language-Guided Inverse Planning}}},
  author = {Zhi-Xuan, Tan and Ying, Lance and Mansinghka, Vikash and Tenenbaum, Joshua B.},
  date = {2024-02-27},
  eprint = {2402.17930},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2402.17930},
  url = {http://arxiv.org/abs/2402.17930},
  urldate = {2024-11-20},
  abstract = {People often give instructions whose meaning is ambiguous without further context, expecting that their actions or goals will disambiguate their intentions. How can we build assistive agents that follow such instructions in a flexible, context-sensitive manner? This paper introduces cooperative language-guided inverse plan search (CLIPS), a Bayesian agent architecture for pragmatic instruction following and goal assistance. Our agent assists a human by modeling them as a cooperative planner who communicates joint plans to the assistant, then performs multimodal Bayesian inference over the human's goal from actions and language, using large language models (LLMs) to evaluate the likelihood of an instruction given a hypothesized plan. Given this posterior, our assistant acts to minimize expected goal achievement cost, enabling it to pragmatically follow ambiguous instructions and provide effective assistance even when uncertain about the goal. We evaluate these capabilities in two cooperative planning domains (Doors, Keys \& Gems and VirtualHome), finding that CLIPS significantly outperforms GPT-4V, LLM-based literal instruction following and unimodal inverse planning in both accuracy and helpfulness, while closely matching the inferences and assistive judgments provided by human raters.},
  pubstate = {prepublished},
  keywords = {/unread,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  annotation = {Read\_Status: New\\
Read\_Status\_Date: 2025-06-11T17:02:08.461Z},
  file = {/Users/andrew/Zotero/storage/8SWNNQJ3/Zhi-Xuan et al. - 2024 - Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning.pdf;/Users/andrew/Zotero/storage/FLLI8YNW/2402.html}
}

@inproceedings{zhouPredictiveScalableInterpretable2023,
  title = {Predictive, Scalable and Interpretable Knowledge Tracing on Structured Domains},
  author = {Zhou, Hanqi and Bamler, Robert and Wu, Charley M. and Tejero-Cantero, Álvaro},
  date = {2023-10-13},
  url = {https://openreview.net/forum?id=NgaLU2fP5D&referrer=%5Bthe%20profile%20of%20Hanqi%20Zhou%5D(%2Fprofile%3Fid%3D~Hanqi_Zhou1)},
  urldate = {2025-06-09},
  abstract = {Intelligent tutoring systems optimize the selection and timing of learning materials to enhance understanding and long-term retention. This requires estimates of both the learner's progress ("knowledge tracing"; KT), and the prerequisite structure of the learning domain ("knowledge mapping"). While recent deep learning models achieve high KT accuracy, they do so at the expense of the interpretability of psychologically-inspired models. In this work, we present a solution to this trade-off. PSI-KT is a hierarchical generative approach that explicitly models how both individual cognitive traits and the prerequisite structure of knowledge influence learning dynamics, thus achieving interpretability by design. Moreover, by using scalable Bayesian inference, PSI-KT targets the real-world need for efficient personalization even with a growing body of learners and interaction data. Evaluated on three datasets from online learning platforms, PSI-KT achieves superior multi-step **p**redictive accuracy and **s**calable inference in continual-learning settings, all while providing **i**nterpretable representations of learner-specific traits and the prerequisite structure of knowledge that causally supports learning. In sum, predictive, scalable and interpretable knowledge tracing with solid knowledge mapping lays a key foundation for effective personalized learning to make education accessible to a broad, global audience.},
  eventtitle = {The {{Twelfth International Conference}} on {{Learning Representations}}},
  langid = {english},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2025-06-12T07:21:42.759Z},
  file = {/Users/andrew/Zotero/storage/KH3P32NE/Zhou et al. - 2023 - Predictive, scalable and interpretable knowledge tracing on structured domains.pdf}
}
