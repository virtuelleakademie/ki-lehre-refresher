[
  {
    "objectID": "guide/index.html",
    "href": "guide/index.html",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "",
    "text": "ChatGPT besteht Anwaltsprüfungen. Claude kann professionelle Programmierer erstezen. Gemini diagnostiziert Krankheiten. Als Hochschullehrende fragst du dich vermutlich: Wie integriere ich diese Werkzeuge sinnvoll in meine Lehre?\nDie Antwort ist komplizierter, als viele annehmen. Eine Studie in PNAS (Bastani u. a. 2025) zeigt ein beunruhigendes Muster: Rund 1000 Gymnasiasten mit GPT-4-Zugang lösten 48% mehr Mathematikaufgaben korrekt. Als der KI-Zugang später entfernt wurde, schnitten dieselben Schüler jedoch 17% schlechter ab als jene, die nie KI hatten.\nDas ist das Produktivitäts-Lern-Paradox: KI verbessert die Aufgabenleistung, kann aber das Lernen selbst beeinträchtigen. Die Frage ist nicht mehr ob KI hilft, sondern wann sie hilft und wann sie schadet.\nDieser Leitfaden bietet einen Rahmen, um diese Frage zu beantworten. Die zentrale These:\n\nKI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht. Ohne durchdachte Integration wird KI das Lernen eher beeinträchtigen als fördern.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Vor dem Weiterlesen\n\n\n\n\n\nBevor du diesen Leitfaden liest, reflektiere kurz:\n\nWo hast du Studierende beim KI-Einsatz beobachtet?\nWelche Auswirkungen auf das Lernen hast du vermutet?\nWelche Fragen stellst du dir bezüglich KI in deiner Lehre? Diese Reflexion hilft, die folgenden Konzepte auf den eigenen Kontext anzuwenden.",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#einleitung",
    "href": "guide/index.html#einleitung",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "",
    "text": "ChatGPT besteht Anwaltsprüfungen. Claude kann professionelle Programmierer erstezen. Gemini diagnostiziert Krankheiten. Als Hochschullehrende fragst du dich vermutlich: Wie integriere ich diese Werkzeuge sinnvoll in meine Lehre?\nDie Antwort ist komplizierter, als viele annehmen. Eine Studie in PNAS (Bastani u. a. 2025) zeigt ein beunruhigendes Muster: Rund 1000 Gymnasiasten mit GPT-4-Zugang lösten 48% mehr Mathematikaufgaben korrekt. Als der KI-Zugang später entfernt wurde, schnitten dieselben Schüler jedoch 17% schlechter ab als jene, die nie KI hatten.\nDas ist das Produktivitäts-Lern-Paradox: KI verbessert die Aufgabenleistung, kann aber das Lernen selbst beeinträchtigen. Die Frage ist nicht mehr ob KI hilft, sondern wann sie hilft und wann sie schadet.\nDieser Leitfaden bietet einen Rahmen, um diese Frage zu beantworten. Die zentrale These:\n\nKI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht. Ohne durchdachte Integration wird KI das Lernen eher beeinträchtigen als fördern.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Vor dem Weiterlesen\n\n\n\n\n\nBevor du diesen Leitfaden liest, reflektiere kurz:\n\nWo hast du Studierende beim KI-Einsatz beobachtet?\nWelche Auswirkungen auf das Lernen hast du vermutet?\nWelche Fragen stellst du dir bezüglich KI in deiner Lehre? Diese Reflexion hilft, die folgenden Konzepte auf den eigenen Kontext anzuwenden.",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#was-ki-kann",
    "href": "guide/index.html#was-ki-kann",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Was KI heute kann",
    "text": "Was KI heute kann\n\nGrundlegende Funktionsweise\nBevor wir über Auswirkungen sprechen, lohnt sich ein Blick darauf, was diese Systeme eigentlich tun. Large Language Models (LLMs) wie GPT-5 oder Claude sind im Kern Next-Word-Prediction-Systeme1. Sie wurden auf Milliarden von Textdokumenten trainiert und haben dabei Muster in Sprache, Argumentation und Stil gelernt, aber auch sehr viel Wissen. Die beste Metapher: extrem ausgeklügelte Autovervollständigung.\nEntscheidend ist die Unterscheidung zwischen Retrieval und Generation:\n\nRetrieval (wie eine Suchmaschine): Information wird gefunden und zurückgegeben\nGeneration (wie ein LLM): Text wird neu erzeugt basierend auf statistischen Mustern\n\nLLMs rufen kein Wissen ab. Sie generieren Text, der plausibel klingt. Dies erklärt, warum sie “halluzinieren”2 können: Sie optimieren für sprachliche Plausibilität, nicht für faktische Korrektheit.\n\n\nChain-of-Thought Reasoning\nModerne LLMs können “denken”, indem sie ihre Überlegungen schrittweise externalisieren. Bei der Frage “Was ist 17 × 24?” kann ein LLM antworten:\n\n“Lass mich das aufteilen: 17 × 20 = 340, 17 × 4 = 68, 340 + 68 = 408”\n\nDieses Chain-of-Thought Reasoning verbessert die Leistung bei komplexen Aufgaben erheblich. Es ist jedoch immer noch Mustererkennung, nur über Denkschritte statt direkt über Antworten. Die KI hat gelernt, wie Menschen Probleme in Teilprobleme zerlegen.\n\n\nWerkzeugfähige Agenten\nDie neueste Entwicklung sind Agenten: LLMs, die mit externen Werkzeugen verbunden sind. Sie können:\n\nWebsuchen durchführen\nCode schreiben und ausführen\nDateien lesen und bearbeiten\nBerechnungen anstellen\nProgrammierschnittstellen (APIs) aufrufen\n\nDie Konsequenz: Agenten können eine grosse Menge an kognitiven Aufgaben ausführen, von Literaturrecherche über Datenanalyse bis zum Schreiben und Überarbeiten von Texten. Die Fähigkeitsgrenze verschiebt sich ständig.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: KI-Fähigkeiten aktuell halten\n\n\n\n\n\nDie Fähigkeiten von KI-Systemen entwickeln sich rasant. Empfehlungen:\n\nRegelmässig aktualisieren: Überprüfe regelmässig, was aktuelle Modelle können\nSelbst testen: Probiere neue Modelle mit Aufgaben aus deinem Fachgebiet\nSkeptisch bleiben: Marketing-Behauptungen übertreffen oft die tatsächliche Leistung\nGrenzen kennen: Identifiziere Aufgaben, bei denen KI zuverlässig versagt",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#expertise",
    "href": "guide/index.html#expertise",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Wie Expertise entsteht",
    "text": "Wie Expertise entsteht\nWarum wirkt KI auf Experten und Lernende so unterschiedlich? Die Antwort ist darin zu finden, was Expertise eigentlich ist.\n\nExperten und Novizen sind grundlegend verschieden\nEin weit verbreitetes Missverständnis: Experten haben einfach “mehr Wissen”. Die Forschung zeigt etwas anderes. Experten haben eine qualitativ andere kognitive Architektur.\nDas klassische Beispiel stammt aus der Schachforschung (Groot und Groot 1978; Chase und Simon 1973). Schachmeistern und Anfängern wurden Stellungen für wenige Sekunden gezeigt. Bei echten Spielstellungen erinnerten Meister deutlich mehr Figuren korrekt als Anfänger. Bei zufällig platzierten Figuren waren beide Gruppen gleich schlecht.\nDie Interpretation: Meister sehen nicht einzelne Figuren, sondern Chunks, bedeutungsvolle Muster wie “Königsangriff” oder “offene Linie”. Diese Chunks sind im Langzeitgedächtnis gespeichert und werden automatisch erkannt.\nDas Prinzip gilt domänenübergreifend:\n\nÄrzte sehen Symptomkomplexe, nicht Einzelsymptome\nProgrammierer sehen Design Patterns, nicht Codezeilen\nHistoriker sehen Epochenmerkmale, nicht Einzeldaten\n\n\n\nVon schwachen zu starken Methoden\nWie lösen Menschen Probleme? Newell und Simon (Newell und Simon 1972) unterschieden in ihrer einflussreichen Arbeit zwischen “schwachen” und “starken” Methoden der Problemlösung. Anderson’s Theorie des Fertigkeitserwerbs (Anderson 1982) beschreibt dann den Mechanismus, wie der Übergang zwischen diesen Methoden mit wachsender Expertise stattfindet.\nNovizen nutzen schwache Methoden:\n\nMittel-Ziel-Analyse: “Wo bin ich? Wo will ich hin? Was bringt mich näher?”\nVersuch und Irrtum\nAnalogiebildung: “Das ist wie etwas, das ich schon kenne”\nRückwärtsarbeiten vom Ziel\n\nDiese Methoden heissen “schwach”, weil sie domänenunabhängig und allgemein anwendbar, aber langsam, fehleranfällig und kognitiv anstrengend sind.\nExperten nutzen starke Methoden:\n\nAutomatische Mustererkennung: “Das ist ein Fall von X”\nDirekte Lösungswege: “Bei X macht man Y”\nIntuition basierend auf tausenden Erfahrungen\n\nDer Übergang von schwachen zu starken Methoden erfordert umfangreiche Übung. Es gibt keine Abkürzung.\n\n\nProzeduralisierung: Vom Wissen zum Können\nDer Weg zur Expertise folgt typischen Phasen:\n\nDeklaratives Wissen: Wissen als Fakten (“Man muss beim Autofahren die Kupplung treten, bevor man schaltet”)\nBewusste Anwendung: Aktiv an jeden Schritt denken, langsam, fehleranfällig\nProzeduralisierung: Schritte werden zu Einheiten zusammengefasst (“Anfahren” statt drei separate Handlungen)\nAutomatisierung: Unbewusste, flüssige Ausführung\n\nAutomatisierte Prozesse belasten das Arbeitsgedächtnis nicht mehr. Sie sind schneller, zuverlässiger und setzen kognitive Ressourcen für höhere Aufgaben frei.\nEntscheidend ist: Diese Transformation kann nicht übersprungen werden. Man kann nicht direkt von deklarativem Wissen zu Automatisierung springen. Der Weg führt durch bewusste, anstrengende Übung.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Übungsphasen schützen\n\n\n\n\n\nWenn KI die “langweiligen” Übungsphasen übernimmt, findet keine Prozeduralisierung statt. Empfehlungen:\n\nGrundlagenphase KI-frei gestalten: Erste Begegnungen mit neuem Material ohne KI-Unterstützung\nÜbungszeit einplanen: Explizite Übungszeit, in der KI nicht erlaubt ist\nFortschritt monitoren: Regelmässig prüfen, ob Studierende Aufgaben auch ohne KI bewältigen\nSequenzierung beachten: Erst Grundlagen festigen, dann KI als Produktivitätswerkzeug einführen\n\nRealitätscheck: Vollständige Kontrolle über KI-Nutzung ist kaum möglich. Fokus auf Prozessbewertung und Reflexion kann wirksamer sein als strikte Verbote.\n\n\n\n\n\nCognitive Load Theory: Das Nadelöhr des Lernens\nWarum ist Übung so wichtig? Die Cognitive Load Theory (Sweller 2024) liefert die Antwort. Sie basiert auf zwei Gedächtnissystemen:\nArbeitsgedächtnis:\n\nKapazität: etwa \\(4 \\pm 1\\) Elemente gleichzeitig (wobei dies von der Definition eines “Elements” und der Aufgabenart abhängt)\nDauer: wenige Sekunden ohne aktive Aufrechterhaltung\nDer Flaschenhals allen Lernens\n\nLangzeitgedächtnis:\n\nPraktisch unbegrenzte Kapazität\nDauerhafte Speicherung\nHier lebt Expertise\n\nDie zentrale Erkenntnis: Alles Lernen muss durch den Flaschenhals des Arbeitsgedächtnisses. Wenn das Arbeitsgedächtnis überlastet ist, findet kein Lernen statt.\n\n\nDrei Arten kognitiver Belastung\nDie Cognitive Load Theory unterscheidet drei Arten der Belastung:\n\n\n\n\n\n\n\n\nTyp\nBeschreibung\nZiel\n\n\n\n\nIntrinsisch\nInhärente Komplexität des Materials\nKann nicht reduziert werden ohne Vereinfachung\n\n\nExtrinsisch\nSchlecht gestaltete Instruktion\nMinimieren\n\n\nLernförderlich (Germane)\nProduktive Anstrengung für Schemabildung\nErhalten\n\n\n\n(Anmerkung: Die Unterscheidung zwischen lernförderlicher und intrinsischer Belastung ist in der Literatur umstritten. Einige Forscher argumentieren, dass “germane load” keine eigenständige Kategorie darstellt, sondern die produktive Nutzung verfügbarer Kapazität beschreibt.)\nDie entscheidende Frage für KI: Welche Art der Belastung reduziert sie?\n\nKI kann extrinsische Belastung reduzieren (z.B. bessere Erklärungen) → gut\nKI kann lernförderliche Belastung eliminieren (z.B. Antworten statt selbst denken) → problematisch\n\nDas Ergebnis hängt vom Nutzungskontext ab.\n\n\nDer Expertise-Umkehr-Effekt\nEin Forschungsüberblick (Kalyuga 2009) zeigt einen bemerkenswerten Befund:\n\nGeringe Vorkenntnisse: Hohe Unterstützung hilft (mittlere bis grosse Effekte)\nHohe Vorkenntnisse: Hohe Unterstützung schadet (die Effekte kehren sich um)\n\nDas ist der Expertise-Umkehr-Effekt: Dieselbe Instruktionsmethode kann gegenteilige Effekte haben, abhängig vom Vorwissen der Lernenden.\nFür Novizen reduziert Unterstützung die extrinsische Belastung und lässt Raum für Lernen. Für Experten ist die Unterstützung redundant und erzeugt zusätzliche Verarbeitungslast (“Ich weiss das schon, aber muss es trotzdem durcharbeiten”).\nDie Implikation für KI: Dasselbe KI-Werkzeug kann für Experten produktiv und für Novizen schädlich sein, oder umgekehrt, je nach Nutzungsweise. Es gibt keine “One-size-fits-all”-Lösung.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Unterstützung anpassen\n\n\n\n\n\nDer Expertise-Umkehr-Effekt legt nahe, die KI-Nutzung an den Lernstand anzupassen:\n\nVorwissen erheben: Zu Beginn eines Kurses das Vorwissen einschätzen\nDifferenzieren: Unterschiedliche KI-Regeln für Anfänger und Fortgeschrittene\nFading einsetzen: Mit hoher Unterstützung beginnen, dann schrittweise reduzieren\nStudierende einbeziehen: Über den Effekt informieren, Selbstregulation fördern\n\n\n\n\n\n\nWas Instruktion leisten sollte: Explizite Instruktion\nBisher haben wir diskutiert, was KI für Lernen problematisch machen kann. Aber was sollte gute Instruktion tun? Die Forschung zu expliziter Instruktion (Kirschner, und and Clark 2006) liefert klare Antworten.\nDas Problem mit minimaler Anleitung: Konstruktivistische, entdeckende und problembasierte Ansätze klingen intuitiv attraktiv: Lernende sollen selbst entdecken, explorieren, Probleme lösen. Aber die empirische Evidenz zeigt konsistent: Für Novizen ist minimale Anleitung weniger effektiv als explizite Instruktion. Der Grund liegt in der kognitiven Architektur: Novizen haben keine Schemata im Langzeitgedächtnis, die sie zur Problemlösung nutzen könnten. Sie sind auf ihr begrenztes Arbeitsgedächtnis angewiesen, das schnell überlastet wird.\nWorked Examples: Eine der am besten belegten Instruktionsmethoden für Novizen sind Worked Examples (ausgearbeitete Beispiele). Statt Lernende Probleme selbst lösen zu lassen, zeigt man ihnen vollständig ausgearbeitete Lösungswege. Das klingt kontraintuitiv: Sollten Lernende nicht selbst denken? Die Forschung zeigt: Für Novizen reduzieren Worked Examples die extrinsische kognitive Belastung und lassen Kapazität für Schemabildung. Der Worked Example Effect (Cooper und Sweller 1987) ist einer der robustesten Befunde der Instruktionsforschung.\nDer Unterschied zu KI: Hier liegt ein entscheidender Punkt: Worked Examples sind nicht dasselbe wie KI-generierte Lösungen.\n\nWorked Examples sind didaktisch gestaltet, heben relevante Schritte hervor, bauen systematisch Komplexität auf und werden von Lehrenden ausgewählt, um bestimmte Prinzipien zu illustrieren\nKI-generierte Antworten, in der typischen Nutzung durch Studierende, beantworten die gestellte Frage. Sie erfolgen jedoch ohne Einbettung in eine geplante Lernprogression. LLMs können mit entsprechendem Prompting didaktisch strukturierte Erklärungen liefern, aber das erfordert pädagogisches Wissen, das Novizen typischerweise nicht haben.\n\nDer Unterschied liegt in der Einbettung: Worked Examples sind Teil eines durchdachten Instruktionsdesigns, das von Lehrenden mit Blick auf die Lernziele und den Wissensstand der Lernenden gestaltet wurde. KI-Antworten in der studentischen Alltagsnutzung fehlt dieser Kontext.\nCompletion Problems: Ein Mittelweg sind Completion Problems: Teilweise ausgearbeitete Lösungen, die Lernende vervollständigen müssen. Sie bieten Struktur, fordern aber aktive kognitive Verarbeitung. Mit wachsender Expertise können die vorgefertigten Teile reduziert werden (Fading), bis Lernende Probleme vollständig selbst lösen.\nDie Verbindung zum Expertise-Umkehr-Effekt: Explizite Instruktion und Worked Examples helfen Novizen, können aber Experten behindern (Expertise-Umkehr-Effekt). Daher ist Fading zentral: Unterstützung wird systematisch reduziert, wenn Expertise wächst. Das ist genau die dynamische Anpassung, die der Expertise-Umkehr-Effekt nahelegt.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Explizite Instruktion einsetzen\n\n\n\n\n\nEvidenzbasierte Instruktion für Novizen:\n\nWorked Examples nutzen: Ausgearbeitete Beispiele zeigen, bevor Lernende selbst lösen\nCompletion Problems einsetzen: Teilweise gelöste Aufgaben, die vervollständigt werden müssen\nFading planen: Mit viel Unterstützung beginnen, systematisch reduzieren\nDidaktische Sequenzierung: Nicht jede Lösung zeigen, sondern gezielt ausgewählte Beispiele\nKI nicht mit Worked Examples verwechseln: KI-Antworten ersetzen keine didaktisch gestaltete Instruktion\n\nDer Kernpunkt: Novizen brauchen Unterstützung, aber die richtige Art von Unterstützung. Explizite Instruktion reduziert extrinsische Belastung, während produktive kognitive Arbeit erhalten bleibt. KI-Nutzung kann beides tun: extrinsische Belastung reduzieren (gut) oder die produktive Arbeit selbst übernehmen (problematisch).",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#kritisches-denken",
    "href": "guide/index.html#kritisches-denken",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Kritisches Denken erfordert Fachwissen",
    "text": "Kritisches Denken erfordert Fachwissen\nStudierende sollen lernen, KI kritisch zu nutzen. Das klingt vernünftig, greift aber zu kurz.\n\nDie traditionelle Annahme\nOft wird angenommen, kritisches Denken sei eine allgemeine, übertragbare Fähigkeit: einmal erworben, überall anwendbar.\nAuf KI übertragen hiesse das: Man könnte Studierenden “KI-Kompetenz” beibringen, also die Fähigkeit, KI-Outputs kritisch zu bewerten, unabhängig vom Fachgebiet.\nAber stimmt diese Annahme?\n\n\nWillinghams Herausforderung\nDaniel Willingham (Willingham 2008) fasst die Forschung provokant zusammen:\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n\nDas ist zugespitzt formuliert, aber der Kern stimmt: Transfer ist schwieriger als oft angenommen.\n\n\nEvidenz für Domänenspezifität\nDie Forschung zeigt wiederholt, dass Expertise nicht transferiert:\n\nNeurologen können Herzerkrankungen nicht gut diagnostizieren, obwohl sie medizinisch ausgebildet sind\nFachredakteure können keine Zeitungsartikel schreiben, obwohl sie Texte redigieren können\nSelbst trainierte Philosophen werden von irrelevanten Merkmalen beeinflusst, wenn das Thema ausserhalb ihrer Expertise liegt\n\nWillingham formuliert es so:\n\n“Abstract principles like ‘look for hidden assumptions’ won’t help much in evaluating an argument about a topic you know little about.”\n\n\n\nAngewendet auf KI-Bewertung\nWas bedeutet das für die kritische Bewertung von KI-Outputs?\nEine Expertin in Biomedizin kann erkennen, wenn ChatGPT bei Biochemie falsch liegt. Sie hat die mentalen Modelle des Fachgebiets, kann “Das klingt falsch” erkennen, weiss welche Quellen zur Verifizierung dienen, und kann Plausibilität einschätzen.\nEine Novizin kann diese Bewertung nicht vornehmen, unabhängig von ihren “kritischen Denkfähigkeiten”. Ihr fehlen die Referenzrahmen. Sie kann nicht unterscheiden zwischen plausibel und korrekt. Sie weiss nicht, welche Quellen autoritativ sind.\nWas wie “kritisches Denken” aussieht, ist oft domänen-spezifisches Wissen.\n\n\nWas transferiert, und was nicht\nEine nuanciertere Betrachtung unterscheidet:\nTransferiert teilweise:\n\nPlanung des Vorgehens\nÜberwachung des eigenen Verständnisses\nSelbstregulation\nBereitschaft, Annahmen zu hinterfragen\n\nDiese metakognitiven Strategien zeigen in der Forschung gewisse Generalisierung. Man kann sie domänenübergreifend lehren, und sie haben etwas Transferwirkung.\nTransferiert kaum:\n\nWissen, was in einem Fachgebiet plausibel ist\nWissen, welche Quellen autoritativ sind\nErkennen von fachspezifischen Fehlern\n\nDiese inhaltliche Bewertungsfähigkeit erfordert Domänenwissen und transferiert kaum.\nDer Kernpunkt: Die Strategien kann man lehren, aber ihre Anwendung erfordert Fachwissen. Die Strategie “Hinterfrage Annahmen” kann man lehren. Aber um zu wissen, welche Annahmen in einem biochemischen Text fragwürdig sind, braucht man Biochemie-Wissen.\n\n\nDie zentrale Implikation\nDaraus folgen drei wichtige Erkenntnisse:\n\nStudierende, die “mit hohem kritischem Denken” von KI profitieren, haben wahrscheinlich mehr Domänenexpertise. Studien, die zeigen, dass “kritische Denker” von KI profitieren, messen möglicherweise Vorwissen, nicht eine generische Fähigkeit.\nDie beste Vorbereitung für kritische KI-Nutzung ist tiefes Fachlernen. Kontraintuitiv: Nicht “KI-Training”, sondern Fachausbildung. Expertise ermöglicht kritische Nutzung; ohne Expertise ist Kritik kaum möglich.\nGenerische “KI-Kompetenz” kann Fachwissen ergänzen, aber nicht ersetzen. Workshops zu “Prompt Engineering” lösen das fundamentale Problem nicht. Die Fähigkeit, einen guten Prompt zu schreiben, ersetzt nicht die Fähigkeit, die Antwort zu bewerten.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Fach-spezifisches Lernen priorisieren\n\n\n\n\n\nAnstatt nur “KI-Kompetenz” zu lehren:\n\nFachliche Grundlagen stärken: Mehr Zeit für Grundlagenwissen, nicht weniger\nDomänenspezifische KI-Kritik üben: Im Fachkontext KI-Outputs gemeinsam analysieren\nFehler sammeln: Eine Sammlung typischer KI-Fehler im eigenen Fachgebiet anlegen\nMetakognition fördern: Studierende lehren, ihr eigenes Verständnis zu überwachen\nRealistische Erwartungen setzen: KI-Kritik erfordert Fachwissen, das Zeit braucht",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#paradox",
    "href": "guide/index.html#paradox",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Das Produktivitäts-Lern-Paradox",
    "text": "Das Produktivitäts-Lern-Paradox\nDie zentrale Frage lautet: Warum kann KI die Aufgabenleistung verbessern und gleichzeitig das Lernen beeinträchtigen?\n\nDie zentrale Unterscheidung\n\n“Learning and task completion are not synonymous.” (Jose u. a. 2025)\n\nDiese Unterscheidung ist entscheidend:\n\nAufgabenleistung (Performance): Wie gut man eine Aufgabe jetzt löst\nLernen (Learning): Die Fähigkeit, ähnliche Aufgaben später unabhängig zu lösen\n\nKI verbessert Aufgabenleistung (eindeutig belegt). Aber das sagt nichts über Lernen. Lernen erfordert möglicherweise genau die Anstrengung, die KI eliminiert.\n\n\nDie Bastani-Studie im Detail\nSchauen wir uns die eingangs erwähnte Studie (Bastani u. a. 2025) genauer an:\nDesign:\n\nRund 1000 türkische Gymnasiasten\nRandomisierte Zuweisung zu drei Gruppen\nMathe-Übungen über mehrere Wochen\nTest am Ende ohne KI-Zugang\n\nDie Bedingungen:\n\nKontrollgruppe: Kein KI-Zugang\nDirekter GPT-4-Zugang: Freie Nutzung\nGPT Tutor: Strukturierte Nutzung mit pädagogischen Leitplanken\n\nDie Ergebnisse:\n\nMit direktem GPT-4: 48% mehr Aufgaben gelöst\nMit GPT Tutor: 127% mehr Aufgaben gelöst\nOhne KI (später): 17% schlechter als Kontrollgruppe\n\nDie Autoren fassen zusammen:\n\n“Students attempt to use GPT-4 as a ‘crutch’ during practice sessions, and when successful, perform worse on their own.”\n\nWichtige Nuance: Die negativen Effekte betrafen primär den direkten Zugang. Der “GPT Tutor” zeigte bessere Ergebnisse, aber selbst mit Tutor war die spätere Leistung ohne KI reduziert. Die Art der KI-Nutzung macht einen Unterschied.\nEinschränkungen: Die Studie hat methodische Limitationen: Der Kontext (türkische Gymnasiasten, Mathematik) ist spezifisch, die Effekte sind kurzfristig gemessen, und Replikationen stehen aus. Allerdings: Die Kernaussage, dass Aufgabenleistung und Lernen auseinanderfallen können, ist keine Überraschung. Sie folgt direkt aus der Cognitive Load Theory und den Prinzipien erwünschter Schwierigkeiten. Die Studie liefert empirische Evidenz für die Vorhersagen der Theorie.\n\n\nDesirable Difficulties: Warum Anstrengung nötig ist\nRobert Bjork (Bjork und Bjork 2011) hat das Konzept der “erwünschten Schwierigkeiten” geprägt:\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\nVier bewährte Interventionen illustrieren das Prinzip:\n\nVariation: Lernen unter wechselnden Bedingungen\nInterleaving: Aufgabentypen mischen statt blocken\nSpacing: Verteilt lernen statt massiert\nRetrieval Practice: Aktiv abrufen statt passiv wiederlesen (Roediger und Karpicke 2006)\n\nAlle vier haben gemeinsam: Sie fühlen sich schwerer an, sind aber effektiver für langfristiges Lernen.\nDer Mechanismus: Sofortiger KI-Zugang kann Abrufversuche kurzschliessen. Statt selbst nachzudenken (“Was weiss ich darüber?”), fragt man die KI. Die Gedächtnisspur wird nicht gestärkt.\n\n\nDer Generierungseffekt\nDer Generierungseffekt ist ein robuster Befund: Selbst generierte Information wird besser behalten als passiv erhaltene. Slamecka und Graf (1978) demonstrierten dies erstmals experimentell, spätere Meta-Analysen bestätigten moderate Effektstärken.\nDas typische Experiment:\n\nGruppe A: Liest Wortpaare (Heiss—Kalt)\nGruppe B: Ergänzt Wortpaare (Heiss—K___)\nTest: Beide Gruppen werden abgefragt\nErgebnis: Gruppe B erinnert besser\n\nWarum funktioniert es?\n\nAktivere Verarbeitung während des Generierens\nMehr Verbindungen im Gedächtnis\nTiefere Enkodierung\n\nDie Implikation: Wenn KI generiert, was Studierende selbst produzieren sollten, wird der Generierungseffekt eliminiert. Studierende, die selbst einen Essay-Entwurf schreiben, profitieren vom Generierungseffekt. Studierende, die einen KI-generierten Entwurf bearbeiten, nicht, auch wenn das Endprodukt ähnlich aussieht.\n\n\nDie Scaffolding-Hypothese\nEine tiefere Frage drängt sich auf: Was passiert mit der Entwicklung kognitiver Fähigkeiten? Hier müssen wir sorgfältig zwischen dem unterscheiden, was wir wissen, was wir theoretisch ableiten, und was wir vermuten.\nWas wir wissen (Evidenz): Atrophie von Fähigkeiten ist gut dokumentiert. Eine vorhandene Fähigkeit verkümmert durch Nichtgebrauch. Das ist reversibel: Wenn man wieder übt, kommt die Fähigkeit zurück. Der Generierungseffekt und die Prinzipien erwünschter Schwierigkeiten sind empirisch belegt.\nWas wir theoretisch ableiten: Wenn KI die kognitiven Prozesse übernimmt, die für Lernen notwendig sind, sollte weniger Lernen stattfinden. Das folgt aus der Cognitive Load Theory und ist durch Studien wie Bastani gestützt.\nWas wir vermuten (Hypothese): Es könnte einen Unterschied geben zwischen Fertigkeitsatrophie und Entwicklungsbeeinträchtigung. Eine Fähigkeit, die nie entsteht, weil der konstruktive Prozess übersprungen wird, könnte schwerer nachzuholen sein als eine verkümmerte Fähigkeit. Die Hypothese: Grundfertigkeiten wie Schreiben, Rechnen und analytisches Lesen sind nicht nur Fertigkeiten, sondern Prozesse, die kognitive Architektur aufbauen. Schreiben könnte ein “epistemisches Werkzeug” sein: Gedanken entwickeln sich durch das Schreiben, nicht vor dem Schreiben.\nVorsicht: Diese Hypothese ist plausibel, aber nicht empirisch belegt. Wir haben keine Längsschnittstudien, die zeigen, dass übersprungene kognitive Entwicklungsphasen irreversible Defizite verursachen. Die Bedenken verdienen Aufmerksamkeit, sollten aber nicht als gesicherte Fakten behandelt werden.\n\n\nHistorische Analogien\nFrühere Technologien zeigen ähnliche Muster:\nGPS und räumliches Gedächtnis (Dahmani und Bohbot 2020): Eine longitudinale Studie über drei Jahre zeigte: Stärkere GPS-Nutzung korreliert mit steilerem Rückgang des räumlichen Gedächtnisses. Die zeitliche Abfolge ist konsistent mit der Interpretation, dass GPS-Nutzung zum Rückgang beiträgt, wobei ungemessene konfundierende Variablen nicht ausgeschlossen werden können.\nKonzeptuelles Verständnis (Lortie-Forgues und Siegler 2017): Forschung zeigt, dass selbst Erwachsene mit Zugang zu Rechenhilfen oft überraschende Lücken im konzeptuellen Verständnis mathematischer Operationen aufweisen. Werkzeugnutzung ersetzt kein Grundverständnis. Dieselbe Parallele wie bei KI: Das Werkzeug kann prozedurale Aufgaben übernehmen, aber konzeptuelles Verständnis muss eigenständig aufgebaut werden.\nGoogle-Effekt (Sparrow, Liu, und Wegner 2011): Menschen erinnern Information schlechter, wenn sie erwarten, dass sie verfügbar bleibt. Sie erinnern stattdessen, wo die Information zu finden ist. Das Gedächtnis adaptiert sich an die Verfügbarkeit externer Speicher.\n\n\nGrenzen der Analogien\nDie historischen Analogien sind suggestiv, aber nicht ausreichend:\n\nGPS betrifft räumliche Navigation\nTaschenrechner betreffen arithmetische Berechnungen\nGoogle betrifft Informationsabruf\n\nJede dieser Technologien betrifft eine spezifische, enge kognitive Funktion.\nGenerative KI kann fast jede kognitive Aufgabe übernehmen: Schreiben, Argumentieren, Analysieren, Synthetisieren, Bewerten. Die Breite ist beispiellos. Wir können nicht einfach extrapolieren.\nAber: Die historischen Bedenken hatten oft Berechtigung. GPS beeinflusst tatsächlich räumliche Kognition. Taschenrechner veränderten den Mathematikunterricht. Die Bedenken waren nicht blosse Panikmache.\n\n\nDer EdTech-Hype-Zyklus\nBildungstechnologien folgen einem wiederkehrenden Muster (Reich 2020): Überschwängliche Versprechen, gefolgt von bescheidener Adoption, die bestehende Praktiken eher ergänzt als ersetzt.\n\nRadio sollte die besten Vorlesungen in jedes Klassenzimmer bringen\nFernsehen sollte Lernen revolutionieren\nComputer sollten Unterricht personalisieren\nMOOCs sollten Elite-Bildung demokratisieren\n\nJede Technologie fand eine Nische, aber keine erfüllte die transformativen Versprechen.\nDas MOOC-Beispiel ist besonders lehrreich: MOOCs versprachen Demokratisierung, erreichten aber primär Lernende, die bereits Abschlüsse hatten und berufliche Weiterbildung suchten. Der Erfolg erforderte genau die Selbstregulation und das Vorwissen, das privilegierte Lernende bereits besassen. Die “Demokratisierung” verstärkte bestehende Ungleichheiten.\nWas macht dieses Mal anders? KIs Breite ist beispiellos. Aber dieselben strukturellen Kräfte könnten wirken: die Komplexität des Lehrens, die Einpassung neuer Werkzeuge in bestehende Praktiken, die Kluft zwischen Pilotprojekten und flächendeckender Umsetzung.\n\n\n“Das haben sie über das Schreiben auch gesagt”\nEin häufiger Einwand lautet: Sokrates warnte vor der Schrift, und wir haben überlebt. Jede neue Technologie löst Panik aus.\nIm Phaidros warnte Sokrates: Schrift wird das Gedächtnis schwächen und nur “Scheinwissen” erzeugen.\nDrei Antworten:\n\nSchrift hat Kognition tiefgreifend verändert. Wir denken anders als orale Kulturen. Abstraktion, Kategorisierung, lineare Argumentation wurden durch Schrift gefördert. Das war nicht nur positiv oder negativ, es war transformativ.\nEinige Bedenken waren berechtigt. Mündliche Gedächtnistraditionen sind zurückgegangen. Homers Epen wurden über Generationen mündlich überliefert. Diese Fähigkeit ist weitgehend verloren.\nSchriftkultur entwickelte sich über Jahrhunderte. Es gab Zeit für kulturelle Anpassung. Bildungssysteme entwickelten sich mit. KI-Integration geschieht in Jahren, nicht Jahrhunderten.\n\n\n\nWarum Experten profitieren, Lernende nicht\nJetzt können wir versuchen, das Muster zu erklären:\nExperten können:\n\nRoutine-Aufgaben sicher auslagern (sie wissen, was “Routine” ist)\nHöheres Denken aufrechterhalten (kognitive Kapazität wird frei)\nKI-Outputs bewerten (sie haben Domänenexpertise)\nIhre Grundfähigkeiten verkümmern nicht (sie sind schon da)\n\nLernenden fehlt:\n\nWissen zur Bewertung (sie können nicht einschätzen, ob KI richtig liegt)\nEtablierte Grundfähigkeiten (was nicht da ist, kann nicht verkümmern, entsteht aber auch nicht)\nMetakognitive Kontrolle (sie wissen nicht, wann KI-Nutzung schadet)\n\nDas Ergebnis kann “fliessende Inkompetenz” sein: Anspruchsvoll wirkende Outputs ohne zugrundeliegendes Verständnis. Das KI-generierte Produkt sieht kompetent aus, das Wissen fehlt.\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Lernsituationen gestalten\n\n\n\n\n\nUm produktive Anstrengung zu erhalten:\n\n“Ohne-KI”-Phasen einplanen: Explizite Zeiten, in denen KI nicht erlaubt ist\nProzess bewerten, nicht nur Produkt: Zwischenschritte einfordern und bewerten\nRetrieval Practice integrieren: Regelmässige Abrufübungen ohne Hilfsmittel\nSpacing und Interleaving nutzen: Verteiltes, gemischtes Üben\nGenerierung fordern: Eigene Entwürfe vor KI-Unterstützung verlangen\nReflexion einbauen: Studierende über ihren Lernprozess nachdenken lassen\n\nRealitätscheck: Diese Empfehlungen erfordern Zeit und Planung. Nicht jede Lehrveranstaltung kann alles umsetzen. Beginne mit einem oder zwei Punkten, die zu deinem Kontext passen.",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#sokrates",
    "href": "guide/index.html#sokrates",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Exkurs: Sokratisches Fragen in KI-Tutoren",
    "text": "Exkurs: Sokratisches Fragen in KI-Tutoren\nEin konkretes Beispiel für den Hype-Evidenz-Gap: Viele EdTech-Unternehmen bewerben ihre KI-Tutoren mit “sokratischer Methode”.\n\n\n\n\n\n\nPro-tipWas “sokratisch” eigentlich bedeutet\n\n\n\n\n\nDie ursprüngliche sokratische Methode, wie sie in Platons Dialogen beschrieben wird, war kein sanftes Hinführen zu richtigen Antworten. Sokrates stellte bohrende Fragen, die vermeintliches Wissen als unbegründet entlarvten. Das Ziel war Aporie: die Erkenntnis, dass man weniger weiss, als man dachte. Diese Erfahrung war oft unangenehm.\nWas EdTech-Unternehmen “sokratisch” nennen, ist etwas anderes: ein System, das durch Fragen zur richtigen Antwort führt, statt sie direkt zu geben. Das ist eher geleitetes Entdecken als sokratischer Dialog. Die Bezeichnung klingt gut, aber der Vergleich hinkt.\n\n\n\n\nDas Versprechen\nDie Argumentation ist verlockend:\n\nBlooms “Two Sigma Problem” (BLOOM 1984): 1:1-Tutoring erzielt 2 Standardabweichungen Verbesserung\nDas würde einen durchschnittlichen Studierenden in die Top 2% bringen\nKI kann unbegrenzt viele Lernende betreuen\nAlso: Demokratisierung personalisierter Bildung\n\nAber: Die Begeisterung übersteigt die Evidenz erheblich.\n\n\nWarum Fragen theoretisch helfen könnten\nDie kognitionswissenschaftliche Grundlage ist solide:\nGenerierungseffekt: Selbst erzeugte Antworten werden besser behalten als passiv erhaltene (Slamecka und Graf 1978).\nSelbsterklärungseffekt: Erklären fördert tiefere Verarbeitung und deckt Wissenslücken auf (Chi u. a. 1994).\nAber: Die Qualität der Selbsterklärungen und damit der Lerneffekt hängt vom Vorwissen ab. Das verknüpft mit dem Expertise-Umkehr-Effekt: Was für Fortgeschrittene funktioniert, kann Novizen überfordern.\n\n\nWas die Evidenz tatsächlich zeigt\nVanLehn (2011) führte eine Meta-Analyse zur Effektivität verschiedener Tutoring-Formen durch:\n\nMenschliche Tutoren: d = 0.79 (nicht 2.0 wie Bloom behauptete)\nIntelligente Tutorsysteme: d = 0.76 (vergleichbar)\n\nVanLehns Analyse legt nahe, dass Schritt-für-Schritt-Feedback ein wesentlicher Faktor war, wobei die genaue Rolle des sokratischen Dialogs schwer zu isolieren ist.\nZu LLM-basierten sokratischen Tutoren: Es gibt keine gut kontrollierten randomisierten Studien. Die existierende Evidenz besteht hauptsächlich aus Zufriedenheitsumfragen und Vergleichen mit “kein Tutoring” statt mit Alternativen (siehe auch Weidlich u. a. (2025)).\n\n\nDas Diagnose-Problem\nEffektives sokratisches Fragen erfordert:\n\nGenaue Einschätzung des aktuellen Wissensstands\nUnterscheidung verschiedener Fehlertypen\nAnpassung der Fragen an den individuellen Lernenden\n\nBeispiel: Wenn ein Schüler antwortet \\(\\frac{1}{2} + \\frac{1}{3} = \\frac{2}{5}\\), kann das bedeuten:\n\nProzeduraler Fehler (Zähler und Nenner addiert)\nKonzeptueller Fehler (versteht nicht, was Brüche repräsentieren)\nFlüchtigkeitsfehler (weiss es eigentlich)\n\nDie angemessene sokratische Frage unterscheidet sich je nach Ursache. Menschliche Tutoren nutzen Mimik, Tonfall, Zögern und jahrelange Erfahrung zur Diagnose. KI-Systeme haben nur den Text und können diese Unterscheidung nicht zuverlässig treffen.\n\n\nWeitere Herausforderungen\nFragesequenzierung: Sokratischer Dialog ist kontingent. Jede Frage hängt von der vorherigen Antwort ab. Einfache LLM-Implementierungen generieren Token für Token ohne expliziten pädagogischen Plan, obwohl Multi-Agent-Systeme oder strukturierte Prompting-Ansätze dies teilweise adressieren können.\nFeedback-Timing: Wann korrigieren, wann weiter fragen lassen? Zu früh verhindert eigenes Denken, zu spät frustriert und verfestigt Fehler. Die Balance hängt vom individuellen Lernenden ab.\nLLM-Sycophancy: LLMs sind darauf trainiert, hilfreich und angenehm zu sein. Sie tendieren dazu, Nutzern zuzustimmen. Das ist das Gegenteil von produktivem sokratischem Unbehagen. Sokrates machte seine Gesprächspartner unbequem. Das war der Punkt.\n\n\nFazit zum sokratischen KI-Tutoring\nDie ehrliche Antwort ist: Wir wissen es noch nicht.\nWas plausibel ist: Selbsterklärung und Generierung fördern Lernen. Fragen können diese Prozesse anregen.\nWas nicht belegt ist: Dass aktuelle KI-Systeme die nötige Diagnose leisten können. Dass LLM-basierte sokratische Tutoren besser sind als Alternativen. Dass positive Effekte langfristig halten.\nSokrates würde es schätzen: Die beste Art, Werkzeuge zu bewerten, die seine Methode beanspruchen, ist, kritische Fragen zu stellen und unbegründete Antworten nicht zu akzeptieren.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: KI-Tutoren evaluieren\n\n\n\n\n\nBei der Evaluation von KI-Tutoring-Tools:\n\nEvidenz verlangen: Peer-Review-Studien mit Learning Outcomes, nicht nur Zufriedenheit\nDiagnose-Fähigkeit prüfen: Kann das System zwischen Fehlertypen unterscheiden?\nOpportunitätskosten bedenken: Ist KI-Tutoring besser als Lehrbuch, Übungsaufgaben, Peer-Diskussion?\nMit strukturierten Domänen beginnen: Mathematik vor Literaturanalyse\nAuf unbeabsichtigte Folgen achten: Strategisches Ausnutzen des Systems statt echtem Lernen, Abhängigkeit von der KI-Unterstützung\nPilotieren und messen: Kleine Versuche mit klaren Erfolgskriterien",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#implikationen",
    "href": "guide/index.html#implikationen",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Implikationen und offene Fragen",
    "text": "Implikationen und offene Fragen\n\nDie unbequeme Wahrheit\nWas bedeutet das alles? Die zentrale These lässt sich nun präzisieren:\n\nWas KI für Produktivität nützlich macht, droht sie für Lernen schädlich zu machen: Sofortige Antworten können die Anstrengung eliminieren, die Kompetenz aufbaut.\n\nDies ist kein Mangel aktueller KI. Es folgt aus etablierten Prinzipien der Kognitionswissenschaft. Das Problem liegt in der Natur des Lernens selbst. Die Frage ist daher nicht ob, sondern wie KI eingesetzt wird.\nEinschränkung: Es gibt noch wenige Studien, die direkt messen, wie KI-Nutzung Lernen über längere Zeit beeinflusst. Die theoretische Argumentation basiert auf etablierten kognitionswissenschaftlichen Prinzipien, aber empirische Langzeitstudien zu generativer KI fehlen noch.\n\n\nKognition erweitern vs. ersetzen\nAndy Clark (Clark 2025) bietet eine praktische Unterscheidung bei der Bewertung von KI-Nutzung:\nKognition erweitern:\n\nDer Mensch bleibt kognitiv engagiert\nWerkzeug verstärkt, ersetzt nicht\nBeispiel: Taschenrechner für einen Mathematiker\nFähigkeiten bleiben erhalten und werden ausgebaut\n\nKognition ersetzen:\n\nDer Mensch wird passiv\nWerkzeug übernimmt das Denken\nBeispiel: KI schreibt den Essay, Studierender submittet\nAbhängigkeit entsteht, Fähigkeiten verkümmern\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung. Die Frage ist nicht “KI ja oder nein?”, sondern “Wie wird KI genutzt?”\nAus Sicht der Cognitive Load Theory ist dabei entscheidend: Wissen, das im Langzeitgedächtnis gespeichert ist, unterscheidet sich fundamental von Wissen, auf das man extern zugreifen kann. Internalisiertes Wissen ermöglicht automatische Mustererkennung, befreit das Arbeitsgedächtnis und erlaubt höheres Denken. Externer Zugang erfordert immer bewusste Abrufprozesse und belastet das Arbeitsgedächtnis.\n\n\nDie Sequenzierungsfrage\nWas bedeutet das praktisch? Die Forschung legt nahe:\n\nStudierende brauchen wahrscheinlich Grundwissen, bevor KI vorteilhaft wird\nDer Expertise-Umkehr-Effekt empfiehlt dynamische KI-Nutzungsregeln\nDie Schwelle, ab der KI von schädlich zu hilfreich wechselt, ist unbekannt\nDie Antwort ist vermutlich domänen- und personenspezifisch\n\nPauschale Empfehlungen zu geben ist schwierig. Die Forschung liefert Prinzipien, aber deren Anwendung erfordert kontextspezifisches Urteilsvermögen und ist abhängig vom Fach, vom Vorwissen und den Lernzielen.\n\n\nDie Entwicklungsfrage\nEin besonderes Anliegen betrifft die kognitive Entwicklung:\n\nDer präfrontale Kortex entwickelt sich bis etwa Mitte 20, wobei verschiedene Funktionen unterschiedlich schnell reifen und individuelle Variation erheblich ist\nExekutive Funktionen, Metakognition, Selbstregulation sind bei vielen Studierenden noch in Entwicklung\nJene, die KI-Nutzung am wenigsten regulieren können, sind möglicherweise am verletzlichsten\n\nDie aktuelle Studierendengeneration könnte die erste sein, die ihre gesamte Bildungslaufbahn mit generativer KI durchläuft. Wenn wir in 20 Jahren Langzeitdaten haben, wird eine Generation bereits das Experiment gewesen sein.\n\n\nDie soziale Dimension\nDieser Leitfaden fokussiert auf kognitive Prozesse: Arbeitsgedächtnis, Schemabildung, Abrufübung. Aber Lernen ist nicht nur ein individueller kognitiver Prozess. Es ist fundamental sozial (Reich 2020)3.\nBeziehungen beeinflussen Lernerfolg. Studierende lernen besser, wenn sie sich mit Lehrenden und Peers verbunden fühlen. Sie zeigen mehr Ausdauer, wenn sie spüren, dass ihre Lehrenden sich für ihren Erfolg interessieren. Disziplinäre Identität entsteht durch Gemeinschaften.\nWas passiert, wenn Studierende KI fragen statt Menschen?\n\nPeers werden seltener konsultiert; kollaboratives Lernen leidet\nBeziehungen zu Lehrenden werden oberflächlicher, wenn Rückfragen an die KI gehen\nGelegenheiten für Mentoring und informelles Lernen nehmen ab\n\nDie Rolle der Lehrperson: Wenn KI sofortige Antworten und Feedback liefert, verschiebt sich die Rolle der Lehrenden. Die Frage ist, wie Lehrende ihre unersetzliche Funktion, nämlich Beziehung, Motivation, Vorbild, Kontext, neu definieren.\n\n\nDie Equity-Dimension\nDie “dritte digitale Kluft” (Michael Trucano 2023) beschreibt ein neues Ungleichheitsmuster:\n\n\n\n\n\n\n\n\nErste Kluft\nZweite Kluft\nDritte Kluft\n\n\n\n\nZugang zu Geräten\nFähigkeit zur sinnvollen Nutzung\nQualität der pädagogischen Integration\n\n\n\nDie Ironie: “Demokratisierung” durch KI könnte Ungleichheit verstärken:\n\nGutausgestattete Studierende: ausgeklügelte pädagogische Unterstützung, informierte Betreuung, strukturierte KI-Nutzung\nUnterversorgte Studierende: KI als unbeaufsichtigte Abkürzung, niemand erklärt die Risiken\n\nKonkrete Ungleichheiten:\n\nKosten: Premium-KI-Werkzeuge kosten Geld. Wer kann sich ChatGPT Plus, Claude Pro oder spezialisierte Tools leisten? Wer ist auf kostenlose, limitierte Versionen angewiesen?\nInstitutionelle Ressourcen: Welche Hochschulen haben Zeit und Expertise für durchdachte KI-Integration? Welche setzen KI ein, ohne Lehrende zu schulen?\nBetreuung: Wer hat Dozierende, die über KI-Risiken aufklären? Wer hat niemanden, der die Fragen stellt?\n\nDas MOOC-Muster wiederholt sich möglicherweise: Eine Technologie, die “allen” zugänglich ist, nützt vor allem jenen, die bereits die Voraussetzungen mitbringen, sie produktiv zu nutzen.\n\n\nDer stärkste Gegeneinwand\nDer stärkste Einwand lautet: “Wenn KI immer verfügbar ist, müssen Fähigkeiten nicht internalisiert werden.”\nVier Antworten:\n\nPermanenzannahme: Setzt voraus, dass KI immer verfügbar, funktional und bezahlbar bleibt. Stromausfall, Serverprobleme, Kosten, politische Entscheidungen können das ändern.\nRekursionsproblem: Wer erkennt, wenn KI falsch liegt? Wer trainiert die nächste KI-Generation? Wer erweitert menschliches Wissen? Irgendwer muss Domänenexpertise haben.\nAutonomie-Argument: Eigenständiges Denken hat intrinsischen Wert für Selbstbestimmung, Würde, das Gefühl des Verstehens. Nicht alles lässt sich in Produktivität messen.\nUnbekannte Unbekannte: Komplexe Systeme haben Kaskadeneffekte. Wir wissen nicht, was wir verlieren könnten.\n\n\n\nWas wir noch nicht wissen\nEpistemische Bescheidenheit ist angebracht. Wir wissen vieles nicht:\n\nLängsschnittstudien über Jahre: Praktisch nicht vorhanden\nTransfer auf neue Kontexte: Unerforscht\nOptimale Scaffolding-Bedingungen: Unbekannt\nDisziplinspezifische Effekte: Untererforscht\nPublikationsbias: Wahrscheinlich vorhanden\n\n\n\nAbschliessende Überlegungen\nDrei Beobachtungen fassen die Lage zusammen:\n\nWenn KI-Unterstützung während der Ausbildung die eigenständige Fähigkeit beeinträchtigt, könnten Studierende weniger vorbereitet sein auf Kontexte, in denen KI nicht verfügbar ist.\nDie Produktivitätsgewinne während der Ausbildung könnten auf Kosten der späteren Kompetenz gehen.\nOb dieser Kompromiss akzeptabel ist, hängt von Annahmen über die Zukunft ab, die Lehrende nicht verifizieren können.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Entscheidungsrahmen\n\n\n\n\n\nFür Entscheidungen über KI in der eigenen Lehre:\nFragen zur Selbstreflexion:\n\nWelche kognitiven Prozesse will ich fördern?\nWelche davon könnte KI übernehmen?\nIst die Übernahme für Lernen förderlich oder hinderlich?\nHaben meine Studierenden das nötige Vorwissen für kritische KI-Nutzung?\nWie kann ich Grundlagen schützen und dennoch KI sinnvoll einsetzen?",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#fazit",
    "href": "guide/index.html#fazit",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Fazit",
    "text": "Fazit\nDie zentrale Botschaft: KI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende ohne durchdachte Integration oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.\nDie Argumentation stützt sich auf:\n\nCognitive Load Theory: Lernen erfordert produktive Anstrengung durch das Nadelöhr des Arbeitsgedächtnisses\nExpertise-Umkehr-Effekt: Dieselbe Unterstützung kann Novizen helfen und Experten schaden\nDomänenspezifität: Kritische KI-Bewertung erfordert Fachwissen, nicht nur generische Strategien\nDesirable Difficulties: Schwierigkeiten, die das Lernen verlangsamen, optimieren oft Langzeitbehalten\nGenerierungseffekt: Selbst erzeugte Information wird besser behalten\n\nDie praktischen Implikationen sind:\n\nGrundlagen vor Werkzeugen sequenzieren\nProzess bewerten, nicht nur Produkt\nNach Vorwissen differenzieren\n“Ohne-KI”-Phasen einplanen\nKritische KI-Nutzung im Fachkontext üben\n\nDie offenen Fragen sind zahlreich. Langzeitstudien fehlen, optimale Strategien sind unbekannt, und die Effekte variieren nach Kontext und Person.\nDie Frage ist nicht, ob KI in die Bildung kommt. Sie ist schon da. Die Frage ist, wie wir sie so gestalten, dass sie dem Lernen dient, nicht es ersetzt.",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "guide/index.html#referenzen",
    "href": "guide/index.html#referenzen",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Referenzen",
    "text": "Referenzen\n\n\nAnderson, John R. 1982. „Acquisition of Cognitive Skill“. Psychological Review 89 (4): 369–406. https://doi.org/10.1037/0033-295X.89.4.369.\n\n\nBastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, und Rei Mariman. 2025. „Generative AI Without Guardrails Can Harm Learning: Evidence from High School Mathematics“. Proceedings of the National Academy of Sciences of the United States of America 122 (26): e2422633122. https://doi.org/10.1073/pnas.2422633122.\n\n\nBjork, Elizabeth Ligon, und Robert A. Bjork. 2011. „Making Things Hard on Yourself, but in a Good Way: Creating Desirable Difficulties to Enhance Learning“. In Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society, 56–64. New York, NY, US: Worth Publishers.\n\n\nBLOOM, BENJAMIN S. 1984. „The 2 Sigma Problem: The Search for Methods of Group Instruction as Effective as One-to-One Tutoring“. Educational Researcher 13 (6): 4–16. https://doi.org/10.3102/0013189X013006004.\n\n\nChase, William G., und Herbert A. Simon. 1973. „Perception in Chess“. Cognitive Psychology 4 (1): 55–81. https://doi.org/10.1016/0010-0285(73)90004-2.\n\n\nChi, Michelene T. H., Nicholas De Leeuw, Mei-Hung Chiu, und Christian Lavancher. 1994. „Eliciting Self-Explanations Improves Understanding“. Cognitive Science 18 (3): 439–77. https://doi.org/10.1207/s15516709cog1803_3.\n\n\nClark, Andy. 2025. „Extending Minds with Generative AI“. Nature Communications 16 (1): 4627. https://doi.org/10.1038/s41467-025-59906-9.\n\n\nCooper, Graham, und John Sweller. 1987. „Effects of Schema Acquisition and Rule Automation on Mathematical Problem-Solving Transfer“. Journal of Educational Psychology 79 (4): 347–62. https://doi.org/10.1037/0022-0663.79.4.347.\n\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nGroot, Adriaan D. De, und Adrianus Dingeman de Groot. 1978. Thought and Choice in Chess. Walter de Gruyter. https://books.google.com?id=EI4gr42NwDQC.\n\n\nJose, Binny, Deepak Joseph, Visakh Mohan, Elizabeth Alexander, Subi K. Varghese, und Abhijith Roy. 2025. „Outsourcing Cognition: The Psychological Costs of AI-Era Convenience“. Frontiers in Psychology 16 (Dezember). https://doi.org/10.3389/fpsyg.2025.1645237.\n\n\nKalyuga, Slava. 2009. „The Expertise Reversal Effect“. In Managing Cognitive Load in Adaptive Multimedia Learning, 58–80. IGI Global Scientific Publishing. https://doi.org/10.4018/978-1-60566-048-6.ch003.\n\n\nKirschner, Paul A., Sweller, und Richard E. and Clark. 2006. „Why Minimal Guidance During Instruction Does Not Work: An Analysis of the Failure of Constructivist, Discovery, Problem-Based, Experiential, and Inquiry-Based Teaching“. Educational Psychologist 41 (2): 75–86. https://doi.org/10.1207/s15326985ep4102_1.\n\n\nLortie-Forgues, Hugues, und Robert S. Siegler. 2017. „Conceptual Knowledge of Decimal Arithmetic.“ Journal of Educational Psychology 109 (3): 374–86. https://doi.org/10.1037/edu0000148.\n\n\nMichael Trucano. 2023. „AI and the Next Digital Divide in Education“. Brookings. 7. Oktober 2023. https://www.brookings.edu/articles/ai-and-the-next-digital-divide-in-education/.\n\n\nNewell, Allen, und Herbert A. Simon. 1972. Human Problem Solving. Brattleboro, Vermont: Echo Point Books & Media.\n\n\nReich, Justin. 2020. Failure to Disrupt: Why Technology Alone Can’t Transform Education. Cambridge London: Harvard University Press.\n\n\nRoediger, Henry L., und Jeffrey D. Karpicke. 2006. „Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention“. Psychological Science 17 (3): 249–55. https://doi.org/10.1111/j.1467-9280.2006.01693.x.\n\n\nSlamecka, Norman J., und Peter Graf. 1978. „The Generation Effect: Delineation of a Phenomenon“. Journal of Experimental Psychology: Human Learning and Memory 4 (6): 592–604. https://doi.org/10.1037/0278-7393.4.6.592.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745.\n\n\nSweller, John. 2024. „Cognitive Load Theory and Individual Differences“. Learning and Individual Differences 110 (Februar): 102423. https://doi.org/10.1016/j.lindif.2024.102423.\n\n\nVanLEHN, KURT. 2011. „The Relative Effectiveness of Human Tutoring, Intelligent Tutoring Systems, and Other Tutoring Systems“. Educational Psychologist 46 (4): 197–221. https://doi.org/10.1080/00461520.2011.611369.\n\n\nWeidlich, J., D. Gašević, H. Drachsler, und P. Kirschner. 2025. „ChatGPT in Education: An Effect in Search of a Cause“. Journal of Computer Assisted Learning 41 (5): e70105. https://doi.org/10.1111/jcal.70105.\n\n\nWillingham, Daniel T. 2008. „Critical Thinking: Why Is It So Hard to Teach?“ Arts Education Policy Review 109 (4): 21–32. https://doi.org/10.3200/AEPR.109.4.21-32.",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-zentrale-frage",
    "href": "slides/ai-higher-ed/index.html#die-zentrale-frage",
    "title": "KI in der Hochschulbildung",
    "section": "Die zentrale Frage",
    "text": "Die zentrale Frage\n\n\nWas KI kann:\n\nAnwaltsprüfungen bestehen\nCode schreiben und debuggen\nKrankheiten diagnostizieren\nWissenschaftliche Texte verfassen\nKomplexe Analysen durchführen\n\n\nAber was bedeutet das für Lernen?\n\nMit KI → 48% mehr Aufgaben gelöst\nOhne KI → 17% schlechter an der Prüfung\n\n(Bastani u. a. 2025)\n\n\nDie Frage ist nicht ob KI hilft, sondern: Wann hilft sie, und wann schadet sie?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#wie-llms-text-produzieren",
    "href": "slides/ai-higher-ed/index.html#wie-llms-text-produzieren",
    "title": "KI in der Hochschulbildung",
    "section": "Wie LLMs Text produzieren",
    "text": "Wie LLMs Text produzieren\n\nNext-word prediction: Welches Wort kommt am wahrscheinlichsten als nächstes?\nTraining auf Milliarden von Textdokumenten\nErkennen von Mustern in Sprache, Argumentation, Stil\nMetapher: Extrem ausgeklügelte Autovervollständigung\n\n\n\n\n\n\n\n\nWichtig\n\n\nLLMs rufen kein Wissen ab. Sie generieren Text basierend auf statistischen Mustern."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#wie-denken-in-ki-funktioniert",
    "href": "slides/ai-higher-ed/index.html#wie-denken-in-ki-funktioniert",
    "title": "KI in der Hochschulbildung",
    "section": "Wie “Denken” in KI funktioniert",
    "text": "Wie “Denken” in KI funktioniert\nChain-of-Thought Reasoning:\n\n\nOhne Reasoning:\n“Was ist 17 × 24?” → “408”\n\nMit Reasoning:\n“Was ist 17 × 24?” → “Lass mich das aufteilen: 17 × 20 = 340 17 × 4 = 68 340 + 68 = 408”\n\n\nKernpunkt: Immer noch Mustererkennung, aber über Denkschritte statt nur über Antworten."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#werkzeug-fähige-agenten",
    "href": "slides/ai-higher-ed/index.html#werkzeug-fähige-agenten",
    "title": "KI in der Hochschulbildung",
    "section": "Werkzeug-fähige Agenten",
    "text": "Werkzeug-fähige Agenten\nLLM + Werkzeuge = Agent\n\nWebsuche durchführen\nCode ausführen\nDateien lesen und schreiben\nBerechnungen anstellen\nAPIs aufrufen\n\n\nKonsequenz: Agenten können fast jede kognitive Aufgabe ausführen:\n\nLiteraturrecherche\nDatenanalyse\nSchreiben und Überarbeiten\nProgrammieren"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion",
    "href": "slides/ai-higher-ed/index.html#diskussion",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion",
    "text": "Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nKurze Diskussion\n\n\n\nWelche KI-Fähigkeiten haben dich überrascht?\nWo hast du Studierende beim Einsatz von KI beobachtet?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#experten-und-novizen-sind-grundlegend-verschieden",
    "href": "slides/ai-higher-ed/index.html#experten-und-novizen-sind-grundlegend-verschieden",
    "title": "KI in der Hochschulbildung",
    "section": "Experten und Novizen sind grundlegend verschieden",
    "text": "Experten und Novizen sind grundlegend verschieden\n\n\nNicht nur “mehr Wissen”\nSondern eine andere kognitive Architektur\n\nKlassisches Beispiel: (Groot und Groot 1978; Chase und Simon 1973)\nSchachmeister sehen Muster und Strategien\nAnfänger sehen Figuren auf Feldern\n\n\n\n“Experts don’t just know more; they organize knowledge differently.”"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#von-schwachen-zu-starken-methoden",
    "href": "slides/ai-higher-ed/index.html#von-schwachen-zu-starken-methoden",
    "title": "KI in der Hochschulbildung",
    "section": "Von schwachen zu starken Methoden",
    "text": "Von schwachen zu starken Methoden\nNewell & Simon (Newell und Simon 1972) | ACT-R (Anderson 1982)\n\n\nNovizen: Schwache Methoden\n\nMittel-Ziel-Analyse\nVersuch und Irrtum\nAnalogiebildung\nRückwärtsarbeiten\n\n\nExperten: Starke Methoden\n\nAutomatische Mustererkennung\nProzeduralisiertes Wissen\nDirekte Lösungswege\n\n\n\nDer Übergang erfordert umfangreiche Übung."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#prozeduralisierung-und-kompilation",
    "href": "slides/ai-higher-ed/index.html#prozeduralisierung-und-kompilation",
    "title": "KI in der Hochschulbildung",
    "section": "Prozeduralisierung und Kompilation",
    "text": "Prozeduralisierung und Kompilation\n\nDeklaratives Wissen: “Man muss beim Autofahren die Kupplung treten, bevor man schaltet”\nBewusste Schritte: Aktiv an jeden Schritt denken\nProzeduralisierung: Schritte werden zu Einheiten zusammengefasst\nAutomatisierung: Unbewusste, flüssige Ausführung\n\n\nDiese Transformation kann nicht übersprungen werden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#cognitive-load-theory-die-grundlagen",
    "href": "slides/ai-higher-ed/index.html#cognitive-load-theory-die-grundlagen",
    "title": "KI in der Hochschulbildung",
    "section": "Cognitive Load Theory: Die Grundlagen",
    "text": "Cognitive Load Theory: Die Grundlagen\nJohn Sweller (Sweller 2024)\n\n\nArbeitsgedächtnis\n\n4±1 Elemente\n15-30 Sekunden\nDer Engpass allen Lernens\n\n\nLangzeitgedächtnis\n\nUnbegrenzte Kapazität\nDauerhafte Speicherung\nHier lebt Expertise\n\n\n\n\n\n\n\n\n\nKernaussage\n\n\nAlles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#drei-arten-kognitiver-belastung",
    "href": "slides/ai-higher-ed/index.html#drei-arten-kognitiver-belastung",
    "title": "KI in der Hochschulbildung",
    "section": "Drei Arten kognitiver Belastung",
    "text": "Drei Arten kognitiver Belastung\n\n\n\n\n\n\n\n\nTyp\nBeschreibung\nZiel\n\n\n\n\nIntrinsisch\nInhärente Komplexität des Materials\nKann nicht reduziert werden ohne Vereinfachung\n\n\nExtrinsisch\nSchlecht gestaltete Instruktion\nMinimieren\n\n\nLernförderlich (Germane)\nProduktive Anstrengung für Schemabildung\nErhalten\n\n\n\n(Anmerkung: Die Unterscheidung von lernförderlicher und intrinsischer Belastung ist in der Literatur umstritten)\n\nEntscheidende Frage: Welche Art der Belastung reduziert KI?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-expertise-umkehr-effekt",
    "href": "slides/ai-higher-ed/index.html#der-expertise-umkehr-effekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Expertise-Umkehr-Effekt",
    "text": "Der Expertise-Umkehr-Effekt\nForschungsüberblick (Kalyuga 2009)\n\n\nGeringe Vorkenntnisse:\nProfitieren von hoher Unterstützung\nMittlere bis grosse Effekte\n\nHohe Vorkenntnisse:\nProfitieren von niedriger Unterstützung\nEffekte kehren sich um\n\n\n\n\n\n\n\n\nImplikation\n\n\nDasselbe Werkzeug kann gegenteilige Effekte haben, abhängig vom Expertisegrad."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#explizite-instruktion-was-lernen-fördert",
    "href": "slides/ai-higher-ed/index.html#explizite-instruktion-was-lernen-fördert",
    "title": "KI in der Hochschulbildung",
    "section": "Explizite Instruktion: Was Lernen fördert",
    "text": "Explizite Instruktion: Was Lernen fördert\nDas Problem mit minimaler Anleitung (Kirschner, und and Clark 2006)\n\nKonstruktivistische, entdeckende Ansätze klingen attraktiv\nAber: Für Novizen ist minimale Anleitung weniger effektiv\nNovizen haben keine Schemata im Langzeitgedächtnis\nIhr Arbeitsgedächtnis wird schnell überlastet\n\n\nEvidenzbasierte Alternative: Explizite Instruktion mit Worked Examples"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#worked-examples-ein-robuster-befund",
    "href": "slides/ai-higher-ed/index.html#worked-examples-ein-robuster-befund",
    "title": "KI in der Hochschulbildung",
    "section": "Worked Examples: Ein robuster Befund",
    "text": "Worked Examples: Ein robuster Befund\nStatt Probleme selbst lösen: Ausgearbeitete Lösungswege zeigen (Cooper und Sweller 1987)\n\n\nFür Novizen:\n\nReduziert extrinsische Belastung\nLässt Kapazität für Schemabildung\nEiner der robustesten Befunde der Instruktionsforschung\n\n\nAber Achtung:\nWorked Examples ≠ KI-generierte Lösungen\n\n\n\n\n\n\n\n\nDer entscheidende Unterschied\n\n\nWorked Examples sind didaktisch gestaltet, heben relevante Schritte hervor, bauen systematisch Komplexität auf und werden von Lehrenden ausgewählt.\nKI-generierte Antworten beantworten die gestellte Frage, aber ohne Einbettung in eine geplante Lernprogression.\n\n\n\n\n\n\n\n\n\n\n\nNuance\n\n\nLLMs können mit entsprechendem Prompting didaktisch strukturierte Erklärungen liefern, aber das erfordert pädagogisches Wissen, das Novizen typischerweise nicht haben."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#von-worked-examples-zu-selbständigem-lösen",
    "href": "slides/ai-higher-ed/index.html#von-worked-examples-zu-selbständigem-lösen",
    "title": "KI in der Hochschulbildung",
    "section": "Von Worked Examples zu selbständigem Lösen",
    "text": "Von Worked Examples zu selbständigem Lösen\nFading: Unterstützung systematisch reduzieren\n\nVollständige Worked Examples zeigen\nCompletion Problems: Teilweise gelöste Aufgaben vervollständigen\nZunehmend weniger Vorgaben\nSelbständiges Lösen ohne Unterstützung\n\n\nVerbindung zum Expertise-Umkehr-Effekt:\nWas Novizen hilft, kann Experten behindern. Daher: dynamische Anpassung."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion-think-pair-share",
    "href": "slides/ai-higher-ed/index.html#diskussion-think-pair-share",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion: Think-Pair-Share",
    "text": "Diskussion: Think-Pair-Share\n                    \n                    \n                \n\n\n\n\n\n\nReflexion\n\n\nThink: Denke an eine Fähigkeit, die du gemeistert hast. Wie hat sich der Lernprozess angefühlt?\nPair: Tausche dich mit deinem Nachbarn aus.\nShare: Wie hat sich dein Denken verändert, als du Experte wurdest?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-traditionelle-annahme",
    "href": "slides/ai-higher-ed/index.html#die-traditionelle-annahme",
    "title": "KI in der Hochschulbildung",
    "section": "Die traditionelle Annahme",
    "text": "Die traditionelle Annahme\n\nKritisches Denken als übertragbare Fähigkeit\n“21st Century Skills”-Initiativen\nKI-Kompetenz als generische Fertigkeit\n“Wir müssen Studierende lehren, KI kritisch zu nutzen”\n\n\nAber stimmt diese Annahme?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#willinghams-herausforderung",
    "href": "slides/ai-higher-ed/index.html#willinghams-herausforderung",
    "title": "KI in der Hochschulbildung",
    "section": "Willinghams Herausforderung",
    "text": "Willinghams Herausforderung\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n(Willingham 2008)\n\n\nDenkprozesse sind eng mit Fachwissen verflochten.\nWillinghams Formulierung ist zugespitzt — aber der Kern stimmt: Transfer ist schwieriger als oft angenommen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#evidenz-für-domänenspezifität",
    "href": "slides/ai-higher-ed/index.html#evidenz-für-domänenspezifität",
    "title": "KI in der Hochschulbildung",
    "section": "Evidenz für Domänenspezifität",
    "text": "Evidenz für Domänenspezifität\n\nNeurologen können Herzerkrankungen nicht gut diagnostizieren\nFachredakteure können keine Zeitungsartikel schreiben\nSelbst Philosophen werden von irrelevanten Merkmalen beeinflusst\n\n\n\n“Abstract principles like ‘look for hidden assumptions’ won’t help much in evaluating an argument about a topic you know little about.”"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#angewendet-auf-ki-bewertung",
    "href": "slides/ai-higher-ed/index.html#angewendet-auf-ki-bewertung",
    "title": "KI in der Hochschulbildung",
    "section": "Angewendet auf KI-Bewertung",
    "text": "Angewendet auf KI-Bewertung\n\n\nExperte in Biomedizin:\nErkennt, wenn ChatGPT bei Biochemie falsch liegt\nHat das Domänenwissen zur Bewertung\n\nNovize:\nKann diese Bewertung nicht vornehmen, unabhängig von “kritischem Denken”\nFehlendes Fachwissen verhindert Evaluation\n\n\nWas wie “kritisches Denken” aussieht, ist oft Domänenwissen in Aktion."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-transferiert-und-was-nicht",
    "href": "slides/ai-higher-ed/index.html#was-transferiert-und-was-nicht",
    "title": "KI in der Hochschulbildung",
    "section": "Was transferiert — und was nicht",
    "text": "Was transferiert — und was nicht\n\n\nTransferiert (teilweise):\n\nPlanung des Vorgehens\nÜberwachung des Verständnisses\nSelbstregulation\nBereitschaft, Annahmen zu hinterfragen\n\nMetakognitive Strategien zeigen gewisse Generalisierung\n\nTransferiert kaum:\n\nWissen, was plausibel ist\nWissen, welche Quellen autoritativ sind\nErkennen von fachspezifischen Fehlern\n\nInhaltliche Bewertung erfordert Domänenwissen\n\n\nKernpunkt: Die Strategien kann man lehren — ihre Anwendung erfordert Fachwissen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-zentrale-implikation",
    "href": "slides/ai-higher-ed/index.html#die-zentrale-implikation",
    "title": "KI in der Hochschulbildung",
    "section": "Die zentrale Implikation",
    "text": "Die zentrale Implikation\n\n\n\n\n\n\nKernaussage\n\n\n\nStudierende, die “mit hohem kritischem Denken” von KI profitieren, haben wahrscheinlich mehr Domänenexpertise\nDie beste Vorbereitung für kritische KI-Nutzung ist tiefes Fachlernen\nGenerische “KI-Kompetenz” kann Fachwissen ergänzen, aber nicht ersetzen"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion-1",
    "href": "slides/ai-higher-ed/index.html#diskussion-1",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion",
    "text": "Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nKurze Diskussion\n\n\n\nHast du beobachtet, dass Studierende KI-Outputs in deinem Fach nicht bewerten können?\nWelches Domänenwissen wäre nötig?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-zentrale-paradox",
    "href": "slides/ai-higher-ed/index.html#das-zentrale-paradox",
    "title": "KI in der Hochschulbildung",
    "section": "Das zentrale Paradox",
    "text": "Das zentrale Paradox\n\n“Learning and task completion are not synonymous.”\n(Jose u. a. 2025)\n\n\n\n\nKI verbessert nachweislich:\n\nAufgabenleistung\nGeschwindigkeit\nOutput-Qualität\n\n\nAber:\nAufgabenleistung ≠ Lernen\nProduktivität ≠ Kompetenzaufbau"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-bastani-studie-mathematik",
    "href": "slides/ai-higher-ed/index.html#die-bastani-studie-mathematik",
    "title": "KI in der Hochschulbildung",
    "section": "Die Bastani-Studie: Mathematik",
    "text": "Die Bastani-Studie: Mathematik\nRandomisierte kontrollierte Studie (Bastani u. a. 2025)\nEinzelstudie, Replikation ausstehend\n\n~1000 türkische Gymnasiasten\nGPT-4 Zugang während des Übens\n\n\n\n\nMit KI:\n48% mehr Aufgaben korrekt gelöst (direkter Zugang)\n127% mit “GPT Tutor” (strukturierte Unterstützung)\n\nOhne KI (später):\n17% schlechter als Kontrollgruppe\nDie nie KI hatte\n\n\n\n\n“Students attempt to use GPT-4 as a ‘crutch’ during practice sessions, and when successful, perform worse on their own.”\n\n\n\n\n\n\n\n\n\nNuance\n\n\nDie Schlussfolgerungen gelten hauptsächlich für KI als Antwortgeber. KI als pädagogisch gestalteter Tutor könnte andere Effekte haben — wie die 127% beim “GPT Tutor” andeuten."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#desirable-difficulties-warum-anstrengung-nötig-ist",
    "href": "slides/ai-higher-ed/index.html#desirable-difficulties-warum-anstrengung-nötig-ist",
    "title": "KI in der Hochschulbildung",
    "section": "Desirable Difficulties: Warum Anstrengung nötig ist",
    "text": "Desirable Difficulties: Warum Anstrengung nötig ist\nRobert Bjork (Bjork und Bjork 2011)\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\n\nVier bewährte “erwünschte Schwierigkeiten”:\n\nVariation der Lernbedingungen\nInterleaving: Mischen von Aufgabentypen\nSpacing: Verteiltes statt massiertes Lernen\nRetrieval Practice: Abrufen statt Wiederlesen (Roediger und Karpicke 2006)\n\n\n\n\n\n\n\n\n\nMechanismus\n\n\nSofortiger KI-Zugang kann Abrufversuche kurzschliessen, bevor sie Gedächtnisspuren stärken können."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-generierungseffekt",
    "href": "slides/ai-higher-ed/index.html#der-generierungseffekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Generierungseffekt",
    "text": "Der Generierungseffekt\nSelbst generierte Information wird besser behalten (Slamecka und Graf 1978)\n\n\nSelbst generiert:\nAktiviert breite neuronale Netzwerke\nBessere Langzeitspeicherung\n\nPassiv erhalten:\nGeringere Verarbeitung\nSchwächere Erinnerung\n\n\n\n\n\n\n\n\nImplikation\n\n\nWenn KI generiert, was Studierende selbst produzieren sollten, wird der Generierungseffekt eliminiert."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-scaffolding-hypothese",
    "href": "slides/ai-higher-ed/index.html#die-scaffolding-hypothese",
    "title": "KI in der Hochschulbildung",
    "section": "Die Scaffolding-Hypothese",
    "text": "Die Scaffolding-Hypothese\nWas wissen wir, was vermuten wir?\n\nWas wir wissen (Evidenz): Atrophie von Fähigkeiten ist dokumentiert. Eine vorhandene Fähigkeit verkümmert durch Nichtgebrauch. Das ist reversibel.\nWas wir theoretisch ableiten: Wenn KI die kognitiven Prozesse übernimmt, die für Lernen notwendig sind, sollte weniger Lernen stattfinden. Das folgt aus der CLT.\nWas wir vermuten (Hypothese): Es könnte einen Unterschied geben zwischen Fertigkeitsatrophie und Entwicklungsbeeinträchtigung.\n\n\nDie Hypothese: Grundfertigkeiten wie Schreiben sind nicht nur Fertigkeiten, sondern Prozesse, die kognitive Architektur aufbauen. Schreiben könnte ein “epistemisches Werkzeug” sein.\n\n\n\n\n\n\n\n\nVorsicht\n\n\nDiese Hypothese ist plausibel, aber nicht empirisch belegt. Wir haben keine Längsschnittstudien. Die Bedenken verdienen Aufmerksamkeit, sollten aber nicht als gesicherte Fakten behandelt werden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#historische-analogien",
    "href": "slides/ai-higher-ed/index.html#historische-analogien",
    "title": "KI in der Hochschulbildung",
    "section": "Historische Analogien",
    "text": "Historische Analogien\nGPS und räumliches Gedächtnis (Dahmani und Bohbot 2020)\n\nStärkere GPS-Nutzung korreliert mit steilerem Rückgang des räumlichen Gedächtnisses\nLongitudinale Studie über 3 Jahre\nZeitliche Abfolge konsistent mit kausaler Interpretation (ungemessene Konfundierende nicht ausgeschlossen)\n\n\nKonzeptuelles Verständnis (Lortie-Forgues und Siegler 2017)\n\nAuch Erwachsene mit Rechenhilfen zeigen Lücken im konzeptuellen Verständnis\nWerkzeugnutzung ersetzt kein Grundverständnis\n\n\n\nGoogle-Effekt (Sparrow, Liu, und Wegner 2011)\n\nGeringere Erinnerung, wenn Information als verfügbar erwartet wird\nMenschen erinnern wo, nicht was"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#grenzen-historischer-analogien",
    "href": "slides/ai-higher-ed/index.html#grenzen-historischer-analogien",
    "title": "KI in der Hochschulbildung",
    "section": "Grenzen historischer Analogien",
    "text": "Grenzen historischer Analogien\n\nGPS, Taschenrechner, Google: jeweils spezifische, enge kognitive Funktionen\nGenerative KI kann fast jede kognitive Aufgabe übernehmen\nSchreiben, Argumentieren, Analysieren, Synthetisieren, Bewerten\nDie Breite ist beispiellos\n\n\nAber: Die historischen Bedenken hatten oft Berechtigung. GPS beeinflusst räumliche Kognition. Taschenrechner veränderten Mathematikunterricht."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-edtech-hype-zyklus",
    "href": "slides/ai-higher-ed/index.html#der-edtech-hype-zyklus",
    "title": "KI in der Hochschulbildung",
    "section": "Der EdTech-Hype-Zyklus",
    "text": "Der EdTech-Hype-Zyklus\nBildungstechnologien folgen einem wiederkehrenden Muster (Reich 2020)\n\nRadio sollte die besten Vorlesungen in jedes Klassenzimmer bringen\nFernsehen sollte Lernen revolutionieren\nComputer sollten Unterricht personalisieren\nMOOCs sollten Elite-Bildung demokratisieren\n\n\nJede Technologie fand eine Nische, aber keine erfüllte die transformativen Versprechen.\n\n\nWas macht KI anders? Die Breite ist beispiellos. Aber dieselben strukturellen Kräfte könnten wirken."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-haben-sie-über-das-schreiben-auch-gesagt",
    "href": "slides/ai-higher-ed/index.html#das-haben-sie-über-das-schreiben-auch-gesagt",
    "title": "KI in der Hochschulbildung",
    "section": "“Das haben sie über das Schreiben auch gesagt”",
    "text": "“Das haben sie über das Schreiben auch gesagt”\nSokrates’ Warnung im Phaidros: Schrift wird das Gedächtnis schwächen.\n\nDrei Antworten:\n\nSchrift hat Kognition tiefgreifend verändert\nEinige Bedenken waren berechtigt (mündliche Gedächtnistraditionen sind zurückgegangen)\nSchriftkultur entwickelte sich über Jahrhunderte — KI-Integration geschieht in Jahren"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#warum-experten-profitieren-lernende-nicht",
    "href": "slides/ai-higher-ed/index.html#warum-experten-profitieren-lernende-nicht",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Experten profitieren, Lernende nicht",
    "text": "Warum Experten profitieren, Lernende nicht\n\n\nExperten können:\n\nRoutine-Aufgaben sicher auslagern (sie wissen, was “Routine” ist)\nHöheres Denken aufrechterhalten (kognitive Kapazität wird frei)\nKI-Outputs bewerten (sie haben Domänenexpertise)\nIhre Grundfähigkeiten verkümmern nicht (sie sind schon da)\n\n\nLernenden fehlt:\n\nWissen zur Bewertung (sie können nicht einschätzen, ob KI richtig liegt)\nEtablierte Grundfähigkeiten (was nicht da ist, entsteht auch nicht)\nMetakognitive Kontrolle (sie wissen nicht, wann KI-Nutzung schadet)\n\n\n\nDas Ergebnis kann “fliessende Inkompetenz” sein: Anspruchsvoll wirkende Outputs ohne zugrundeliegendes Verständnis.\n\n\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen. Das ist der Expertise-Umkehr-Effekt, angewandt auf KI."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion-think-pair-share-1",
    "href": "slides/ai-higher-ed/index.html#diskussion-think-pair-share-1",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion: Think-Pair-Share",
    "text": "Diskussion: Think-Pair-Share\n                    \n                    \n                \n\n\n\n\n\n\nReflexion\n\n\nThink: Wo könnte KI-Unterstützung in deinem Fach die produktive Anstrengung eliminieren, die Lernen ermöglicht?\nPair: Diskutiere mit deinem Nachbarn.\nShare: Welche Grundfähigkeiten könnten bei KI-Nutzung verkümmern?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-hype-um-den-digitalen-sokrates",
    "href": "slides/ai-higher-ed/index.html#der-hype-um-den-digitalen-sokrates",
    "title": "KI in der Hochschulbildung",
    "section": "Der Hype um den digitalen Sokrates",
    "text": "Der Hype um den digitalen Sokrates\n\nEdTech verspricht: KI-Tutoren mit “sokratischer Methode”\nBlooms “Two Sigma Problem” (BLOOM 1984): 1:1-Tutoring erzielt 2 SD Verbesserung\nVersprechen: Demokratisierung personalisierter Bildung durch KI\n\n\n\n\n\n\n\n\nAber\n\n\nDie Begeisterung übersteigt die Evidenz erheblich."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#warum-fragen-theoretisch-helfen-könnten",
    "href": "slides/ai-higher-ed/index.html#warum-fragen-theoretisch-helfen-könnten",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Fragen theoretisch helfen könnten",
    "text": "Warum Fragen theoretisch helfen könnten\n\n\nGenerierungseffekt\nSelbst erzeugte Antworten werden besser behalten als passiv erhaltene (Slamecka und Graf 1978)\n\nSelbsterklärungseffekt\nErklären fördert tiefere Verarbeitung und deckt Wissenslücken auf (Chi u. a. 1994)\n\n\nAber: Diese Effekte erfordern, dass Lernende genug Vorwissen haben, um sinnvolle Antworten zu generieren."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-die-evidenz-tatsächlich-zeigt",
    "href": "slides/ai-higher-ed/index.html#was-die-evidenz-tatsächlich-zeigt",
    "title": "KI in der Hochschulbildung",
    "section": "Was die Evidenz tatsächlich zeigt",
    "text": "Was die Evidenz tatsächlich zeigt\nVanLEHN (2011): Meta-Analyse zu Tutoring\n\nMenschliche Tutoren: d = 0.79 (nicht 2.0 wie Bloom behauptete)\nIntelligente Tutorsysteme: d = 0.76 (vergleichbar)\nAber: Schritt-für-Schritt-Feedback war wesentlich; die Rolle des sokratischen Dialogs ist schwer zu isolieren\n\n\n\n\n\n\n\n\nZu LLM-basierten sokratischen Tutoren\n\n\nKeine gut kontrollierten RCTs vorhanden. Die Evidenz besteht hauptsächlich aus Zufriedenheitsumfragen und Vergleichen mit “kein Tutoring”."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-diagnose-problem",
    "href": "slides/ai-higher-ed/index.html#das-diagnose-problem",
    "title": "KI in der Hochschulbildung",
    "section": "Das Diagnose-Problem",
    "text": "Das Diagnose-Problem\nEffektives sokratisches Fragen erfordert:\n\nGenaue Einschätzung des aktuellen Wissensstands\nUnterscheidung verschiedener Fehlertypen\nAnpassung der Fragen an den Lernenden\n\n\nBeispiel: “1/2 + 1/3 = 2/5” kann bedeuten:\n\nProzeduraler Fehler (Zähler und Nenner addiert)\nKonzeptueller Fehler (versteht Brüche nicht)\nFlüchtigkeitsfehler\n\n\n\nKI-Systeme können diese Unterscheidung nicht zuverlässig treffen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#weitere-implementierungsherausforderungen",
    "href": "slides/ai-higher-ed/index.html#weitere-implementierungsherausforderungen",
    "title": "KI in der Hochschulbildung",
    "section": "Weitere Implementierungsherausforderungen",
    "text": "Weitere Implementierungsherausforderungen\n\n\nFragesequenzierung\n\nSokratischer Dialog ist kontingent\nJede Frage baut auf vorherigen Antworten auf\nLLMs generieren Token, keine pädagogischen Pläne\n\n\nFeedback-Timing\n\nWann korrigieren, wann weiter fragen?\nAbhängig von Lernenden und Fehlertyp\nKI kann das nicht zuverlässig beurteilen\n\n\n\nTendenz von LLMs: Zu nachgiebig, akzeptieren falsche Antworten, vermeiden produktives Unbehagen"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#praktische-empfehlungen",
    "href": "slides/ai-higher-ed/index.html#praktische-empfehlungen",
    "title": "KI in der Hochschulbildung",
    "section": "Praktische Empfehlungen",
    "text": "Praktische Empfehlungen\n\nEvidenz verlangen: Peer-Review-Studien mit Lernoutcomes, nicht nur Zufriedenheit\nDiagnose-Fähigkeit prüfen: Kann das System verschiedene Fehlertypen unterscheiden?\nOpportunitätskosten bedenken: Ist KI-Tutoring besser als Alternativen?\nMit strukturierten Domänen beginnen: Mathematik vor Literaturanalyse\nAuf unbeabsichtigte Folgen achten: Gaming, Abhängigkeit von externen Prompts"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#fazit-zum-sokratischen-ki-tutoring",
    "href": "slides/ai-higher-ed/index.html#fazit-zum-sokratischen-ki-tutoring",
    "title": "KI in der Hochschulbildung",
    "section": "Fazit zum sokratischen KI-Tutoring",
    "text": "Fazit zum sokratischen KI-Tutoring\n\n“Die ehrliche Antwort ist: Wir wissen es noch nicht.”\n\n\n\n\nWas plausibel ist:\nSelbsterklärung und Generierung fördern Lernen\n\nWas nicht belegt ist:\nDass aktuelle KI-Systeme dies effektiv implementieren können\n\n\n\nSokrates würde es schätzen: Die beste Art, Werkzeuge zu bewerten, die seine Methode beanspruchen, ist, kritische Fragen zu stellen und unbegründete Antworten nicht zu akzeptieren."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-unbequeme-wahrheit",
    "href": "slides/ai-higher-ed/index.html#die-unbequeme-wahrheit",
    "title": "KI in der Hochschulbildung",
    "section": "Die unbequeme Wahrheit",
    "text": "Die unbequeme Wahrheit\n\n\n\n\n\n\nKernaussage\n\n\nWas KI für Produktivität nützlich macht, droht sie für Lernen schädlich zu machen.\nSofortige Antworten können die Anstrengung eliminieren, die Kompetenz aufbaut.\nDies ist kein Mangel aktueller KI. Es folgt aus etablierten Prinzipien der Kognitionswissenschaft. Die Frage ist daher nicht ob, sondern wie KI eingesetzt wird.\n\n\n\n\n\n\n\n\n\n\nEinschränkung\n\n\nEs gibt noch wenige Studien, die direkt messen, wie KI-Nutzung Lernen über längere Zeit beeinflusst. Die theoretische Argumentation basiert auf etablierten Prinzipien, aber empirische Langzeitstudien zu generativer KI fehlen noch."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#mind-extending-vs.-mind-replacing",
    "href": "slides/ai-higher-ed/index.html#mind-extending-vs.-mind-replacing",
    "title": "KI in der Hochschulbildung",
    "section": "Mind-extending vs. Mind-replacing",
    "text": "Mind-extending vs. Mind-replacing\nAndy Clark (Clark 2025)\n\n\nKognition erweitern:\n\nDer Mensch bleibt kognitiv engagiert\nWerkzeug verstärkt, ersetzt nicht\nBeispiel: Taschenrechner für Mathematiker\nFähigkeiten bleiben erhalten und werden ausgebaut\n\n\nKognition ersetzen:\n\nDer Mensch wird passiv\nWerkzeug übernimmt das Denken\nBeispiel: KI schreibt Essay, Studierender submittet\nAbhängigkeit entsteht, Fähigkeiten verkümmern\n\n\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung.\n\n\n\n\n\n\n\n\nAus Sicht der Cognitive Load Theory\n\n\nWissen im Langzeitgedächtnis unterscheidet sich fundamental von extern zugänglichem Wissen. Internalisiertes Wissen ermöglicht automatische Mustererkennung, befreit das Arbeitsgedächtnis und erlaubt höheres Denken. Externer Zugang erfordert immer bewusste Abrufprozesse."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-sequenzierungsfrage",
    "href": "slides/ai-higher-ed/index.html#die-sequenzierungsfrage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Sequenzierungsfrage",
    "text": "Die Sequenzierungsfrage\n\nStudierende brauchen wahrscheinlich Grundwissen BEVOR KI vorteilhaft wird\nDer Expertise-Umkehr-Effekt empfiehlt dynamische KI-Nutzungsregeln\nDie Schwelle, ab der KI von schädlich zu hilfreich wechselt, ist unbekannt\nDie Antwort ist vermutlich domänen- und personenspezifisch\n\n\n\n\n\n\n\n\nKeine Pauschallösungen\n\n\nDie Forschung liefert Prinzipien, aber deren Anwendung erfordert kontextspezifisches Urteilsvermögen: abhängig vom Fach, vom Vorwissen und den Lernzielen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-entwicklungsfrage",
    "href": "slides/ai-higher-ed/index.html#die-entwicklungsfrage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Entwicklungsfrage",
    "text": "Die Entwicklungsfrage\nKognitive Entwicklung und KI\n\nDer präfrontale Kortex entwickelt sich bis etwa Mitte 20 (individuelle Variation erheblich)\nExekutive Funktionen, Metakognition, Selbstregulation sind bei vielen Studierenden noch in Entwicklung\nParadox: Jene, die KI-Nutzung am wenigsten regulieren können, sind möglicherweise am verletzlichsten\n\n\n\n\n\n\n\n\nDie Kohortenfrage\n\n\nDie aktuelle Studierendengeneration ist möglicherweise die erste, die ihre gesamte Bildungslaufbahn mit generativer KI durchläuft.\nWenn wir Langzeitdaten haben, wird eine Generation bereits das Experiment gewesen sein."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-soziale-dimension",
    "href": "slides/ai-higher-ed/index.html#die-soziale-dimension",
    "title": "KI in der Hochschulbildung",
    "section": "Die soziale Dimension",
    "text": "Die soziale Dimension\nLernen ist nicht nur ein kognitiver, sondern ein sozialer Prozess (Reich 2020)\n\nStudierende lernen besser, wenn sie sich mit Lehrenden und Peers verbunden fühlen\nPeers werden seltener konsultiert, wenn KI antwortet: kollaboratives Lernen leidet\nBeziehungen zu Lehrenden werden oberflächlicher, wenn Rückfragen an die KI gehen\nGelegenheiten für Mentoring und informelles Lernen nehmen ab\n\n\nDie Rolle der Lehrperson: Wenn KI sofortige Antworten und Feedback liefert, verschiebt sich die Rolle der Lehrenden. Beziehung, Motivation, Vorbild, Kontext: diese unersetzliche Funktion muss neu definiert werden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-equity-dimension",
    "href": "slides/ai-higher-ed/index.html#die-equity-dimension",
    "title": "KI in der Hochschulbildung",
    "section": "Die Equity-Dimension",
    "text": "Die Equity-Dimension\nDie dritte digitale Kluft (Michael Trucano 2023)\n\n\n\n\n\n\n\n\n\nErste Kluft\nZweite Kluft\nDritte Kluft\n\n\n\n\nZugang zu Geräten\nFähigkeit zur sinnvollen Nutzung\nQualität der pädagogischen Integration\n\n\n\n\n\nKonkrete Ungleichheiten:\n\nKosten: Premium-KI-Werkzeuge kosten Geld. Wer kann sich ChatGPT Plus leisten?\nInstitutionelle Ressourcen: Welche Hochschulen haben Zeit und Expertise für durchdachte Integration?\nBetreuung: Wer hat Dozierende, die über KI-Risiken aufklären?\n\n\n\n\n\n\n\n\n\nRisiko\n\n\n“Demokratisierung” von Bildung durch KI könnte genau jene benachteiligen, denen sie helfen soll.\nDas MOOC-Muster wiederholt sich möglicherweise: Eine Technologie, die “allen” zugänglich ist, nützt vor allem jenen, die bereits die Voraussetzungen mitbringen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-stärkste-gegeneinwand",
    "href": "slides/ai-higher-ed/index.html#der-stärkste-gegeneinwand",
    "title": "KI in der Hochschulbildung",
    "section": "Der stärkste Gegeneinwand",
    "text": "Der stärkste Gegeneinwand\n\n“Wenn KI immer verfügbar ist, müssen Fähigkeiten nicht internalisiert werden.”\n\n\nVier Antworten:\n\nPermanenzannahme: Setzt voraus, dass KI immer verfügbar, funktional und bezahlbar bleibt\nRekursionsproblem: Wer erkennt, wenn KI falsch liegt? Wer erweitert menschliches Wissen?\nAutonomie-Argument: Eigenständige kognitive Fähigkeit hat intrinsischen Wert\nUnbekannte Unbekannte: Wir wissen nicht, welche Kaskadeneffekte folgen könnten"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-wir-noch-nicht-wissen",
    "href": "slides/ai-higher-ed/index.html#was-wir-noch-nicht-wissen",
    "title": "KI in der Hochschulbildung",
    "section": "Was wir noch nicht wissen",
    "text": "Was wir noch nicht wissen\n\nLängsschnittstudien über Jahre: Praktisch nicht vorhanden\nTransfer auf neue Kontexte: Unerforscht\nOptimale Scaffolding-Bedingungen: Unbekannt\nDisziplinspezifische Effekte: Untererforscht\nPublikationsbias: Wahrscheinlich vorhanden\n\n\nEpistemische Bescheidenheit ist angebracht."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#abschliessende-provokationen",
    "href": "slides/ai-higher-ed/index.html#abschliessende-provokationen",
    "title": "KI in der Hochschulbildung",
    "section": "Abschliessende Provokationen",
    "text": "Abschliessende Provokationen\n\n“If AI assistance during education impairs independent capability, students may graduate less prepared for contexts where AI is unavailable.”\n\n\n\n“The productivity gains during education would come at the cost of capability thereafter.”\n\n\n\n\n“Whether this tradeoff is acceptable depends on assumptions about the future that educators cannot verify.”\n\n\n\n\n“Wenn wir uns bei den Risiken irren, haben wir die Einführung nützlicher Technologie etwas verlangsamt. Wenn sich die Kritiker bei der Sicherheit irren, haben wir möglicherweise die kognitive Entwicklung einer Generation beeinträchtigt.”"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#offene-diskussion",
    "href": "slides/ai-higher-ed/index.html#offene-diskussion",
    "title": "KI in der Hochschulbildung",
    "section": "Offene Diskussion",
    "text": "Offene Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nDiskussionsfragen\n\n\n\nWas bedeutet das für deine Lehre?\nWo siehst du die Experten-Lernenden-Unterscheidung in der Praxis?\nWas sind die schwierigsten Fragen, die das aufwirft?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#referenzen",
    "href": "slides/ai-higher-ed/index.html#referenzen",
    "title": "KI in der Hochschulbildung",
    "section": "Referenzen",
    "text": "Referenzen\n\n\nAnderson, John R. 1982. „Acquisition of Cognitive Skill“. Psychological Review 89 (4): 369–406. https://doi.org/10.1037/0033-295X.89.4.369.\n\n\nBastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, und Rei Mariman. 2025. „Generative AI Without Guardrails Can Harm Learning: Evidence from High School Mathematics“. Proceedings of the National Academy of Sciences of the United States of America 122 (26): e2422633122. https://doi.org/10.1073/pnas.2422633122.\n\n\nBjork, Elizabeth Ligon, und Robert A. Bjork. 2011. „Making Things Hard on Yourself, but in a Good Way: Creating Desirable Difficulties to Enhance Learning“. In Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society, 56–64. New York, NY, US: Worth Publishers.\n\n\nBLOOM, BENJAMIN S. 1984. „The 2 Sigma Problem: The Search for Methods of Group Instruction as Effective as One-to-One Tutoring“. Educational Researcher 13 (6): 4–16. https://doi.org/10.3102/0013189X013006004.\n\n\nChase, William G., und Herbert A. Simon. 1973. „Perception in Chess“. Cognitive Psychology 4 (1): 55–81. https://doi.org/10.1016/0010-0285(73)90004-2.\n\n\nChi, Michelene T. H., Nicholas De Leeuw, Mei-Hung Chiu, und Christian Lavancher. 1994. „Eliciting Self-Explanations Improves Understanding“. Cognitive Science 18 (3): 439–77. https://doi.org/10.1207/s15516709cog1803_3.\n\n\nClark, Andy. 2025. „Extending Minds with Generative AI“. Nature Communications 16 (1): 4627. https://doi.org/10.1038/s41467-025-59906-9.\n\n\nCooper, Graham, und John Sweller. 1987. „Effects of Schema Acquisition and Rule Automation on Mathematical Problem-Solving Transfer“. Journal of Educational Psychology 79 (4): 347–62. https://doi.org/10.1037/0022-0663.79.4.347.\n\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nGroot, Adriaan D. De, und Adrianus Dingeman de Groot. 1978. Thought and Choice in Chess. Walter de Gruyter. https://books.google.com?id=EI4gr42NwDQC.\n\n\nJose, Binny, Deepak Joseph, Visakh Mohan, Elizabeth Alexander, Subi K. Varghese, und Abhijith Roy. 2025. „Outsourcing Cognition: The Psychological Costs of AI-Era Convenience“. Frontiers in Psychology 16 (Dezember). https://doi.org/10.3389/fpsyg.2025.1645237.\n\n\nKalyuga, Slava. 2009. „The Expertise Reversal Effect“. In Managing Cognitive Load in Adaptive Multimedia Learning, 58–80. IGI Global Scientific Publishing. https://doi.org/10.4018/978-1-60566-048-6.ch003.\n\n\nKirschner, Paul A., Sweller, und Richard E. and Clark. 2006. „Why Minimal Guidance During Instruction Does Not Work: An Analysis of the Failure of Constructivist, Discovery, Problem-Based, Experiential, and Inquiry-Based Teaching“. Educational Psychologist 41 (2): 75–86. https://doi.org/10.1207/s15326985ep4102_1.\n\n\nLortie-Forgues, Hugues, und Robert S. Siegler. 2017. „Conceptual Knowledge of Decimal Arithmetic.“ Journal of Educational Psychology 109 (3): 374–86. https://doi.org/10.1037/edu0000148.\n\n\nMichael Trucano. 2023. „AI and the Next Digital Divide in Education“. Brookings. 7. Oktober 2023. https://www.brookings.edu/articles/ai-and-the-next-digital-divide-in-education/.\n\n\nNewell, Allen, und Herbert A. Simon. 1972. Human Problem Solving. Brattleboro, Vermont: Echo Point Books & Media.\n\n\nReich, Justin. 2020. Failure to Disrupt: Why Technology Alone Can’t Transform Education. Cambridge London: Harvard University Press.\n\n\nRoediger, Henry L., und Jeffrey D. Karpicke. 2006. „Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention“. Psychological Science 17 (3): 249–55. https://doi.org/10.1111/j.1467-9280.2006.01693.x.\n\n\nSlamecka, Norman J., und Peter Graf. 1978. „The Generation Effect: Delineation of a Phenomenon“. Journal of Experimental Psychology: Human Learning and Memory 4 (6): 592–604. https://doi.org/10.1037/0278-7393.4.6.592.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745.\n\n\nSweller, John. 2024. „Cognitive Load Theory and Individual Differences“. Learning and Individual Differences 110 (Februar): 102423. https://doi.org/10.1016/j.lindif.2024.102423.\n\n\nVanLEHN, KURT. 2011. „The Relative Effectiveness of Human Tutoring, Intelligent Tutoring Systems, and Other Tutoring Systems“. Educational Psychologist 46 (4): 197–221. https://doi.org/10.1080/00461520.2011.611369.\n\n\nWillingham, Daniel T. 2008. „Critical Thinking: Why Is It So Hard to Teach?“ Arts Education Policy Review 109 (4): 21–32. https://doi.org/10.3200/AEPR.109.4.21-32."
  },
  {
    "objectID": "presentation/index.html",
    "href": "presentation/index.html",
    "title": "Präsentation",
    "section": "",
    "text": "Zwei Versionen verfügbar:\n\n\n\nVersion\nDauer\nBeschreibung\n\n\n\n\nVollversion\n~3 Stunden\nWorkshop mit Diskussionen und Pausen\n\n\nKurzversion\n30 + 30 Min\nFokussierter Vortrag mit anschliessender Diskussion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTippNavigation\n\n\n\nNutze die Pfeiltasten oder klicke auf die Slides, um durch die Präsentation zu navigieren. Drücke F für Vollbild.",
    "crumbs": [
      "Präsentation"
    ]
  },
  {
    "objectID": "presentation/index.html#ki-in-der-hochschulbildung",
    "href": "presentation/index.html#ki-in-der-hochschulbildung",
    "title": "Präsentation",
    "section": "",
    "text": "Zwei Versionen verfügbar:\n\n\n\nVersion\nDauer\nBeschreibung\n\n\n\n\nVollversion\n~3 Stunden\nWorkshop mit Diskussionen und Pausen\n\n\nKurzversion\n30 + 30 Min\nFokussierter Vortrag mit anschliessender Diskussion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTippNavigation\n\n\n\nNutze die Pfeiltasten oder klicke auf die Slides, um durch die Präsentation zu navigieren. Drücke F für Vollbild.",
    "crumbs": [
      "Präsentation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KI in der Lehre: Refresher",
    "section": "",
    "text": "Diese Seite begleitet die Präsentation zum aktuellen Stand von KI in der Hochschulbildung.\n\n\n\nPräsentation: Aktueller Stand von KI in der Hochschulbildung\nQ & A: Fragen, Antworten und weiterführende Ressourcen"
  },
  {
    "objectID": "index.html#willkommen",
    "href": "index.html#willkommen",
    "title": "KI in der Lehre: Refresher",
    "section": "",
    "text": "Diese Seite begleitet die Präsentation zum aktuellen Stand von KI in der Hochschulbildung.\n\n\n\nPräsentation: Aktueller Stand von KI in der Hochschulbildung\nQ & A: Fragen, Antworten und weiterführende Ressourcen"
  },
  {
    "objectID": "index.html#kontakt",
    "href": "index.html#kontakt",
    "title": "KI in der Lehre: Refresher",
    "section": "Kontakt",
    "text": "Kontakt\nDr. Andrew Ellis ist Kognitionspsychologe und Wissenschaftlicher Mitarbeiter an der Virtuellen Akademie der Berner Fachhochschule."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-zentrale-frage",
    "href": "slides/ai-higher-ed-short/index.html#die-zentrale-frage",
    "title": "KI in der Hochschulbildung",
    "section": "Die zentrale Frage",
    "text": "Die zentrale Frage\n\n\nWas KI kann:\n\nAnwaltsprüfungen bestehen\nCode schreiben und debuggen\nKrankheiten diagnostizieren\nWissenschaftliche Texte verfassen\n\n\nWas wir beobachten:\n\n“48% mehr Aufgaben gelöst MIT KI, 17% schlechter OHNE KI”\n(Bastani u. a. 2024)\n\n\n\nDie Frage ist nicht ob KI hilft, sondern: Wann hilft sie, und wann schadet sie?"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-these",
    "href": "slides/ai-higher-ed-short/index.html#die-these",
    "title": "KI in der Hochschulbildung",
    "section": "Die These",
    "text": "Die These\n\n\n\n\n\n\nKernaussage\n\n\nKI-Werkzeuge sind für Experten gemacht.\nSie machen Experten produktiver.\nLernende profitieren oft nicht, weil Lernen die kognitive Anstrengung erfordert, die KI eliminiert."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#agenda",
    "href": "slides/ai-higher-ed-short/index.html#agenda",
    "title": "KI in der Hochschulbildung",
    "section": "Agenda",
    "text": "Agenda\n\nDas Produktivitäts-Lern-Paradox\nDie kognitionswissenschaftliche Erklärung\nWarum Experten profitieren, Lernende nicht\nDiskussion"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-bastani-studie",
    "href": "slides/ai-higher-ed-short/index.html#die-bastani-studie",
    "title": "KI in der Hochschulbildung",
    "section": "Die Bastani-Studie",
    "text": "Die Bastani-Studie\nRandomisierte kontrollierte Studie (Bastani u. a. 2024) (Einzelstudie)\n~1000 Gymnasiasten, GPT-4 Zugang während Mathe-Übungen\n\n\n\nMit KI:\n48% mehr Aufgaben korrekt gelöst (direkter Zugang)\n127% mit “GPT Tutor” (strukturierte Unterstützung)\n\nOhne KI (später):\n17% schlechter als Kontrollgruppe\nDie nie KI hatte\n\n\n\n\n“Students attempt to use GPT-4 as a ‘crutch’ during practice sessions, and when successful, perform worse on their own.”\n\nHinweis: Die Schlussfolgerungen gelten v.a. für KI als Antwortgeber, nicht als pädagogisch gestalteter Tutor."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#das-paradox-in-einem-satz",
    "href": "slides/ai-higher-ed-short/index.html#das-paradox-in-einem-satz",
    "title": "KI in der Hochschulbildung",
    "section": "Das Paradox in einem Satz",
    "text": "Das Paradox in einem Satz\n\n“Learning and task completion are not synonymous.”\n(joseCognitiveParadoxAI2025?)\n\n\nAufgabenleistung ≠ Lernen\nProduktivität ≠ Kompetenzaufbau"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#warum-anstrengung-nötig-ist",
    "href": "slides/ai-higher-ed-short/index.html#warum-anstrengung-nötig-ist",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Anstrengung nötig ist",
    "text": "Warum Anstrengung nötig ist\nRobert Bjork: Desirable Difficulties (Bjork und Bjork 2011)\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\n\nBewährte “erwünschte Schwierigkeiten”:\n\nSelbst generieren statt lesen\nVerteilt lernen statt crammen\nAbrufen statt wiederholen\nVariieren statt konstant üben"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#der-generierungseffekt",
    "href": "slides/ai-higher-ed-short/index.html#der-generierungseffekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Generierungseffekt",
    "text": "Der Generierungseffekt\nMeta-Analyse: d = 0.40 (slameckaGenerationEffect1978?)\n\n\nSelbst generiert:\nAktiviert breite neuronale Netzwerke\nBessere Langzeitspeicherung\n\nPassiv erhalten:\nGeringere Verarbeitung\nSchwächere Erinnerung\n\n\n\n\n\n\n\n\nImplikation\n\n\nWenn KI generiert, was Studierende selbst produzieren sollten, wird der Generierungseffekt eliminiert."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#historische-analogien",
    "href": "slides/ai-higher-ed-short/index.html#historische-analogien",
    "title": "KI in der Hochschulbildung",
    "section": "Historische Analogien",
    "text": "Historische Analogien\nGPS (Dahmani und Bohbot 2020): Längere Nutzung → steilerer Rückgang des räumlichen Gedächtnisses\n\nTaschenrechner (sieglerDevelopingConceptualUnderstanding2017?): Neutral für jene mit Fähigkeiten, schädlich für jene ohne\n\n\nGoogle-Effekt (Sparrow, Liu, und Wegner 2011): Geringere Erinnerung, wenn Information als verfügbar erwartet wird\n\n\nMuster: Werkzeuge, die Experten helfen, können Novizen schaden.\nAber: Diese Analogien sind begrenzt — KI ist breiter als GPS oder Taschenrechner."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#der-expertise-umkehr-effekt",
    "href": "slides/ai-higher-ed-short/index.html#der-expertise-umkehr-effekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Expertise-Umkehr-Effekt",
    "text": "Der Expertise-Umkehr-Effekt\nMeta-Analyse (Kalyuga 2009)\n\n\nGeringe Vorkenntnisse:\nProfitieren von hoher Unterstützung\nd = 0.505\n\nHohe Vorkenntnisse:\nProfitieren von niedriger Unterstützung\nd = −0.428\n\n\n\n\n\n\n\n\nKernaussage\n\n\nDasselbe Werkzeug kann gegenteilige Effekte haben, abhängig vom Expertisegrad."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#warum-experten-profitieren",
    "href": "slides/ai-higher-ed-short/index.html#warum-experten-profitieren",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Experten profitieren",
    "text": "Warum Experten profitieren\n\n\nExperten können:\n\nRoutine-Aufgaben sicher auslagern\nHöheres Denken aufrechterhalten\nKI-Outputs bewerten\nHaben Grundfähigkeiten, die nicht verkümmern\n\n\nLernenden fehlt:\n\nWissen zur Bewertung\nEtablierte Grundfähigkeiten\nMetakognitive Kontrolle\nRisiko: “Fliessende Inkompetenz”\n\n\n\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#kritisches-denken-braucht-fachwissen",
    "href": "slides/ai-higher-ed-short/index.html#kritisches-denken-braucht-fachwissen",
    "title": "KI in der Hochschulbildung",
    "section": "Kritisches Denken braucht Fachwissen",
    "text": "Kritisches Denken braucht Fachwissen\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n(Willingham 2008)\n\nWillinghams Formulierung ist zugespitzt — aber der Kern stimmt: Transfer ist schwieriger als oft angenommen.\n\n\n\nExperte in Biomedizin:\nErkennt, wenn ChatGPT bei Biochemie falsch liegt\n\nNovize:\nKann diese Bewertung nicht vornehmen, auch mit guten metakognitiven Strategien\n\n\n\nMetakognitive Strategien helfen — aber ihre Anwendung erfordert Fachwissen."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-unbequeme-wahrheit",
    "href": "slides/ai-higher-ed-short/index.html#die-unbequeme-wahrheit",
    "title": "KI in der Hochschulbildung",
    "section": "Die unbequeme Wahrheit",
    "text": "Die unbequeme Wahrheit\n\n\n\n\n\n\nKernaussage\n\n\nWas KI für Produktivität nützlich macht, macht sie für Lernen schädlich.\nSofortige Antworten eliminieren die Anstrengung, die Kompetenz aufbaut.\nDies folgt aus etablierten Prinzipien der Kognitionswissenschaft — wobei die direkte Evidenz für KI noch begrenzt ist."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#mind-extending-vs.-mind-replacing",
    "href": "slides/ai-higher-ed-short/index.html#mind-extending-vs.-mind-replacing",
    "title": "KI in der Hochschulbildung",
    "section": "Mind-extending vs. Mind-replacing",
    "text": "Mind-extending vs. Mind-replacing\nAndy Clark (Clark 2025)\n\n\nKognition erweitern:\n\nErhält kognitives Engagement\nLeitet Anstrengung um\nMensch bleibt in der Schleife\n\n\nKognition ersetzen:\n\nEliminiert Engagement\nErzeugt Abhängigkeit\nPassives Akzeptieren\n\n\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#offene-fragen",
    "href": "slides/ai-higher-ed-short/index.html#offene-fragen",
    "title": "KI in der Hochschulbildung",
    "section": "Offene Fragen",
    "text": "Offene Fragen\n\nScaffolding-Hypothese: Werden Grundfertigkeiten nur verlernt, oder entstehen höhere Fähigkeiten gar nicht erst?\nEntwicklungsfrage: Sind Lernende in sensiblen Entwicklungsphasen besonders gefährdet?\nDer stärkste Gegeneinwand: “Wenn KI immer verfügbar ist, brauchen wir diese Fähigkeiten nicht mehr.” — Aber wer erkennt dann Fehler? Wer erweitert Wissen?"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#abschliessende-provokationen",
    "href": "slides/ai-higher-ed-short/index.html#abschliessende-provokationen",
    "title": "KI in der Hochschulbildung",
    "section": "Abschliessende Provokationen",
    "text": "Abschliessende Provokationen\n\n“If AI assistance during education impairs independent capability, students may graduate less prepared for contexts where AI is unavailable.”\n\n\n\n“The productivity gains during education would come at the cost of capability thereafter.”\n\n\n\n\n“Whether this tradeoff is acceptable depends on assumptions about the future that educators cannot verify.”\n\n\n\n\n“Wenn wir uns bei den Risiken irren, haben wir die Einführung nützlicher Technologie etwas verlangsamt. Wenn sich die Kritiker bei der Sicherheit irren, haben wir möglicherweise die kognitive Entwicklung einer Generation beeinträchtigt.”"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#diskussion",
    "href": "slides/ai-higher-ed-short/index.html#diskussion",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion",
    "text": "Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nDiskussionsfragen\n\n\n\nFür dein Fach: Wo könnte KI-Nutzung die produktive Anstrengung eliminieren, die Lernen ermöglicht? Welche Grundfähigkeiten könnten verkümmern?\nFür deine Lehre: Ab welchem Punkt sollten Studierende KI nutzen dürfen? Wie bestimmst du, ob genug Grundwissen vorhanden ist?\nGrundsätzlich: Ist die Unterscheidung “Experten vs. Lernende” in deinem Kontext nützlich? Wo greift sie, wo nicht?"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#referenzen",
    "href": "slides/ai-higher-ed-short/index.html#referenzen",
    "title": "KI in der Hochschulbildung",
    "section": "Referenzen",
    "text": "Referenzen\n\n\nBastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, und Rei Mariman. 2024. „Generative AI Can Harm Learning“. SSRN Scholarly Paper. Rochester, NY. 15. Juli 2024. https://doi.org/10.2139/ssrn.4895486.\n\n\nBjork, Elizabeth Ligon, und Robert A. Bjork. 2011. „Making Things Hard on Yourself, but in a Good Way: Creating Desirable Difficulties to Enhance Learning“. In Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society, 56–64. New York, NY, US: Worth Publishers.\n\n\nClark, Andy. 2025. „Extending Minds with Generative AI“. Nature Communications 16 (1): 4627. https://doi.org/10.1038/s41467-025-59906-9.\n\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nKalyuga, Slava. 2009. „The Expertise Reversal Effect“. In Managing Cognitive Load in Adaptive Multimedia Learning, 58–80. IGI Global Scientific Publishing. https://doi.org/10.4018/978-1-60566-048-6.ch003.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745.\n\n\nWillingham, Daniel T. 2008. „Critical Thinking: Why Is It So Hard to Teach?“ Arts Education Policy Review 109 (4): 21–32. https://doi.org/10.3200/AEPR.109.4.21-32."
  },
  {
    "objectID": "qa/index.html",
    "href": "qa/index.html",
    "title": "Q & A",
    "section": "",
    "text": "Hier werden häufig gestellte Fragen und Antworten aus der Präsentation gesammelt.",
    "crumbs": [
      "Präsentation",
      "Q & A"
    ]
  },
  {
    "objectID": "qa/index.html#fragen-und-antworten",
    "href": "qa/index.html#fragen-und-antworten",
    "title": "Q & A",
    "section": "",
    "text": "Hier werden häufig gestellte Fragen und Antworten aus der Präsentation gesammelt.",
    "crumbs": [
      "Präsentation",
      "Q & A"
    ]
  },
  {
    "objectID": "qa/index.html#weiterführende-ressourcen",
    "href": "qa/index.html#weiterführende-ressourcen",
    "title": "Q & A",
    "section": "Weiterführende Ressourcen",
    "text": "Weiterführende Ressourcen\n\nLiteratur\n\nInhalt folgt\n\n\n\nLinks\n\nVirtuelle Akademie Knowledge Base",
    "crumbs": [
      "Präsentation",
      "Q & A"
    ]
  },
  {
    "objectID": "guide/index.html#footnotes",
    "href": "guide/index.html#footnotes",
    "title": "KI in der Hochschulbildung: Ein Leitfaden",
    "section": "Fußnoten",
    "text": "Fußnoten\n\n\nEigentlich “Next-Token-Prediction”, da sie eigentlich Wortteile oder Satzzeichen vorhersagen.↩︎\n“Halluzinieren” ist eigentlich kein guter Begriff; ein treffenderer Ausdruck wäre “Konfabulation”.↩︎\nDiese Dimension verdient mehr Aufmerksamkeit, als dieser Leitfaden ihr geben kann. Der Fokus auf Kognition ist eine bewusste Einschränkung.↩︎",
    "crumbs": [
      "Präsentation",
      "KI in der Hochschulbildung: Ein Leitfaden"
    ]
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#fazit-die-zentrale-botschaft",
    "href": "slides/ai-higher-ed/index.html#fazit-die-zentrale-botschaft",
    "title": "KI in der Hochschulbildung",
    "section": "Fazit: Die zentrale Botschaft",
    "text": "Fazit: Die zentrale Botschaft\n\nKI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende ohne durchdachte Integration oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.\n\n\nDie Argumentation stützt sich auf:\n\nCognitive Load Theory: Produktive Anstrengung durch das Nadelöhr des Arbeitsgedächtnisses\nExpertise-Umkehr-Effekt: Dieselbe Unterstützung kann Novizen helfen und Experten schaden\nDomänenspezifität: Kritische KI-Bewertung erfordert Fachwissen\nDesirable Difficulties: Schwierigkeiten optimieren oft Langzeitbehalten\nGenerierungseffekt: Selbst erzeugte Information wird besser behalten\n\n\n\nDie praktischen Implikationen: Grundlagen vor Werkzeugen | Prozess bewerten | Nach Vorwissen differenzieren | “Ohne-KI”-Phasen | Kritische KI-Nutzung im Fachkontext üben"
  }
]