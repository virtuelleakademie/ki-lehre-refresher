[
  {
    "objectID": "guide/index.html",
    "href": "guide/index.html",
    "title": "KI in der Hochschulbildung",
    "section": "",
    "text": "ChatGPT besteht Anwaltsprüfungen. Claude kann professionelle Programmierer erstezen. Gemini diagnostiziert Krankheiten. Als Hochschullehrende fragst du dich vermutlich: Wie integriere ich diese Werkzeuge sinnvoll in meine Lehre?\nDie Antwort ist komplizierter, als viele annehmen. Eine Studie in PNAS (Bastani u. a. 2025) zeigt ein beunruhigendes Muster: Rund 1000 Gymnasiasten mit GPT-4-Zugang lösten 48% mehr Mathematikaufgaben korrekt. Als der KI-Zugang später entfernt wurde, schnitten dieselben Schüler jedoch 17% schlechter ab als jene, die nie KI hatten.\nDas ist das Produktivitäts-Lern-Paradox: KI verbessert die Aufgabenleistung, kann aber das Lernen selbst beeinträchtigen. Die Frage ist nicht mehr ob KI hilft, sondern wann sie hilft und wann sie schadet.\nDieser Leitfaden bietet einen Rahmen, um diese Frage zu beantworten. Die zentrale These:\n\nKI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht. Ohne durchdachte Integration wird KI das Lernen eher beeinträchtigen als fördern.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Vor dem Weiterlesen\n\n\n\n\n\nBevor du diesen Leitfaden liest, reflektiere kurz:\n\nWo hast du Studierende beim KI-Einsatz beobachtet?\nWelche Auswirkungen auf das Lernen hast du vermutet?\nWelche Fragen stellst du dir bezüglich KI in deiner Lehre? Diese Reflexion hilft, die folgenden Konzepte auf den eigenen Kontext anzuwenden."
  },
  {
    "objectID": "guide/index.html#einleitung",
    "href": "guide/index.html#einleitung",
    "title": "KI in der Hochschulbildung",
    "section": "",
    "text": "ChatGPT besteht Anwaltsprüfungen. Claude kann professionelle Programmierer erstezen. Gemini diagnostiziert Krankheiten. Als Hochschullehrende fragst du dich vermutlich: Wie integriere ich diese Werkzeuge sinnvoll in meine Lehre?\nDie Antwort ist komplizierter, als viele annehmen. Eine Studie in PNAS (Bastani u. a. 2025) zeigt ein beunruhigendes Muster: Rund 1000 Gymnasiasten mit GPT-4-Zugang lösten 48% mehr Mathematikaufgaben korrekt. Als der KI-Zugang später entfernt wurde, schnitten dieselben Schüler jedoch 17% schlechter ab als jene, die nie KI hatten.\nDas ist das Produktivitäts-Lern-Paradox: KI verbessert die Aufgabenleistung, kann aber das Lernen selbst beeinträchtigen. Die Frage ist nicht mehr ob KI hilft, sondern wann sie hilft und wann sie schadet.\nDieser Leitfaden bietet einen Rahmen, um diese Frage zu beantworten. Die zentrale These:\n\nKI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht. Ohne durchdachte Integration wird KI das Lernen eher beeinträchtigen als fördern.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Vor dem Weiterlesen\n\n\n\n\n\nBevor du diesen Leitfaden liest, reflektiere kurz:\n\nWo hast du Studierende beim KI-Einsatz beobachtet?\nWelche Auswirkungen auf das Lernen hast du vermutet?\nWelche Fragen stellst du dir bezüglich KI in deiner Lehre? Diese Reflexion hilft, die folgenden Konzepte auf den eigenen Kontext anzuwenden."
  },
  {
    "objectID": "guide/index.html#was-ki-kann",
    "href": "guide/index.html#was-ki-kann",
    "title": "KI in der Hochschulbildung",
    "section": "Was KI heute kann",
    "text": "Was KI heute kann\n\nGrundlegende Funktionsweise\nBevor wir über Auswirkungen sprechen, lohnt sich ein Blick darauf, was diese Systeme eigentlich tun. Large Language Models (LLMs) wie GPT-5 oder Claude sind im Kern Next-Word-Prediction-Systeme1. Sie wurden auf Milliarden von Textdokumenten trainiert und haben dabei Muster in Sprache, Argumentation und Stil gelernt, aber auch sehr viel Wissen. Die beste Metapher: extrem ausgeklügelte Autovervollständigung.\nEntscheidend ist die Unterscheidung zwischen Retrieval und Generation:\n\nRetrieval (wie eine Suchmaschine): Information wird gefunden und zurückgegeben\nGeneration (wie ein LLM): Text wird neu erzeugt basierend auf statistischen Mustern\n\nLLMs rufen kein Wissen ab. Sie generieren Text, der plausibel klingt. Dies erklärt, warum sie “halluzinieren”2 können: Sie optimieren für sprachliche Plausibilität, nicht für faktische Korrektheit.\n\n\nChain-of-Thought Reasoning\nModerne LLMs können “denken”, indem sie ihre Überlegungen schrittweise externalisieren. Bei der Frage “Was ist 17 × 24?” kann ein LLM antworten:\n\n“Lass mich das aufteilen: 17 × 20 = 340, 17 × 4 = 68, 340 + 68 = 408”\n\nDieses Chain-of-Thought Reasoning verbessert die Leistung bei komplexen Aufgaben erheblich. Es ist jedoch immer noch Mustererkennung, nur über Denkschritte statt direkt über Antworten. Die KI hat gelernt, wie Menschen Probleme in Teilprobleme zerlegen.\n\n\nWerkzeugfähige Agenten\nDie neueste Entwicklung sind Agenten: LLMs, die mit externen Werkzeugen verbunden sind. Sie können:\n\nWebsuchen durchführen\nCode schreiben und ausführen\nDateien lesen und bearbeiten\nBerechnungen anstellen\nProgrammierschnittstellen (APIs) aufrufen\n\nDie Konsequenz: Agenten können eine grosse Menge an kognitiven Aufgaben ausführen, von Literaturrecherche über Datenanalyse bis zum Schreiben und Überarbeiten von Texten. Die Fähigkeitsgrenze verschiebt sich ständig.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: KI-Fähigkeiten aktuell halten\n\n\n\n\n\nDie Fähigkeiten von KI-Systemen entwickeln sich rasant. Empfehlungen:\n\nRegelmässig aktualisieren: Überprüfe regelmässig, was aktuelle Modelle können\nSelbst testen: Probiere neue Modelle mit Aufgaben aus deinem Fachgebiet\nSkeptisch bleiben: Marketing-Behauptungen übertreffen oft die tatsächliche Leistung\nGrenzen kennen: Identifiziere Aufgaben, bei denen KI zuverlässig versagt"
  },
  {
    "objectID": "guide/index.html#expertise",
    "href": "guide/index.html#expertise",
    "title": "KI in der Hochschulbildung",
    "section": "Wie Expertise entsteht",
    "text": "Wie Expertise entsteht\nWarum wirkt KI auf Experten und Lernende so unterschiedlich? Die Antwort ist darin zu finden, was Expertise eigentlich ist.\n\nExperten und Novizen sind grundlegend verschieden\nEin weit verbreitetes Missverständnis: Experten haben einfach “mehr Wissen”. Die Forschung zeigt etwas anderes. Experten haben eine qualitativ andere kognitive Architektur.\nDas klassische Beispiel stammt aus der Schachforschung (Groot und Groot 1978; Chase und Simon 1973). Schachmeistern und Anfängern wurden Stellungen für wenige Sekunden gezeigt. Bei echten Spielstellungen erinnerten Meister deutlich mehr Figuren korrekt als Anfänger. Bei zufällig platzierten Figuren waren beide Gruppen gleich schlecht.\nDie Interpretation: Meister sehen nicht einzelne Figuren, sondern Chunks, bedeutungsvolle Muster wie “Königsangriff” oder “offene Linie”. Diese Chunks sind im Langzeitgedächtnis gespeichert und werden automatisch erkannt.\nDas Prinzip gilt domänenübergreifend:\n\nÄrzte sehen Symptomkomplexe, nicht Einzelsymptome\nProgrammierer sehen Design Patterns, nicht Codezeilen\nHistoriker sehen Epochenmerkmale, nicht Einzeldaten\n\n\n\nVon schwachen zu starken Methoden\nWie lösen Menschen Probleme? Newell und Simon (Newell und Simon 1972) unterschieden in ihrer einflussreichen Arbeit zwischen “schwachen” und “starken” Methoden der Problemlösung. Anderson’s Theorie des Fertigkeitserwerbs (Anderson 1982) beschreibt dann den Mechanismus, wie der Übergang zwischen diesen Methoden mit wachsender Expertise stattfindet.\nNovizen nutzen schwache Methoden:\n\nMittel-Ziel-Analyse: “Wo bin ich? Wo will ich hin? Was bringt mich näher?”\nVersuch und Irrtum\nAnalogiebildung: “Das ist wie etwas, das ich schon kenne”\nRückwärtsarbeiten vom Ziel\n\nDiese Methoden heissen “schwach”, weil sie domänenunabhängig und allgemein anwendbar, aber langsam, fehleranfällig und kognitiv anstrengend sind.\nExperten nutzen starke Methoden:\n\nAutomatische Mustererkennung: “Das ist ein Fall von X”\nDirekte Lösungswege: “Bei X macht man Y”\nIntuition basierend auf tausenden Erfahrungen\n\nDer Übergang von schwachen zu starken Methoden erfordert umfangreiche Übung. Es gibt keine Abkürzung.\n\n\nProzeduralisierung: Vom Wissen zum Können\nDer Weg zur Expertise folgt typischen Phasen:\n\nDeklaratives Wissen: Wissen als Fakten (“Man muss beim Autofahren die Kupplung treten, bevor man schaltet”)\nBewusste Anwendung: Aktiv an jeden Schritt denken, langsam, fehleranfällig\nProzeduralisierung: Schritte werden zu Einheiten zusammengefasst (“Anfahren” statt drei separate Handlungen)\nAutomatisierung: Unbewusste, flüssige Ausführung\n\nAutomatisierte Prozesse belasten das Arbeitsgedächtnis nicht mehr. Sie sind schneller, zuverlässiger und setzen kognitive Ressourcen für höhere Aufgaben frei.\nEntscheidend ist: Diese Transformation kann nicht übersprungen werden. Man kann nicht direkt von deklarativem Wissen zu Automatisierung springen. Der Weg führt durch bewusste, anstrengende Übung.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Übungsphasen schützen\n\n\n\n\n\nWenn KI die “langweiligen” Übungsphasen übernimmt, findet keine Prozeduralisierung statt. Empfehlungen:\n\nGrundlagenphase KI-frei gestalten: Erste Begegnungen mit neuem Material ohne KI-Unterstützung\nÜbungszeit einplanen: Explizite Übungszeit, in der KI nicht erlaubt ist\nFortschritt monitoren: Regelmässig prüfen, ob Studierende Aufgaben auch ohne KI bewältigen\nSequenzierung beachten: Erst Grundlagen festigen, dann KI als Produktivitätswerkzeug einführen\n\nRealitätscheck: Vollständige Kontrolle über KI-Nutzung ist kaum möglich. Fokus auf Prozessbewertung und Reflexion kann wirksamer sein als strikte Verbote.\n\n\n\n\n\nCognitive Load Theory: Das Nadelöhr des Lernens\nWarum ist Übung so wichtig? Die Cognitive Load Theory (Sweller 2024) liefert die Antwort. Sie basiert auf zwei Gedächtnissystemen:\nArbeitsgedächtnis:\n\nKapazität: etwa \\(4 \\pm 1\\) Elemente gleichzeitig (wobei dies von der Definition eines “Elements” und der Aufgabenart abhängt)\nDauer: wenige Sekunden ohne aktive Aufrechterhaltung\nDer Flaschenhals allen Lernens\n\nLangzeitgedächtnis:\n\nPraktisch unbegrenzte Kapazität\nDauerhafte Speicherung\nHier lebt Expertise\n\nDie zentrale Erkenntnis: Alles Lernen muss durch den Flaschenhals des Arbeitsgedächtnisses. Wenn das Arbeitsgedächtnis überlastet ist, findet kein Lernen statt.\n\n\nDrei Arten kognitiver Belastung\nDie Cognitive Load Theory unterscheidet drei Arten der Belastung:\n\n\n\n\n\n\n\n\nTyp\nBeschreibung\nZiel\n\n\n\n\nIntrinsisch\nInhärente Komplexität des Materials\nKann nicht reduziert werden ohne Vereinfachung\n\n\nExtrinsisch\nSchlecht gestaltete Instruktion\nMinimieren\n\n\nLernförderlich (Germane)\nProduktive Anstrengung für Schemabildung\nErhalten\n\n\n\n(Anmerkung: Die Unterscheidung zwischen lernförderlicher und intrinsischer Belastung ist in der Literatur umstritten. Einige Forscher argumentieren, dass “germane load” keine eigenständige Kategorie darstellt, sondern die produktive Nutzung verfügbarer Kapazität beschreibt.)\nDie entscheidende Frage für KI: Welche Art der Belastung reduziert sie?\n\nKI kann extrinsische Belastung reduzieren (z.B. bessere Erklärungen) → gut\nKI kann lernförderliche Belastung eliminieren (z.B. Antworten statt selbst denken) → problematisch\n\nDas Ergebnis hängt vom Nutzungskontext ab.\n\n\nDer Expertise-Umkehr-Effekt\nEin Forschungsüberblick (Kalyuga 2009) zeigt einen bemerkenswerten Befund:\n\nGeringe Vorkenntnisse: Hohe Unterstützung hilft (mittlere bis grosse Effekte)\nHohe Vorkenntnisse: Hohe Unterstützung schadet (die Effekte kehren sich um)\n\nDas ist der Expertise-Umkehr-Effekt: Dieselbe Instruktionsmethode kann gegenteilige Effekte haben, abhängig vom Vorwissen der Lernenden.\nFür Novizen reduziert Unterstützung die extrinsische Belastung und lässt Raum für Lernen. Für Experten ist die Unterstützung redundant und erzeugt zusätzliche Verarbeitungslast (“Ich weiss das schon, aber muss es trotzdem durcharbeiten”).\nDie Implikation für KI: Dasselbe KI-Werkzeug kann für Experten produktiv und für Novizen schädlich sein, oder umgekehrt, je nach Nutzungsweise. Es gibt keine “One-size-fits-all”-Lösung.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Unterstützung anpassen\n\n\n\n\n\nDer Expertise-Umkehr-Effekt legt nahe, die KI-Nutzung an den Lernstand anzupassen:\n\nVorwissen erheben: Zu Beginn eines Kurses das Vorwissen einschätzen\nDifferenzieren: Unterschiedliche KI-Regeln für Anfänger und Fortgeschrittene\nFading einsetzen: Mit hoher Unterstützung beginnen, dann schrittweise reduzieren\nStudierende einbeziehen: Über den Effekt informieren, Selbstregulation fördern\n\n\n\n\n\n\nWas Instruktion leisten sollte: Explizite Instruktion\nBisher haben wir diskutiert, was KI für Lernen problematisch machen kann. Aber was sollte gute Instruktion tun? Die Forschung zu expliziter Instruktion (Kirschner, und and Clark 2006) liefert klare Antworten.\nDas Problem mit minimaler Anleitung: Konstruktivistische, entdeckende und problembasierte Ansätze klingen intuitiv attraktiv: Lernende sollen selbst entdecken, explorieren, Probleme lösen. Aber die empirische Evidenz zeigt konsistent: Für Novizen ist minimale Anleitung weniger effektiv als explizite Instruktion. Der Grund liegt in der kognitiven Architektur: Novizen haben keine Schemata im Langzeitgedächtnis, die sie zur Problemlösung nutzen könnten. Sie sind auf ihr begrenztes Arbeitsgedächtnis angewiesen, das schnell überlastet wird.\nWorked Examples: Eine der am besten belegten Instruktionsmethoden für Novizen sind Worked Examples (ausgearbeitete Beispiele). Statt Lernende Probleme selbst lösen zu lassen, zeigt man ihnen vollständig ausgearbeitete Lösungswege. Das klingt kontraintuitiv: Sollten Lernende nicht selbst denken? Die Forschung zeigt: Für Novizen reduzieren Worked Examples die extrinsische kognitive Belastung und lassen Kapazität für Schemabildung. Der Worked Example Effect (Cooper und Sweller 1987) ist einer der robustesten Befunde der Instruktionsforschung.\nDer Unterschied zu KI: Hier liegt ein entscheidender Punkt: Worked Examples sind nicht dasselbe wie KI-generierte Lösungen.\n\nWorked Examples sind didaktisch gestaltet, heben relevante Schritte hervor, bauen systematisch Komplexität auf und werden von Lehrenden ausgewählt, um bestimmte Prinzipien zu illustrieren\nKI-generierte Antworten, in der typischen Nutzung durch Studierende, beantworten die gestellte Frage. Sie erfolgen jedoch ohne Einbettung in eine geplante Lernprogression. LLMs können mit entsprechendem Prompting didaktisch strukturierte Erklärungen liefern, aber das erfordert pädagogisches Wissen, das Novizen typischerweise nicht haben.\n\nDer Unterschied liegt in der Einbettung: Worked Examples sind Teil eines durchdachten Instruktionsdesigns, das von Lehrenden mit Blick auf die Lernziele und den Wissensstand der Lernenden gestaltet wurde. KI-Antworten in der studentischen Alltagsnutzung fehlt dieser Kontext.\nCompletion Problems: Ein Mittelweg sind Completion Problems: Teilweise ausgearbeitete Lösungen, die Lernende vervollständigen müssen. Sie bieten Struktur, fordern aber aktive kognitive Verarbeitung. Mit wachsender Expertise können die vorgefertigten Teile reduziert werden (Fading), bis Lernende Probleme vollständig selbst lösen.\nDie Verbindung zum Expertise-Umkehr-Effekt: Explizite Instruktion und Worked Examples helfen Novizen, können aber Experten behindern (Expertise-Umkehr-Effekt). Daher ist Fading zentral: Unterstützung wird systematisch reduziert, wenn Expertise wächst. Das ist genau die dynamische Anpassung, die der Expertise-Umkehr-Effekt nahelegt.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Explizite Instruktion einsetzen\n\n\n\n\n\nEvidenzbasierte Instruktion für Novizen:\n\nWorked Examples nutzen: Ausgearbeitete Beispiele zeigen, bevor Lernende selbst lösen\nCompletion Problems einsetzen: Teilweise gelöste Aufgaben, die vervollständigt werden müssen\nFading planen: Mit viel Unterstützung beginnen, systematisch reduzieren\nDidaktische Sequenzierung: Nicht jede Lösung zeigen, sondern gezielt ausgewählte Beispiele\nKI nicht mit Worked Examples verwechseln: KI-Antworten ersetzen keine didaktisch gestaltete Instruktion\n\nDer Kernpunkt: Novizen brauchen Unterstützung, aber die richtige Art von Unterstützung. Explizite Instruktion reduziert extrinsische Belastung, während produktive kognitive Arbeit erhalten bleibt. KI-Nutzung kann beides tun: extrinsische Belastung reduzieren (gut) oder die produktive Arbeit selbst übernehmen (problematisch)."
  },
  {
    "objectID": "guide/index.html#kritisches-denken",
    "href": "guide/index.html#kritisches-denken",
    "title": "KI in der Hochschulbildung",
    "section": "Kritisches Denken erfordert Fachwissen",
    "text": "Kritisches Denken erfordert Fachwissen\nStudierende sollen lernen, KI kritisch zu nutzen. Das klingt vernünftig, greift aber zu kurz.\n\nDie traditionelle Annahme\nOft wird angenommen, kritisches Denken sei eine allgemeine, übertragbare Fähigkeit: einmal erworben, überall anwendbar.\nAuf KI übertragen hiesse das: Man könnte Studierenden “KI-Kompetenz” beibringen, also die Fähigkeit, KI-Outputs kritisch zu bewerten, unabhängig vom Fachgebiet.\nAber stimmt diese Annahme?\n\n\nWillinghams Herausforderung\nDaniel Willingham (Willingham 2008) fasst die Forschung provokant zusammen:\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n\nDas ist zugespitzt formuliert, aber der Kern stimmt: Transfer ist schwieriger als oft angenommen.\n\n\nEvidenz für Domänenspezifität\nDie Forschung zeigt wiederholt, dass Expertise nicht transferiert:\n\nNeurologen können Herzerkrankungen nicht gut diagnostizieren, obwohl sie medizinisch ausgebildet sind\nFachredakteure können keine Zeitungsartikel schreiben, obwohl sie Texte redigieren können\nSelbst trainierte Philosophen werden von irrelevanten Merkmalen beeinflusst, wenn das Thema ausserhalb ihrer Expertise liegt\n\nWillingham formuliert es so:\n\n“Abstract principles like ‘look for hidden assumptions’ won’t help much in evaluating an argument about a topic you know little about.”\n\n\n\nAngewendet auf KI-Bewertung\nWas bedeutet das für die kritische Bewertung von KI-Outputs?\nEine Expertin in Biomedizin kann erkennen, wenn ChatGPT bei Biochemie falsch liegt. Sie hat die mentalen Modelle des Fachgebiets, kann “Das klingt falsch” erkennen, weiss welche Quellen zur Verifizierung dienen, und kann Plausibilität einschätzen.\nEine Novizin kann diese Bewertung nicht vornehmen, unabhängig von ihren “kritischen Denkfähigkeiten”. Ihr fehlen die Referenzrahmen. Sie kann nicht unterscheiden zwischen plausibel und korrekt. Sie weiss nicht, welche Quellen autoritativ sind.\nWas wie “kritisches Denken” aussieht, ist oft domänen-spezifisches Wissen.\n\n\nWas transferiert, und was nicht\nEine nuanciertere Betrachtung unterscheidet:\nTransferiert teilweise:\n\nPlanung des Vorgehens\nÜberwachung des eigenen Verständnisses\nSelbstregulation\nBereitschaft, Annahmen zu hinterfragen\n\nDiese metakognitiven Strategien zeigen in der Forschung gewisse Generalisierung. Man kann sie domänenübergreifend lehren, und sie haben etwas Transferwirkung.\nTransferiert kaum:\n\nWissen, was in einem Fachgebiet plausibel ist\nWissen, welche Quellen autoritativ sind\nErkennen von fachspezifischen Fehlern\n\nDiese inhaltliche Bewertungsfähigkeit erfordert Domänenwissen und transferiert kaum.\nDer Kernpunkt: Die Strategien kann man lehren, aber ihre Anwendung erfordert Fachwissen. Die Strategie “Hinterfrage Annahmen” kann man lehren. Aber um zu wissen, welche Annahmen in einem biochemischen Text fragwürdig sind, braucht man Biochemie-Wissen.\n\n\nDie zentrale Implikation\nDaraus folgen drei wichtige Erkenntnisse:\n\nStudierende, die “mit hohem kritischem Denken” von KI profitieren, haben wahrscheinlich mehr Domänenexpertise. Studien, die zeigen, dass “kritische Denker” von KI profitieren, messen möglicherweise Vorwissen, nicht eine generische Fähigkeit.\nDie beste Vorbereitung für kritische KI-Nutzung ist tiefes Fachlernen. Kontraintuitiv: Nicht “KI-Training”, sondern Fachausbildung. Expertise ermöglicht kritische Nutzung; ohne Expertise ist Kritik kaum möglich.\nGenerische “KI-Kompetenz” kann Fachwissen ergänzen, aber nicht ersetzen. Workshops zu “Prompt Engineering” lösen das fundamentale Problem nicht. Die Fähigkeit, einen guten Prompt zu schreiben, ersetzt nicht die Fähigkeit, die Antwort zu bewerten.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Fach-spezifisches Lernen priorisieren\n\n\n\n\n\nAnstatt nur “KI-Kompetenz” zu lehren:\n\nFachliche Grundlagen stärken: Mehr Zeit für Grundlagenwissen, nicht weniger\nDomänenspezifische KI-Kritik üben: Im Fachkontext KI-Outputs gemeinsam analysieren\nFehler sammeln: Eine Sammlung typischer KI-Fehler im eigenen Fachgebiet anlegen\nMetakognition fördern: Studierende lehren, ihr eigenes Verständnis zu überwachen\nRealistische Erwartungen setzen: KI-Kritik erfordert Fachwissen, das Zeit braucht"
  },
  {
    "objectID": "guide/index.html#paradox",
    "href": "guide/index.html#paradox",
    "title": "KI in der Hochschulbildung",
    "section": "Das Produktivitäts-Lern-Paradox",
    "text": "Das Produktivitäts-Lern-Paradox\nDie zentrale Frage lautet: Warum kann KI die Aufgabenleistung verbessern und gleichzeitig das Lernen beeinträchtigen?\n\nDie zentrale Unterscheidung\n\n“Learning and task completion are not synonymous.” (Jose u. a. 2025)\n\nDiese Unterscheidung ist entscheidend:\n\nAufgabenleistung (Performance): Wie gut man eine Aufgabe jetzt löst\nLernen (Learning): Die Fähigkeit, ähnliche Aufgaben später unabhängig zu lösen\n\nKI verbessert Aufgabenleistung (eindeutig belegt). Aber das sagt nichts über Lernen. Lernen erfordert möglicherweise genau die Anstrengung, die KI eliminiert.\n\n\nDie Bastani-Studie im Detail\nSchauen wir uns die eingangs erwähnte Studie (Bastani u. a. 2025) genauer an:\nDesign:\n\nRund 1000 türkische Gymnasiasten\nRandomisierte Zuweisung zu drei Gruppen\nMathe-Übungen über mehrere Wochen\nTest am Ende ohne KI-Zugang\n\nDie Bedingungen:\n\nKontrollgruppe: Kein KI-Zugang\nDirekter GPT-4-Zugang: Freie Nutzung\nGPT Tutor: Strukturierte Nutzung mit pädagogischen Leitplanken\n\nDie Ergebnisse:\n\nMit direktem GPT-4: 48% mehr Aufgaben gelöst\nMit GPT Tutor: 127% mehr Aufgaben gelöst\nOhne KI (später): 17% schlechter als Kontrollgruppe\n\nDie Autoren fassen zusammen:\n\n“Students attempt to use GPT-4 as a ‘crutch’ during practice sessions, and when successful, perform worse on their own.”\n\nWichtige Nuance: Die negativen Effekte betrafen primär den direkten Zugang. Der “GPT Tutor” zeigte bessere Ergebnisse, aber selbst mit Tutor war die spätere Leistung ohne KI reduziert. Die Art der KI-Nutzung macht einen Unterschied.\nEinschränkungen: Die Studie hat methodische Limitationen: Der Kontext (türkische Gymnasiasten, Mathematik) ist spezifisch, die Effekte sind kurzfristig gemessen, und Replikationen stehen aus. Allerdings: Die Kernaussage, dass Aufgabenleistung und Lernen auseinanderfallen können, ist keine Überraschung. Sie folgt direkt aus der Cognitive Load Theory und den Prinzipien erwünschter Schwierigkeiten. Die Studie liefert empirische Evidenz für die Vorhersagen der Theorie.\n\n\nDesirable Difficulties: Warum Anstrengung nötig ist\nRobert Bjork (Bjork und Bjork 2011) hat das Konzept der “erwünschten Schwierigkeiten” geprägt:\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\nVier bewährte Interventionen illustrieren das Prinzip:\n\nVariation: Lernen unter wechselnden Bedingungen\nInterleaving: Aufgabentypen mischen statt blocken\nSpacing: Verteilt lernen statt massiert\nRetrieval Practice: Aktiv abrufen statt passiv wiederlesen (Roediger und Karpicke 2006)\n\nAlle vier haben gemeinsam: Sie fühlen sich schwerer an, sind aber effektiver für langfristiges Lernen.\nDer Mechanismus: Sofortiger KI-Zugang kann Abrufversuche kurzschliessen. Statt selbst nachzudenken (“Was weiss ich darüber?”), fragt man die KI. Die Gedächtnisspur wird nicht gestärkt.\n\n\nDer Generierungseffekt\nDer Generierungseffekt ist ein robuster Befund: Selbst generierte Information wird besser behalten als passiv erhaltene. Slamecka und Graf (1978) demonstrierten dies erstmals experimentell, spätere Meta-Analysen bestätigten moderate Effektstärken.\nDas typische Experiment:\n\nGruppe A: Liest Wortpaare (Heiss—Kalt)\nGruppe B: Ergänzt Wortpaare (Heiss—K___)\nTest: Beide Gruppen werden abgefragt\nErgebnis: Gruppe B erinnert besser\n\nWarum funktioniert es?\n\nAktivere Verarbeitung während des Generierens\nMehr Verbindungen im Gedächtnis\nTiefere Enkodierung\n\nDie Implikation: Wenn KI generiert, was Studierende selbst produzieren sollten, wird der Generierungseffekt eliminiert. Studierende, die selbst einen Essay-Entwurf schreiben, profitieren vom Generierungseffekt. Studierende, die einen KI-generierten Entwurf bearbeiten, nicht, auch wenn das Endprodukt ähnlich aussieht.\n\n\nDie Scaffolding-Hypothese\nEine tiefere Frage drängt sich auf: Was passiert mit der Entwicklung kognitiver Fähigkeiten? Hier müssen wir sorgfältig zwischen dem unterscheiden, was wir wissen, was wir theoretisch ableiten, und was wir vermuten.\nWas wir wissen (Evidenz): Atrophie von Fähigkeiten ist gut dokumentiert. Eine vorhandene Fähigkeit verkümmert durch Nichtgebrauch. Das ist reversibel: Wenn man wieder übt, kommt die Fähigkeit zurück. Der Generierungseffekt und die Prinzipien erwünschter Schwierigkeiten sind empirisch belegt.\nWas wir theoretisch ableiten: Wenn KI die kognitiven Prozesse übernimmt, die für Lernen notwendig sind, sollte weniger Lernen stattfinden. Das folgt aus der Cognitive Load Theory und ist durch Studien wie Bastani gestützt.\nWas wir vermuten (Hypothese): Es könnte einen Unterschied geben zwischen Fertigkeitsatrophie und Entwicklungsbeeinträchtigung. Eine Fähigkeit, die nie entsteht, weil der konstruktive Prozess übersprungen wird, könnte schwerer nachzuholen sein als eine verkümmerte Fähigkeit. Die Hypothese: Grundfertigkeiten wie Schreiben, Rechnen und analytisches Lesen sind nicht nur Fertigkeiten, sondern Prozesse, die kognitive Architektur aufbauen. Schreiben könnte ein “epistemisches Werkzeug” sein: Gedanken entwickeln sich durch das Schreiben, nicht vor dem Schreiben.\nVorsicht: Diese Hypothese ist plausibel, aber nicht empirisch belegt. Wir haben keine Längsschnittstudien, die zeigen, dass übersprungene kognitive Entwicklungsphasen irreversible Defizite verursachen. Die Bedenken verdienen Aufmerksamkeit, sollten aber nicht als gesicherte Fakten behandelt werden.\n\n\nHistorische Analogien\nFrühere Technologien zeigen ähnliche Muster:\nGPS und räumliches Gedächtnis (Dahmani und Bohbot 2020): Eine longitudinale Studie über drei Jahre zeigte: Stärkere GPS-Nutzung korreliert mit steilerem Rückgang des räumlichen Gedächtnisses. Die zeitliche Abfolge ist konsistent mit der Interpretation, dass GPS-Nutzung zum Rückgang beiträgt, wobei ungemessene konfundierende Variablen nicht ausgeschlossen werden können.\nKonzeptuelles Verständnis (Lortie-Forgues und Siegler 2017): Forschung zeigt, dass selbst Erwachsene mit Zugang zu Rechenhilfen oft überraschende Lücken im konzeptuellen Verständnis mathematischer Operationen aufweisen. Werkzeugnutzung ersetzt kein Grundverständnis. Dieselbe Parallele wie bei KI: Das Werkzeug kann prozedurale Aufgaben übernehmen, aber konzeptuelles Verständnis muss eigenständig aufgebaut werden.\nGoogle-Effekt (Sparrow, Liu, und Wegner 2011): Menschen erinnern Information schlechter, wenn sie erwarten, dass sie verfügbar bleibt. Sie erinnern stattdessen, wo die Information zu finden ist. Das Gedächtnis adaptiert sich an die Verfügbarkeit externer Speicher.\n\n\nGrenzen der Analogien\nDie historischen Analogien sind suggestiv, aber nicht ausreichend:\n\nGPS betrifft räumliche Navigation\nTaschenrechner betreffen arithmetische Berechnungen\nGoogle betrifft Informationsabruf\n\nJede dieser Technologien betrifft eine spezifische, enge kognitive Funktion.\nGenerative KI kann fast jede kognitive Aufgabe übernehmen: Schreiben, Argumentieren, Analysieren, Synthetisieren, Bewerten. Die Breite ist beispiellos. Wir können nicht einfach extrapolieren.\nAber: Die historischen Bedenken hatten oft Berechtigung. GPS beeinflusst tatsächlich räumliche Kognition. Taschenrechner veränderten den Mathematikunterricht. Die Bedenken waren nicht blosse Panikmache.\n\n\nDer EdTech-Hype-Zyklus\nBildungstechnologien folgen einem wiederkehrenden Muster (Reich 2020): Überschwängliche Versprechen, gefolgt von bescheidener Adoption, die bestehende Praktiken eher ergänzt als ersetzt.\n\nRadio sollte die besten Vorlesungen in jedes Klassenzimmer bringen\nFernsehen sollte Lernen revolutionieren\nComputer sollten Unterricht personalisieren\nMOOCs sollten Elite-Bildung demokratisieren\n\nJede Technologie fand eine Nische, aber keine erfüllte die transformativen Versprechen.\nDas MOOC-Beispiel ist besonders lehrreich: MOOCs versprachen Demokratisierung, erreichten aber primär Lernende, die bereits Abschlüsse hatten und berufliche Weiterbildung suchten. Der Erfolg erforderte genau die Selbstregulation und das Vorwissen, das privilegierte Lernende bereits besassen. Die “Demokratisierung” verstärkte bestehende Ungleichheiten.\nWas macht dieses Mal anders? KIs Breite ist beispiellos. Aber dieselben strukturellen Kräfte könnten wirken: die Komplexität des Lehrens, die Einpassung neuer Werkzeuge in bestehende Praktiken, die Kluft zwischen Pilotprojekten und flächendeckender Umsetzung.\n\n\n“Das haben sie über das Schreiben auch gesagt”\nEin häufiger Einwand lautet: Sokrates warnte vor der Schrift, und wir haben überlebt. Jede neue Technologie löst Panik aus.\nIm Phaidros warnte Sokrates: Schrift wird das Gedächtnis schwächen und nur “Scheinwissen” erzeugen.\nDrei Antworten:\n\nSchrift hat Kognition tiefgreifend verändert. Wir denken anders als orale Kulturen. Abstraktion, Kategorisierung, lineare Argumentation wurden durch Schrift gefördert. Das war nicht nur positiv oder negativ, es war transformativ.\nEinige Bedenken waren berechtigt. Mündliche Gedächtnistraditionen sind zurückgegangen. Homers Epen wurden über Generationen mündlich überliefert. Diese Fähigkeit ist weitgehend verloren.\nSchriftkultur entwickelte sich über Jahrhunderte. Es gab Zeit für kulturelle Anpassung. Bildungssysteme entwickelten sich mit. KI-Integration geschieht in Jahren, nicht Jahrhunderten.\n\n\n\nWarum Experten profitieren, Lernende nicht\nJetzt können wir versuchen, das Muster zu erklären:\nExperten können:\n\nRoutine-Aufgaben sicher auslagern (sie wissen, was “Routine” ist)\nHöheres Denken aufrechterhalten (kognitive Kapazität wird frei)\nKI-Outputs bewerten (sie haben Domänenexpertise)\nIhre Grundfähigkeiten verkümmern nicht (sie sind schon da)\n\nLernenden fehlt:\n\nWissen zur Bewertung (sie können nicht einschätzen, ob KI richtig liegt)\nEtablierte Grundfähigkeiten (was nicht da ist, kann nicht verkümmern, entsteht aber auch nicht)\nMetakognitive Kontrolle (sie wissen nicht, wann KI-Nutzung schadet)\n\nDas Ergebnis kann “fliessende Inkompetenz” sein: Anspruchsvoll wirkende Outputs ohne zugrundeliegendes Verständnis. Das KI-generierte Produkt sieht kompetent aus, das Wissen fehlt.\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Lernsituationen gestalten\n\n\n\n\n\nUm produktive Anstrengung zu erhalten:\n\n“Ohne-KI”-Phasen einplanen: Explizite Zeiten, in denen KI nicht erlaubt ist\nProzess bewerten, nicht nur Produkt: Zwischenschritte einfordern und bewerten\nRetrieval Practice integrieren: Regelmässige Abrufübungen ohne Hilfsmittel\nSpacing und Interleaving nutzen: Verteiltes, gemischtes Üben\nGenerierung fordern: Eigene Entwürfe vor KI-Unterstützung verlangen\nReflexion einbauen: Studierende über ihren Lernprozess nachdenken lassen\n\nRealitätscheck: Diese Empfehlungen erfordern Zeit und Planung. Nicht jede Lehrveranstaltung kann alles umsetzen. Beginne mit einem oder zwei Punkten, die zu deinem Kontext passen."
  },
  {
    "objectID": "guide/index.html#sokrates",
    "href": "guide/index.html#sokrates",
    "title": "KI in der Hochschulbildung",
    "section": "Exkurs: Sokratisches Fragen in KI-Tutoren",
    "text": "Exkurs: Sokratisches Fragen in KI-Tutoren\nEin konkretes Beispiel für den Hype-Evidenz-Gap: Viele EdTech-Unternehmen bewerben ihre KI-Tutoren mit “sokratischer Methode”.\n\n\n\n\n\n\nPro-tipWas “sokratisch” eigentlich bedeutet\n\n\n\n\n\nDie ursprüngliche sokratische Methode, wie sie in Platons Dialogen beschrieben wird, war kein sanftes Hinführen zu richtigen Antworten. Sokrates stellte bohrende Fragen, die vermeintliches Wissen als unbegründet entlarvten. Das Ziel war Aporie: die Erkenntnis, dass man weniger weiss, als man dachte. Diese Erfahrung war oft unangenehm.\nWas EdTech-Unternehmen “sokratisch” nennen, ist etwas anderes: ein System, das durch Fragen zur richtigen Antwort führt, statt sie direkt zu geben. Das ist eher geleitetes Entdecken als sokratischer Dialog. Die Bezeichnung klingt gut, aber der Vergleich hinkt.\n\n\n\n\nDas Versprechen\nDie Argumentation ist verlockend:\n\nBlooms “Two Sigma Problem” (BLOOM 1984): 1:1-Tutoring erzielt 2 Standardabweichungen Verbesserung\nDas würde einen durchschnittlichen Studierenden in die Top 2% bringen\nKI kann unbegrenzt viele Lernende betreuen\nAlso: Demokratisierung personalisierter Bildung\n\nAber: Die Begeisterung übersteigt die Evidenz erheblich.\n\n\nWarum Fragen theoretisch helfen könnten\nDie kognitionswissenschaftliche Grundlage ist solide:\nGenerierungseffekt: Selbst erzeugte Antworten werden besser behalten als passiv erhaltene (Slamecka und Graf 1978).\nSelbsterklärungseffekt: Erklären fördert tiefere Verarbeitung und deckt Wissenslücken auf (Chi u. a. 1994).\nAber: Die Qualität der Selbsterklärungen und damit der Lerneffekt hängt vom Vorwissen ab. Das verknüpft mit dem Expertise-Umkehr-Effekt: Was für Fortgeschrittene funktioniert, kann Novizen überfordern.\n\n\nWas die Evidenz tatsächlich zeigt\nVanLehn (2011) führte eine Meta-Analyse zur Effektivität verschiedener Tutoring-Formen durch:\n\nMenschliche Tutoren: d = 0.79 (nicht 2.0 wie Bloom behauptete)\nIntelligente Tutorsysteme: d = 0.76 (vergleichbar)\n\nVanLehns Analyse legt nahe, dass Schritt-für-Schritt-Feedback ein wesentlicher Faktor war, wobei die genaue Rolle des sokratischen Dialogs schwer zu isolieren ist.\nZu LLM-basierten sokratischen Tutoren: Es gibt keine gut kontrollierten randomisierten Studien. Die existierende Evidenz besteht hauptsächlich aus Zufriedenheitsumfragen und Vergleichen mit “kein Tutoring” statt mit Alternativen (siehe auch Weidlich u. a. (2025)).\n\n\nDas Diagnose-Problem\nEffektives sokratisches Fragen erfordert:\n\nGenaue Einschätzung des aktuellen Wissensstands\nUnterscheidung verschiedener Fehlertypen\nAnpassung der Fragen an den individuellen Lernenden\n\nBeispiel: Wenn ein Schüler antwortet \\(\\frac{1}{2} + \\frac{1}{3} = \\frac{2}{5}\\), kann das bedeuten:\n\nProzeduraler Fehler (Zähler und Nenner addiert)\nKonzeptueller Fehler (versteht nicht, was Brüche repräsentieren)\nFlüchtigkeitsfehler (weiss es eigentlich)\n\nDie angemessene sokratische Frage unterscheidet sich je nach Ursache. Menschliche Tutoren nutzen Mimik, Tonfall, Zögern und jahrelange Erfahrung zur Diagnose. KI-Systeme haben nur den Text und können diese Unterscheidung nicht zuverlässig treffen.\n\n\nWeitere Herausforderungen\nFragesequenzierung: Sokratischer Dialog ist kontingent. Jede Frage hängt von der vorherigen Antwort ab. Einfache LLM-Implementierungen generieren Token für Token ohne expliziten pädagogischen Plan, obwohl Multi-Agent-Systeme oder strukturierte Prompting-Ansätze dies teilweise adressieren können.\nFeedback-Timing: Wann korrigieren, wann weiter fragen lassen? Zu früh verhindert eigenes Denken, zu spät frustriert und verfestigt Fehler. Die Balance hängt vom individuellen Lernenden ab.\nLLM-Sycophancy: LLMs sind darauf trainiert, hilfreich und angenehm zu sein. Sie tendieren dazu, Nutzern zuzustimmen. Das ist das Gegenteil von produktivem sokratischem Unbehagen. Sokrates machte seine Gesprächspartner unbequem. Das war der Punkt.\n\n\nFazit zum sokratischen KI-Tutoring\nDie ehrliche Antwort ist: Wir wissen es noch nicht.\nWas plausibel ist: Selbsterklärung und Generierung fördern Lernen. Fragen können diese Prozesse anregen.\nWas nicht belegt ist: Dass aktuelle KI-Systeme die nötige Diagnose leisten können. Dass LLM-basierte sokratische Tutoren besser sind als Alternativen. Dass positive Effekte langfristig halten.\nSokrates würde es schätzen: Die beste Art, Werkzeuge zu bewerten, die seine Methode beanspruchen, ist, kritische Fragen zu stellen und unbegründete Antworten nicht zu akzeptieren.\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: KI-Tutoren evaluieren\n\n\n\n\n\nBei der Evaluation von KI-Tutoring-Tools:\n\nEvidenz verlangen: Peer-Review-Studien mit Learning Outcomes, nicht nur Zufriedenheit\nDiagnose-Fähigkeit prüfen: Kann das System zwischen Fehlertypen unterscheiden?\nOpportunitätskosten bedenken: Ist KI-Tutoring besser als Lehrbuch, Übungsaufgaben, Peer-Diskussion?\nMit strukturierten Domänen beginnen: Mathematik vor Literaturanalyse\nAuf unbeabsichtigte Folgen achten: Strategisches Ausnutzen des Systems statt echtem Lernen, Abhängigkeit von der KI-Unterstützung\nPilotieren und messen: Kleine Versuche mit klaren Erfolgskriterien"
  },
  {
    "objectID": "guide/index.html#implikationen",
    "href": "guide/index.html#implikationen",
    "title": "KI in der Hochschulbildung",
    "section": "Implikationen und offene Fragen",
    "text": "Implikationen und offene Fragen\n\nDie unbequeme Wahrheit\nWas bedeutet das alles? Die zentrale These lässt sich nun präzisieren:\n\nWas KI für Produktivität nützlich macht, droht sie für Lernen schädlich zu machen: Sofortige Antworten können die Anstrengung eliminieren, die Kompetenz aufbaut.\n\nDies ist kein Mangel aktueller KI. Es folgt aus etablierten Prinzipien der Kognitionswissenschaft. Das Problem liegt in der Natur des Lernens selbst. Die Frage ist daher nicht ob, sondern wie KI eingesetzt wird.\nEinschränkung: Es gibt noch wenige Studien, die direkt messen, wie KI-Nutzung Lernen über längere Zeit beeinflusst. Die theoretische Argumentation basiert auf etablierten kognitionswissenschaftlichen Prinzipien, aber empirische Langzeitstudien zu generativer KI fehlen noch.\n\n\nKognition erweitern vs. ersetzen\nAndy Clark (Clark 2025) bietet eine praktische Unterscheidung bei der Bewertung von KI-Nutzung:\nKognition erweitern:\n\nDer Mensch bleibt kognitiv engagiert\nWerkzeug verstärkt, ersetzt nicht\nBeispiel: Taschenrechner für einen Mathematiker\nFähigkeiten bleiben erhalten und werden ausgebaut\n\nKognition ersetzen:\n\nDer Mensch wird passiv\nWerkzeug übernimmt das Denken\nBeispiel: KI schreibt den Essay, Studierender submittet\nAbhängigkeit entsteht, Fähigkeiten verkümmern\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung. Die Frage ist nicht “KI ja oder nein?”, sondern “Wie wird KI genutzt?”\nAus Sicht der Cognitive Load Theory ist dabei entscheidend: Wissen, das im Langzeitgedächtnis gespeichert ist, unterscheidet sich fundamental von Wissen, auf das man extern zugreifen kann. Internalisiertes Wissen ermöglicht automatische Mustererkennung, befreit das Arbeitsgedächtnis und erlaubt höheres Denken. Externer Zugang erfordert immer bewusste Abrufprozesse und belastet das Arbeitsgedächtnis.\n\n\nDie Sequenzierungsfrage\nWas bedeutet das praktisch? Die Forschung legt nahe:\n\nStudierende brauchen wahrscheinlich Grundwissen, bevor KI vorteilhaft wird\nDer Expertise-Umkehr-Effekt empfiehlt dynamische KI-Nutzungsregeln\nDie Schwelle, ab der KI von schädlich zu hilfreich wechselt, ist unbekannt\nDie Antwort ist vermutlich domänen- und personenspezifisch\n\nPauschale Empfehlungen zu geben ist schwierig. Die Forschung liefert Prinzipien, aber deren Anwendung erfordert kontextspezifisches Urteilsvermögen und ist abhängig vom Fach, vom Vorwissen und den Lernzielen.\n\n\nDie Entwicklungsfrage\nEin besonderes Anliegen betrifft die kognitive Entwicklung:\n\nDer präfrontale Kortex entwickelt sich bis etwa Mitte 20, wobei verschiedene Funktionen unterschiedlich schnell reifen und individuelle Variation erheblich ist\nExekutive Funktionen, Metakognition, Selbstregulation sind bei vielen Studierenden noch in Entwicklung\nJene, die KI-Nutzung am wenigsten regulieren können, sind möglicherweise am verletzlichsten\n\nDie aktuelle Studierendengeneration könnte die erste sein, die ihre gesamte Bildungslaufbahn mit generativer KI durchläuft. Wenn wir in 20 Jahren Langzeitdaten haben, wird eine Generation bereits das Experiment gewesen sein.\n\n\nDie soziale Dimension\nDieser Leitfaden fokussiert auf kognitive Prozesse: Arbeitsgedächtnis, Schemabildung, Abrufübung. Aber Lernen ist nicht nur ein individueller kognitiver Prozess. Es ist fundamental sozial (Reich 2020)3.\nBeziehungen beeinflussen Lernerfolg. Studierende lernen besser, wenn sie sich mit Lehrenden und Peers verbunden fühlen. Sie zeigen mehr Ausdauer, wenn sie spüren, dass ihre Lehrenden sich für ihren Erfolg interessieren. Disziplinäre Identität entsteht durch Gemeinschaften.\nWas passiert, wenn Studierende KI fragen statt Menschen?\n\nPeers werden seltener konsultiert; kollaboratives Lernen leidet\nBeziehungen zu Lehrenden werden oberflächlicher, wenn Rückfragen an die KI gehen\nGelegenheiten für Mentoring und informelles Lernen nehmen ab\n\nDie Rolle der Lehrperson: Wenn KI sofortige Antworten und Feedback liefert, verschiebt sich die Rolle der Lehrenden. Die Frage ist, wie Lehrende ihre unersetzliche Funktion, nämlich Beziehung, Motivation, Vorbild, Kontext, neu definieren.\n\n\nDie Equity-Dimension\nDie “dritte digitale Kluft” (Michael Trucano 2023) beschreibt ein neues Ungleichheitsmuster:\n\n\n\n\n\n\n\n\nErste Kluft\nZweite Kluft\nDritte Kluft\n\n\n\n\nZugang zu Geräten\nFähigkeit zur sinnvollen Nutzung\nQualität der pädagogischen Integration\n\n\n\nDie Ironie: “Demokratisierung” durch KI könnte Ungleichheit verstärken:\n\nGutausgestattete Studierende: ausgeklügelte pädagogische Unterstützung, informierte Betreuung, strukturierte KI-Nutzung\nUnterversorgte Studierende: KI als unbeaufsichtigte Abkürzung, niemand erklärt die Risiken\n\nKonkrete Ungleichheiten:\n\nKosten: Premium-KI-Werkzeuge kosten Geld. Wer kann sich ChatGPT Plus, Claude Pro oder spezialisierte Tools leisten? Wer ist auf kostenlose, limitierte Versionen angewiesen?\nInstitutionelle Ressourcen: Welche Hochschulen haben Zeit und Expertise für durchdachte KI-Integration? Welche setzen KI ein, ohne Lehrende zu schulen?\nBetreuung: Wer hat Dozierende, die über KI-Risiken aufklären? Wer hat niemanden, der die Fragen stellt?\n\nDas MOOC-Muster wiederholt sich möglicherweise: Eine Technologie, die “allen” zugänglich ist, nützt vor allem jenen, die bereits die Voraussetzungen mitbringen, sie produktiv zu nutzen.\n\n\nDer stärkste Gegeneinwand\nDer stärkste Einwand lautet: “Wenn KI immer verfügbar ist, müssen Fähigkeiten nicht internalisiert werden.”\nVier Antworten:\n\nPermanenzannahme: Setzt voraus, dass KI immer verfügbar, funktional und bezahlbar bleibt. Stromausfall, Serverprobleme, Kosten, politische Entscheidungen können das ändern.\nRekursionsproblem: Wer erkennt, wenn KI falsch liegt? Wer trainiert die nächste KI-Generation? Wer erweitert menschliches Wissen? Irgendwer muss Domänenexpertise haben.\nAutonomie-Argument: Eigenständiges Denken hat intrinsischen Wert für Selbstbestimmung, Würde, das Gefühl des Verstehens. Nicht alles lässt sich in Produktivität messen.\nUnbekannte Unbekannte: Komplexe Systeme haben Kaskadeneffekte. Wir wissen nicht, was wir verlieren könnten.\n\n\n\nWas wir noch nicht wissen\nEpistemische Bescheidenheit ist angebracht. Wir wissen vieles nicht:\n\nLängsschnittstudien über Jahre: Praktisch nicht vorhanden\nTransfer auf neue Kontexte: Unerforscht\nOptimale Scaffolding-Bedingungen: Unbekannt\nDisziplinspezifische Effekte: Untererforscht\nPublikationsbias: Wahrscheinlich vorhanden\n\n\n\nAbschliessende Überlegungen\nDrei Beobachtungen fassen die Lage zusammen:\n\nWenn KI-Unterstützung während der Ausbildung die eigenständige Fähigkeit beeinträchtigt, könnten Studierende weniger vorbereitet sein auf Kontexte, in denen KI nicht verfügbar ist.\nDie Produktivitätsgewinne während der Ausbildung könnten auf Kosten der späteren Kompetenz gehen.\nOb dieser Kompromiss akzeptabel ist, hängt von Annahmen über die Zukunft ab, die Lehrende nicht verifizieren können.\n\n\n\n\n\n\n\nPro-tipPraktische Empfehlung: Entscheidungsrahmen\n\n\n\n\n\nFür Entscheidungen über KI in der eigenen Lehre:\nFragen zur Selbstreflexion:\n\nWelche kognitiven Prozesse will ich fördern?\nWelche davon könnte KI übernehmen?\nIst die Übernahme für Lernen förderlich oder hinderlich?\nHaben meine Studierenden das nötige Vorwissen für kritische KI-Nutzung?\nWie kann ich Grundlagen schützen und dennoch KI sinnvoll einsetzen?"
  },
  {
    "objectID": "guide/index.html#fazit",
    "href": "guide/index.html#fazit",
    "title": "KI in der Hochschulbildung",
    "section": "Fazit",
    "text": "Fazit\nDie zentrale Botschaft: KI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende ohne durchdachte Integration oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.\nDie Argumentation stützt sich auf:\n\nCognitive Load Theory: Lernen erfordert produktive Anstrengung durch das Nadelöhr des Arbeitsgedächtnisses\nExpertise-Umkehr-Effekt: Dieselbe Unterstützung kann Novizen helfen und Experten schaden\nDomänenspezifität: Kritische KI-Bewertung erfordert Fachwissen, nicht nur generische Strategien\nDesirable Difficulties: Schwierigkeiten, die das Lernen verlangsamen, optimieren oft Langzeitbehalten\nGenerierungseffekt: Selbst erzeugte Information wird besser behalten\n\nDie praktischen Implikationen sind:\n\nGrundlagen vor Werkzeugen sequenzieren\nProzess bewerten, nicht nur Produkt\nNach Vorwissen differenzieren\n“Ohne-KI”-Phasen einplanen\nKritische KI-Nutzung im Fachkontext üben\n\nDie offenen Fragen sind zahlreich. Langzeitstudien fehlen, optimale Strategien sind unbekannt, und die Effekte variieren nach Kontext und Person.\nDie Frage ist nicht, ob KI in die Bildung kommt. Sie ist schon da. Die Frage ist, wie wir sie so gestalten, dass sie dem Lernen dient, nicht es ersetzt."
  },
  {
    "objectID": "guide/index.html#referenzen",
    "href": "guide/index.html#referenzen",
    "title": "KI in der Hochschulbildung",
    "section": "Referenzen",
    "text": "Referenzen\n\n\nAnderson, John R. 1982. „Acquisition of Cognitive Skill“. Psychological Review 89 (4): 369–406. https://doi.org/10.1037/0033-295X.89.4.369.\n\n\nBastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, und Rei Mariman. 2025. „Generative AI Without Guardrails Can Harm Learning: Evidence from High School Mathematics“. Proceedings of the National Academy of Sciences of the United States of America 122 (26): e2422633122. https://doi.org/10.1073/pnas.2422633122.\n\n\nBjork, Elizabeth Ligon, und Robert A. Bjork. 2011. „Making Things Hard on Yourself, but in a Good Way: Creating Desirable Difficulties to Enhance Learning“. In Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society, 56–64. New York, NY, US: Worth Publishers.\n\n\nBLOOM, BENJAMIN S. 1984. „The 2 Sigma Problem: The Search for Methods of Group Instruction as Effective as One-to-One Tutoring“. Educational Researcher 13 (6): 4–16. https://doi.org/10.3102/0013189X013006004.\n\n\nChase, William G., und Herbert A. Simon. 1973. „Perception in Chess“. Cognitive Psychology 4 (1): 55–81. https://doi.org/10.1016/0010-0285(73)90004-2.\n\n\nChi, Michelene T. H., Nicholas De Leeuw, Mei-Hung Chiu, und Christian Lavancher. 1994. „Eliciting Self-Explanations Improves Understanding“. Cognitive Science 18 (3): 439–77. https://doi.org/10.1207/s15516709cog1803_3.\n\n\nClark, Andy. 2025. „Extending Minds with Generative AI“. Nature Communications 16 (1): 4627. https://doi.org/10.1038/s41467-025-59906-9.\n\n\nCooper, Graham, und John Sweller. 1987. „Effects of Schema Acquisition and Rule Automation on Mathematical Problem-Solving Transfer“. Journal of Educational Psychology 79 (4): 347–62. https://doi.org/10.1037/0022-0663.79.4.347.\n\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nGroot, Adriaan D. De, und Adrianus Dingeman de Groot. 1978. Thought and Choice in Chess. Walter de Gruyter. https://books.google.com?id=EI4gr42NwDQC.\n\n\nJose, Binny, Deepak Joseph, Visakh Mohan, Elizabeth Alexander, Subi K. Varghese, und Abhijith Roy. 2025. „Outsourcing Cognition: The Psychological Costs of AI-Era Convenience“. Frontiers in Psychology 16 (Dezember). https://doi.org/10.3389/fpsyg.2025.1645237.\n\n\nKalyuga, Slava. 2009. „The Expertise Reversal Effect“. In Managing Cognitive Load in Adaptive Multimedia Learning, 58–80. IGI Global Scientific Publishing. https://doi.org/10.4018/978-1-60566-048-6.ch003.\n\n\nKirschner, Paul A., Sweller, und Richard E. and Clark. 2006. „Why Minimal Guidance During Instruction Does Not Work: An Analysis of the Failure of Constructivist, Discovery, Problem-Based, Experiential, and Inquiry-Based Teaching“. Educational Psychologist 41 (2): 75–86. https://doi.org/10.1207/s15326985ep4102_1.\n\n\nLortie-Forgues, Hugues, und Robert S. Siegler. 2017. „Conceptual Knowledge of Decimal Arithmetic.“ Journal of Educational Psychology 109 (3): 374–86. https://doi.org/10.1037/edu0000148.\n\n\nMichael Trucano. 2023. „AI and the Next Digital Divide in Education“. Brookings. 7. Oktober 2023. https://www.brookings.edu/articles/ai-and-the-next-digital-divide-in-education/.\n\n\nNewell, Allen, und Herbert A. Simon. 1972. Human Problem Solving. Brattleboro, Vermont: Echo Point Books & Media.\n\n\nReich, Justin. 2020. Failure to Disrupt: Why Technology Alone Can’t Transform Education. Cambridge London: Harvard University Press.\n\n\nRoediger, Henry L., und Jeffrey D. Karpicke. 2006. „Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention“. Psychological Science 17 (3): 249–55. https://doi.org/10.1111/j.1467-9280.2006.01693.x.\n\n\nSlamecka, Norman J., und Peter Graf. 1978. „The Generation Effect: Delineation of a Phenomenon“. Journal of Experimental Psychology: Human Learning and Memory 4 (6): 592–604. https://doi.org/10.1037/0278-7393.4.6.592.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745.\n\n\nSweller, John. 2024. „Cognitive Load Theory and Individual Differences“. Learning and Individual Differences 110 (Februar): 102423. https://doi.org/10.1016/j.lindif.2024.102423.\n\n\nVanLEHN, KURT. 2011. „The Relative Effectiveness of Human Tutoring, Intelligent Tutoring Systems, and Other Tutoring Systems“. Educational Psychologist 46 (4): 197–221. https://doi.org/10.1080/00461520.2011.611369.\n\n\nWeidlich, J., D. Gašević, H. Drachsler, und P. Kirschner. 2025. „ChatGPT in Education: An Effect in Search of a Cause“. Journal of Computer Assisted Learning 41 (5): e70105. https://doi.org/10.1111/jcal.70105.\n\n\nWillingham, Daniel T. 2008. „Critical Thinking: Why Is It So Hard to Teach?“ Arts Education Policy Review 109 (4): 21–32. https://doi.org/10.3200/AEPR.109.4.21-32."
  },
  {
    "objectID": "guide/index.html#footnotes",
    "href": "guide/index.html#footnotes",
    "title": "KI in der Hochschulbildung",
    "section": "Fußnoten",
    "text": "Fußnoten\n\n\nEigentlich “Next-Token-Prediction”, da sie eigentlich Wortteile oder Satzzeichen vorhersagen.↩︎\n“Halluzinieren” ist eigentlich kein guter Begriff; ein treffenderer Ausdruck wäre “Konfabulation”.↩︎\nDiese Dimension verdient mehr Aufmerksamkeit, als dieser Leitfaden ihr geben kann. Der Fokus auf Kognition ist eine bewusste Einschränkung.↩︎"
  },
  {
    "objectID": "qa/paradox/index.html",
    "href": "qa/paradox/index.html",
    "title": "Das Produktivitäts-Lern-Paradox",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Das Produktivitäts-Lern-Paradox"
    ]
  },
  {
    "objectID": "qa/paradox/index.html#das-zentrale-ergebnis",
    "href": "qa/paradox/index.html#das-zentrale-ergebnis",
    "title": "Das Produktivitäts-Lern-Paradox",
    "section": "Das zentrale Ergebnis",
    "text": "Das zentrale Ergebnis\nIn der Präsentation wurde eine Studie vorgestellt, bei der rund 1000 Gymnasiasten GPT-4-Zugang während Mathematik-Übungen erhielten. Das Ergebnis:\n\nMit KI-Zugang: 48% mehr Aufgaben korrekt gelöst\nOhne KI (später): 17% schlechter als die Kontrollgruppe\n\nDies illustriert das Produktivitäts-Lern-Paradox: Mehr Aufgaben gelöst bedeutet nicht automatisch mehr gelernt.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Das Produktivitäts-Lern-Paradox"
    ]
  },
  {
    "objectID": "qa/paradox/index.html#häufige-fragen",
    "href": "qa/paradox/index.html#häufige-fragen",
    "title": "Das Produktivitäts-Lern-Paradox",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Klinisches Reasoning und Pflegediagnostik\nIm Unterricht von klinischem Reasoning und Pflegediagnostik im 2. Studienjahr müssen Studierende lernen, Patientensituationen zu analysieren und eigenständig Pflegediagnosen zu stellen. Dabei wird festgestellt, dass einige ChatGPT nutzen, um Fallbeispiele zu lösen.\nFrage: Wenn Studierende mit KI-Unterstützung mehr Fallbeispiele korrekt lösen, aber dann in der Praxis ohne KI schlechter abschneiden: Wie erkennt man das rechtzeitig? Beim OSCE haben sie ja kein Handy dabei, aber bis dahin haben sie schon Monate mit KI geübt. Kann man überhaupt noch davon ausgehen, dass die Selbstlernphasen mit Fallbeispielen einen Lerneffekt haben, wenn viele heimlich ChatGPT verwenden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Problem liegt in der Unterscheidung zwischen Aufgabenleistung und Lernen. Regelmässige formative Assessments ohne KI-Zugang können helfen, den tatsächlichen Lernstand zu erfassen. Mehr dazu im Leitfaden unter Das Produktivitäts-Lern-Paradox und Lernsituationen gestalten.\n\n\n\n\n\n\nTechnik und Informatik: Code-Assistenten und Grundlagen\nIn Modulen zur objektorientierten Programmierung und Softwarearchitektur sollen Studierende eigenständig kleinere Projekte entwickeln und dabei Design Patterns anwenden lernen.\nFrage: Die Situation ist paradox: Einerseits sollen Studierende GitHub Copilot und ähnliche Tools kennenlernen, weil das zum Berufsalltag gehört. Andererseits zeigt diese Studie ja, dass sie dann die Grundlagen nicht mehr lernen. Wie findet man die richtige Balance? Soll in den ersten Semestern ein komplettes AI-Verbot durchgesetzt und erst ab dem 5. Semester Code-Assistenten erlaubt werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Sequenzierung ist entscheidend: Grundlagen vor Werkzeugen. Der Expertise-Umkehr-Effekt zeigt, dass dieselbe Unterstützung für Novizen schädlich und für Fortgeschrittene hilfreich sein kann. Mehr dazu im Leitfaden unter Die Sequenzierungsfrage und Der Expertise-Umkehr-Effekt.\n\n\n\n\n\n\nWirtschaft: Konzeptverständnis vs. Formelanwendung\nIm Finanzmanagement und Corporate Finance im Bachelor müssen Studierende Investitionsrechnungen durchführen, Cash-Flow-Analysen erstellen und Unternehmensbewertungen vornehmen können.\nFrage: Das Problem zeigt sich direkt bei Excel-basierten Assignments. Wenn Studierende ChatGPT fragen “Erstelle mir eine Formel für den Net Present Value mit diesen Parametern”, bekommen sie sofort die Lösung. Sie reichen dann perfekte Spreadsheets ein, aber in der schriftlichen Prüfung können sie nicht mal erklären, warum man den Diskontierungssatz überhaupt braucht. Wie gestaltet man Übungsaufgaben, bei denen sie wirklich das Konzept verstehen müssen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer Generierungseffekt zeigt: Selbst erarbeitetes Wissen wird besser behalten. Aufgaben sollten den Prozess bewerten, nicht nur das Produkt. Zwischenschritte einfordern und begründen lassen. Mehr dazu im Leitfaden unter Der Generierungseffekt und Prozess bewerten, nicht nur Produkt.\n\n\n\n\n\n\nSoziale Arbeit: Reflexionsfähigkeit und Beziehungsarbeit\nIm Unterricht von Gesprächsführung und Case Management lernen Studierende, mit Klientinnen und Klienten professionelle Beratungsgespräche zu führen und individuelle Unterstützungspläne zu entwickeln.\nFrage: In der Sozialen Arbeit wird viel mit Rollenspielen und schriftlichen Fallanalysen gearbeitet. Es zeigt sich, dass Studierende ihre Gesprächsvorbereitungen und Analysen von ChatGPT schreiben lassen. Die Texte klingen plausibel, aber in der praktischen Umsetzung fehlt komplett das Verständnis für Gesprächsdynamiken. Das Paradox ist besonders kritisch: In diesem Berufsfeld geht es um Beziehungsarbeit und situatives Handeln. Wie bereitet man sie dann auf echte Krisensituationen vor, wo keine KI hilft?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nLernen erfordert die kognitive Anstrengung, die KI zu eliminieren droht. Praktische Übungen ohne KI-Unterstützung sind hier besonders wichtig. Die Reflexionsfähigkeit entsteht durch den mühsamen Prozess des Formulierens. Mehr dazu im Leitfaden unter Desirable Difficulties und Kognition erweitern vs. ersetzen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDas Produktivitäts-Lern-Paradox\nDie Bastani-Studie im Detail\nLernsituationen gestalten",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Das Produktivitäts-Lern-Paradox"
    ]
  },
  {
    "objectID": "qa/kognitive-grundlagen/index.html",
    "href": "qa/kognitive-grundlagen/index.html",
    "title": "Kognitive Grundlagen",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kognitive Grundlagen"
    ]
  },
  {
    "objectID": "qa/kognitive-grundlagen/index.html#das-nadelöhr-des-lernens",
    "href": "qa/kognitive-grundlagen/index.html#das-nadelöhr-des-lernens",
    "title": "Kognitive Grundlagen",
    "section": "Das Nadelöhr des Lernens",
    "text": "Das Nadelöhr des Lernens\nDas Arbeitsgedächtnis hat eine stark begrenzte Kapazität von etwa 4 plus/minus 1 Elementen. Alles Lernen muss durch dieses Nadelöhr. Es gibt keinen Weg drumherum, keine Abkürzung, und keine KI kann diesen biologischen Engpass umgehen.\nDie Cognitive Load Theory unterscheidet drei Arten der Belastung:\n\nIntrinsische Belastung: Inhärente Komplexität des Materials\nExtrinsische Belastung: Schlecht gestaltete Instruktion (minimieren)\nLernförderliche Belastung: Produktive Anstrengung für Schemabildung (erhalten)",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kognitive Grundlagen"
    ]
  },
  {
    "objectID": "qa/kognitive-grundlagen/index.html#häufige-fragen",
    "href": "qa/kognitive-grundlagen/index.html#häufige-fragen",
    "title": "Kognitive Grundlagen",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Notfallsituationen und Informationsverarbeitung\nIm Bachelor Pflege müssen Studierende in Notfallsituationen sehr schnell viele Informationen gleichzeitig verarbeiten: Vitalwerte, Symptome, Medikamentenwirkungen, und so weiter.\nFrage: Wenn das Working Memory wirklich auf 4±1 Elemente beschränkt ist, wie kann man Studierende dann überhaupt auf solche komplexen Situationen vorbereiten? KI-gestützte Simulationen könnten helfen, aber wenn die kognitive Belastung nicht umgangen werden kann: Sollte dann vielleicht mehr auf klassische Chunking-Strategien gesetzt werden, wo zusammengehörige Informationen gebündelt werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nChunking ist tatsächlich der Schlüssel: Experten speichern Wissen in vernetzten Strukturen, die automatisch abgerufen werden. Diese “Chunks” müssen aber durch Übung aufgebaut werden. KI kann diesen Prozess nicht abkürzen, aber gut gestaltete Simulationen können helfen, Muster zu erkennen. Mehr dazu im Leitfaden unter Wie Expertise entsteht und Was Experten sehen.\n\n\n\n\n\n\nTechnik und Informatik: Code verstehen vs. kopieren\nStudierende im dritten Semester Informatik programmieren zunehmend mit GitHub Copilot und ChatGPT. Theoretisch umgeht das die kognitive Verarbeitung nicht wirklich: Sie müssen den generierten Code ja trotzdem verstehen und durchdenken.\nFrage: Aber es zeigt sich, dass viele einfach Code kopieren, ohne ihn richtig zu durchdringen. Wie kann man Aufgabenstellungen so gestalten, dass der germane Load, also die lernrelevante Belastung, im Vordergrund steht? Sollten bewusst kleinere Code-Beispiele verwendet werden, damit Studierende innerhalb dieser 4±1 Elemente arbeiten können?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Problem ist, dass KI die lernförderliche Belastung eliminieren kann. Aufgabenstellungen sollten den Denkprozess fordern: Code erklären lassen, Varianten vergleichen, Fehler finden. Kleinere, fokussierte Beispiele können helfen, die kognitive Belastung zu managen. Mehr dazu im Leitfaden unter Cognitive Load Theory und Drei Arten kognitiver Belastung.\n\n\n\n\n\n\nWirtschaft: KI zur Komplexitätsreduktion\nIm Kurs “Strategisches Management” wird viel mit komplexen Fallstudien gearbeitet: Marktanalysen, Finanzberichte, Wettbewerbsszenarien. Die Studierenden nutzen mittlerweile KI, um diese Fälle vorab zusammenzufassen.\nFrage: Einerseits ist das Problem mit dem Working Memory klar: Wenn Studierende zu viele Variablen gleichzeitig jonglieren müssen, lernen sie nichts. Andererseits: Wenn KI ihnen hilft, die extrinsic load zu reduzieren, also überflüssige Komplexität wegzufiltern, ist das dann nicht sogar förderlich? Oder riskiert man damit, dass sie die Fähigkeit verlieren, selbst relevante von irrelevanten Informationen zu unterscheiden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas ist eine wichtige Unterscheidung: KI kann extrinsische Belastung reduzieren (gut) oder lernförderliche Belastung eliminieren (problematisch). Die Fähigkeit, Relevantes von Irrelevantem zu unterscheiden, ist selbst eine Expertise, die aufgebaut werden muss. Mehr dazu im Leitfaden unter Welche Art der Belastung reduziert KI?.\n\n\n\n\n\n\nKünste: Kognitive Überlastung durch KI-Output\nIn der Visuellen Kommunikation arbeiten Studierende oft sehr intuitiv und visuell. Viele experimentieren mit Midjourney oder DALL-E und generieren in kurzer Zeit sehr viele Designvarianten.\nFrage: Wenn das Working Memory aber tatsächlich so limitiert ist: Überfordert es Studierende dann nicht kognitiv, wenn sie 50 KI-generierte Entwürfe durchgehen müssen, um den richtigen auszuwählen? Sollte man sie eher anleiten, weniger, aber bewusstere Iterationen zu machen? Kann die Flut an KI-Output den kreativen Lernprozess tatsächlich behindern, weil die kognitive Kapazität überlastet wird?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nJa, zu viele Optionen können das Arbeitsgedächtnis überlasten und den Lernprozess behindern. Bewusste Einschränkungen und fokussierte Iterationen können helfen. Der kreative Prozess des Skizzierens, Iterierens und Verwerfens hat einen eigenen Lernwert. Mehr dazu im Leitfaden unter Das Nadelöhr des Lernens.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nCognitive Load Theory: Das Nadelöhr des Lernens\nDrei Arten kognitiver Belastung\nWie Expertise entsteht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kognitive Grundlagen"
    ]
  },
  {
    "objectID": "qa/historische-analogien/index.html",
    "href": "qa/historische-analogien/index.html",
    "title": "Historische Analogien",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Historische Analogien"
    ]
  },
  {
    "objectID": "qa/historische-analogien/index.html#was-wir-aus-der-vergangenheit-lernen-können",
    "href": "qa/historische-analogien/index.html#was-wir-aus-der-vergangenheit-lernen-können",
    "title": "Historische Analogien",
    "section": "Was wir aus der Vergangenheit lernen können",
    "text": "Was wir aus der Vergangenheit lernen können\nDas Muster wiederholt sich bei verschiedenen Technologien:\n\n1970er, Taschenrechner: Konzeptuelles Verständnis kann leiden\n1990er, GPS: Räumliches Gedächtnis wird schwächer\n2000er, Google: “Wo” ersetzt “Was” im Gedächtnis\n2020er, KI: Alles vorherige plus mehr?\n\nDer Unterschied: KI ist breiter als GPS oder Taschenrechner. Sie betrifft nicht eine kognitive Domäne, sondern potenziell alle.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Historische Analogien"
    ]
  },
  {
    "objectID": "qa/historische-analogien/index.html#häufige-fragen",
    "href": "qa/historische-analogien/index.html#häufige-fragen",
    "title": "Historische Analogien",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nTechnik und Informatik: Technologischer Fortschritt und Grundlagenwissen\nDie historische Entwicklung von Taschenrechner über GPS zu KI wirft Fragen auf. Ist der Vergleich nicht etwas schief? In der Informatik-Ausbildung wurde bewusst entschieden, dass Studierende keinen Assembler mehr von Hand schreiben müssen, weil Compiler das besser machen. Es wurde akzeptiert, dass gewisse Low-Level-Skills obsolet werden.\nFrage: Warum sollte es bei KI anders sein? Wenn Studierende mit KI-Tools schneller zu besseren Lösungen kommen, ist das dann nicht einfach der normale technologische Fortschritt? Wo liegt konkret die Grenze zwischen “wichtiges Grundlagenwissen, das sie trotzdem lernen müssen” und “kann man getrost der KI überlassen”?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Grenze liegt dort, wo Wissen zur Bewertung von KI-Output nötig ist. Assembler kann man delegieren, weil Compiler deterministisch sind. KI-Output muss aber kritisch geprüft werden, und dafür braucht es Fachwissen. Die Frage ist: Was muss man verstehen, um Fehler zu erkennen? Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen.\n\n\n\n\n\n\nWirtschaft: Blindes Vertrauen in Modelle\nDie Analogie mit dem Taschenrechner ist interessant, aber im Bereich Wirtschaft zeigt sich ein Problem: Studierende müssen später in Unternehmen strategische Entscheidungen treffen, Geschäftsberichte analysieren, Budgets verteidigen.\nFrage: Wenn sie jetzt schon im Studium alle Analysen und Argumentationen von ChatGPT machen lassen, wie sollen sie dann später im Beruf beurteilen können, ob die KI-generierten Vorschläge überhaupt Sinn machen? Bei der Finanzkrise 2008 haben viele blind auf Excel-Modelle vertraut, ohne die Annahmen zu hinterfragen. Besteht nicht die Gefahr, dass eine Generation ausgebildet wird, die zwar KI-Tools bedienen kann, aber nicht mehr die Kompetenz hat, deren Output kritisch zu bewerten?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDiese Sorge ist berechtigt und historisch fundiert. Das Muster wiederholt sich: Werkzeuge, die Experten produktiver machen, können bei unkritischer Nutzung zu Fehlentscheidungen führen. Die Fähigkeit zur kritischen Bewertung erfordert Fachwissen, das aufgebaut werden muss. Mehr dazu im Leitfaden unter Der EdTech-Hype-Zyklus und Der stärkste Gegeneinwand.\n\n\n\n\n\n\nHAFL: Praktische vs. digitale Kompetenzen\nDie historischen Beispiele kommen alle aus dem digitalen oder städtischen Bereich. Aber Studierende in der Agronomie, die später Landwirtschaftsbetriebe führen oder in der Beratung arbeiten, müssen raus aufs Feld, Böden beurteilen, Krankheiten an Pflanzen erkennen, Wetterentwicklungen einschätzen.\nFrage: Es gibt mittlerweile Precision-Agriculture-Tools und Apps zur Schädlingserkennung, aber am Ende muss man vor Ort sein und die Situation richtig einschätzen können. Wie übertragbar sind diese Erkenntnisse auf praktische, handwerkliche Ausbildungen? Oder ist das Ganze vor allem ein Problem für Büroberufe?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Erkenntnisse sind übertragbar, aber der Kontext ist anders. Praktische Fertigkeiten wie Bodenbeurteilung erfordern implizites Wissen, das nur durch Erfahrung aufgebaut wird. KI-Tools können hier unterstützen, aber nicht das geschulte Auge ersetzen. Die Gefahr ist, dass Studierende sich auf Apps verlassen, ohne das Grundverständnis aufzubauen. Mehr dazu im Leitfaden unter Prozeduralisierung: Vom Wissen zum Können.\n\n\n\n\n\n\nArchitektur: Handzeichnen und räumliches Verständnis\nDer Vergleich mit GPS ist spannend, weil in der Architektur etwas Ähnliches passiert ist: Früher mussten Studierende von Hand zeichnen und räumlich denken lernen. Dann kam CAD, und es gab grosse Diskussionen, ob das Handzeichnen noch nötig ist. Heute werden generative Design-Tools und KI für Entwurfsvarianten genutzt.\nFrage: Es zeigt sich, dass Studierende, die nie gelernt haben, von Hand zu skizzieren und Proportionen zu erfassen, auch mit den digitalen Tools Mühe haben, weil ihnen das räumliche Verständnis fehlt. Gibt es eine Möglichkeit, diese Grundkompetenzen parallel zur KI-Nutzung zu vermitteln? Oder muss man sich entscheiden zwischen “erst die Grundlagen ohne KI” und “direkt mit KI arbeiten”?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Beobachtung bestätigt das Muster: Grundlegende Fertigkeiten (hier räumliches Denken) sind Voraussetzung für effektive Werkzeugnutzung. Die Sequenz “erst Grundlagen, dann Werkzeuge” ist wahrscheinlich effektiver als paralleles Arbeiten. Das Handzeichnen baut Verständnis auf, das bei der Bewertung von KI-Output hilft. Mehr dazu im Leitfaden unter Die Sequenzierungsfrage und Grundlagen BEVOR Werkzeuge.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nHistorische Analogien\nDer EdTech-Hype-Zyklus\n“Das haben sie über das Schreiben auch gesagt”",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Historische Analogien"
    ]
  },
  {
    "objectID": "qa/expertise-umkehr-effekt/index.html",
    "href": "qa/expertise-umkehr-effekt/index.html",
    "title": "Der Expertise-Umkehr-Effekt",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Expertise-Umkehr-Effekt"
    ]
  },
  {
    "objectID": "qa/expertise-umkehr-effekt/index.html#vorwissen-bestimmt-die-optimale-methode",
    "href": "qa/expertise-umkehr-effekt/index.html#vorwissen-bestimmt-die-optimale-methode",
    "title": "Der Expertise-Umkehr-Effekt",
    "section": "Vorwissen bestimmt die optimale Methode",
    "text": "Vorwissen bestimmt die optimale Methode\nDer Expertise-Umkehr-Effekt zeigt: Dieselbe Instruktionsmethode kann gegenteilige Effekte haben, abhängig vom Vorwissen der Lernenden.\n\nBei niedrigem Vorwissen: Hohe Unterstützung hilft (Worked Examples, direkte Instruktion)\nBei hohem Vorwissen: Hohe Unterstützung kann schaden (problembasiertes Lernen wird effektiver)\n\nDie Schwelle, ab der KI von schädlich zu hilfreich wechselt, ist unbekannt und variiert nach Domäne und Person.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Expertise-Umkehr-Effekt"
    ]
  },
  {
    "objectID": "qa/expertise-umkehr-effekt/index.html#häufige-fragen",
    "href": "qa/expertise-umkehr-effekt/index.html#häufige-fragen",
    "title": "Der Expertise-Umkehr-Effekt",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Heterogene Vorkenntnisse im Kurs\nDas Konzept ist klar, aber wie setzt man es konkret um? In Kursen zur Patientenbeurteilung gibt es oft Studierende mit sehr unterschiedlichen Vorkenntnissen: Einige kommen direkt von der Matur, andere haben bereits eine FaGe-Ausbildung oder Jahre Praxiserfahrung als Pflegeassistenz.\nFrage: Wenn die Empfehlung lautet, “nutzt ChatGPT zur Vorbereitung auf die OSCE-Prüfung”, könnte das den Anfängern helfen, aber den Erfahrenen schaden? Wie findet man heraus, wo bei den Studierenden diese Schwelle liegt? Sollten verschiedene Aufgabenstellungen für verschiedene Levels gemacht werden, oder sollte der KI-Einsatz einfach ganz verboten werden, bis alle ein Grundniveau erreicht haben?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDifferenzierung ist der Schlüssel. Verschiedene Aufgaben für verschiedene Niveaus können sinnvoll sein. Eine Möglichkeit: Selbsteinschätzung kombiniert mit diagnostischen Aufgaben, um das Vorwissen zu erfassen. Dann gestufte KI-Nutzung. Mehr dazu im Leitfaden unter Der Expertise-Umkehr-Effekt und Unterstützung anpassen.\n\n\n\n\n\n\nTechnik und Informatik: KI-Nutzung nach Expertise differenzieren\nIn der Informatik ist die Situation noch komplizierter. Studierende im Web-Development-Kurs kennen teilweise GitHub Copilot sehr gut. Die Frage ist nicht mehr, ob sie KI nutzen, sondern wie.\nFrage: Wenn hohe Unterstützung bei Experten schaden kann: Heisst das, dass fortgeschrittenen Studierenden abgeraten werden sollte, Copilot zu nutzen? Das scheint realitätsfern, denn in der Industrie arbeitet heute jeder damit. Oder geht es darum, dass sie Copilot anders nutzen sollten als Anfänger? Wie kann das in Übungsaufgaben berücksichtigt werden, wenn die “Schwelle” bei jedem anders liegt und sich während des Semesters verschiebt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer Expertise-Umkehr-Effekt bezieht sich auf Instruktion, nicht auf Werkzeugnutzung per se. Fortgeschrittene können KI produktiv nutzen, weil sie den Output bewerten können. Die Frage ist: Nutzen sie KI als Abkürzung (problematisch) oder als Effizienzwerkzeug bei bereits verstandenen Konzepten (ok)? Mehr dazu im Leitfaden unter Kognition erweitern vs. ersetzen.\n\n\n\n\n\n\nWirtschaft: Fallstudien und direkte Instruktion\nDas wirft eine grundsätzliche didaktische Frage auf: In Einführungskursen Marketing wird viel mit Fallstudien gearbeitet. Die Annahme ist oft, dass selbstständiges Problemlösen die beste Methode ist, “Learning by doing”.\nFrage: Könnte das für Erstsemester-Studierende, die noch keine Marketingkonzepte kennen, zu wenig Struktur sein? Müsste am Anfang mehr direkte Instruktion gegeben werden, bevor es an die Fälle geht? Und wenn Studierende dann KI-Tools wie ChatGPT nutzen, um ihre Fallanalysen zu schreiben: Ist das dann quasi eine Form von Unterstützung, die Anfänger brauchen, oder verhindert es genau den Lerneffekt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nFür Novizen ist direkte Instruktion mit Worked Examples tatsächlich oft effektiver als problembasiertes Lernen. KI-Nutzung ist aber nicht dasselbe wie gute Instruktion: KI gibt Antworten, aber nicht didaktisch strukturierte Erklärungen. Die Sequenz wäre: Erst Grundlagen vermitteln (direkte Instruktion), dann angeleitete Übung, dann selbstständige Anwendung, dann KI als Werkzeug. Mehr dazu im Leitfaden unter Explizite Instruktion und Worked Examples.\n\n\n\n\n\n\nKünste: Grundlagen vor generativen Tools\nIn der künstlerischen Ausbildung ist die Situation speziell: Kreativität entsteht oft gerade durch Einschränkungen und durch das Ringen mit dem Material.\nFrage: Wenn Studierende ihre Gehörbildungsübungen oder Harmonielehre-Aufgaben mit KI-Tools lösen, einige können schon ganz gut harmonisieren, andere kämpfen noch mit Grundlagen, wo liegt da die Grenze? Bei den Fortgeschrittenen könnte KI als “Sparringpartner” funktionieren, um verschiedene Varianten durchzuspielen. Aber schadet es den Anfängern nicht fundamental, wenn sie die KI Lösungen generieren lassen, bevor sie überhaupt ein intuitives Gefühl für Stimmführung entwickelt haben? Wie unterscheidet man zwischen “hilfreicher Unterstützung” und “verhindert den grundlegenden Lernprozess”?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nIn künstlerischen Fächern ist das “Ringen mit dem Material” besonders wichtig. Die intuitive Kompetenz entwickelt sich durch Übung, nicht durch Betrachtung von KI-Output. Für Anfänger ist KI-Nutzung hier wahrscheinlich kontraproduktiv. Für Fortgeschrittene kann KI als Experimentierfeld dienen. Die Schwelle liegt dort, wo die Grundlagen internalisiert sind. Mehr dazu im Leitfaden unter Der Expertise-Umkehr-Effekt und Prozeduralisierung.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDer Expertise-Umkehr-Effekt\nUnterstützung anpassen\nExplizite Instruktion",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Expertise-Umkehr-Effekt"
    ]
  },
  {
    "objectID": "qa/erwuenschte-schwierigkeiten/index.html",
    "href": "qa/erwuenschte-schwierigkeiten/index.html",
    "title": "Erwünschte Schwierigkeiten",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Erwünschte Schwierigkeiten"
    ]
  },
  {
    "objectID": "qa/erwuenschte-schwierigkeiten/index.html#warum-anstrengung-notwendig-ist",
    "href": "qa/erwuenschte-schwierigkeiten/index.html#warum-anstrengung-notwendig-ist",
    "title": "Erwünschte Schwierigkeiten",
    "section": "Warum Anstrengung notwendig ist",
    "text": "Warum Anstrengung notwendig ist\nRobert Bjork prägte das Konzept der “Desirable Difficulties”:\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\nVier bewährte Strategien:\n\nSelbst generieren: Eigene Antworten formulieren\nVerteilt lernen: Zeitliche Abstände einbauen\nAktiv abrufen: Wissen aus dem Gedächtnis holen\nVariieren: Themen und Aufgaben mischen\n\nKI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit übernimmt.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Erwünschte Schwierigkeiten"
    ]
  },
  {
    "objectID": "qa/erwuenschte-schwierigkeiten/index.html#häufige-fragen",
    "href": "qa/erwuenschte-schwierigkeiten/index.html#häufige-fragen",
    "title": "Erwünschte Schwierigkeiten",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Pflegediagnosen und Selbst-Generierung\nIm klinischen Reasoning bei Bachelorstudierenden Pflege arbeiten Studierende Fallbeispiele selbst durch und begründen ihre Pflegediagnosen. Das ist mühsam für sie, aber genau diese Mühe scheint ja wichtig zu sein.\nFrage: Studierende berichten, dass sie ChatGPT nutzen, um sich Pflegediagnosen vorschlagen zu lassen und dann nur noch auswählen. Einerseits ist das verständlich: Die KI gibt oft korrekte Vorschläge. Andererseits besteht die Befürchtung, dass ihnen genau dieser Prozess der Selbst-Generierung fehlt. Wie können Fallbeispiele so umgestaltet werden, dass diese “erwünschte Schwierigkeit” erhalten bleibt, auch wenn Studierende KI nutzen? Oder sollte KI-Nutzung bei solchen Übungen einfach verboten werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer Generierungseffekt zeigt: Selbst formulierte Antworten werden besser behalten. Mögliche Strategien: Erst eigene Diagnose erstellen, dann mit KI vergleichen und Unterschiede begründen. Oder: Prozess dokumentieren lassen, nicht nur das Ergebnis. Mehr dazu im Leitfaden unter Der Generierungseffekt und Desirable Difficulties.\n\n\n\n\n\n\nTechnik und Informatik: Abkürzung vs. Effizienz\nDas Konzept der “erwünschten Schwierigkeiten” wirft Fragen auf. In Programmierkursen zeigt sich, dass Studierende mit GitHub Copilot und KI-Assistenten viel schneller vorankommen und mehr Projekte umsetzen können.\nFrage: Variation wird als eine dieser Strategien genannt, aber genau das ermöglicht doch die KI? Studierende können jetzt viel mehr verschiedene Frameworks und Ansätze ausprobieren. Wo ist die Grenze zwischen unerwünschter Abkürzung und sinnvoller Effizienzsteigerung? Einerseits sollen Studierende Programmiersprachen beherrschen. Andererseits sollen sie nicht Zeit mit dem Auswendiglernen von Syntax verschwenden. Wie unterscheidet man, welche Schwierigkeiten “erwünscht” sind und welche einfach nur Zeitverschwendung?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nErwünschte Schwierigkeiten sind solche, die zur Schemabildung beitragen. Syntax auswendig lernen ist weniger wichtig als Konzepte verstehen. Die Frage ist: Verstehen sie, warum der Code funktioniert? Können sie Fehler finden und beheben? Mehr dazu im Leitfaden unter Von schwachen zu starken Methoden und Prozeduralisierung.\n\n\n\n\n\n\nSoziale Arbeit: Reflexionsberichte und aktiver Abruf\nIn der Sozialen Arbeit geht es viel um Gesprächsführung und die Entwicklung einer professionellen Haltung. Studierende schreiben oft Reflexionsberichte nach Praxiseinsätzen, das ist diese “aktive Retrieval”-Strategie, oder?\nFrage: Es zeigt sich, dass manche Arbeiten sprachlich perfekt sind, aber irgendwie leer wirken. Studierende geben zu, dass sie ihre Stichworte in ChatGPT eingeben und dann den Text überarbeiten. Sie meinen, das helfe ihnen, ihre Gedanken zu strukturieren. Einerseits haben sie sich ja mit dem Inhalt auseinandergesetzt. Andererseits stellt sich die Frage, ob dieser Prozess des mühsamen Formulierens nicht genau das ist, was die Reflexion vertieft. Wie können Reflexionsaufgaben so gestaltet werden, dass diese erwünschte Schwierigkeit erhalten bleibt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas mühsame Formulieren ist tatsächlich Teil des Lernprozesses. Schreiben kann ein “epistemisches Werkzeug” sein: Gedanken entwickeln sich durch das Schreiben. Mögliche Ansätze: Handschriftliche Erstfassung, mündliche Reflexion, oder strukturierte Fragen, die KI-Nutzung erschweren. Mehr dazu im Leitfaden unter Die Scaffolding-Hypothese.\n\n\n\n\n\n\nHAFL: Spaced Learning und KI-Tools in der Praxis\nIn Bodenkunde und Pflanzenernährung ist ein wichtiger Teil des Lernens, dass Studierende lernen, Nährstoffmängel an Pflanzen zu erkennen und zu diagnostizieren. Das braucht Übung: Sie müssen viele Beispiele sehen und selbst interpretieren.\nFrage: Es gibt bereits Apps, die per Bilderkennung Pflanzenkrankheiten und Nährstoffmängel identifizieren. In der Praxis werden Studierende später als Agronomieberatende solche Tools nutzen. Gleichzeitig müssen sie zuerst das Grundwissen aufbauen, um die KI-Vorschläge überhaupt kritisch beurteilen zu können. Wie können diese Übungen so gestaltet werden, dass Studierende lernen, KI-Tools sinnvoll einzusetzen, ohne dass ihnen der mühsame Prozess des Lernens verloren geht? Sollten die KI-Tools in gewissen Phasen erlaubt und in anderen verboten werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Sequenzierung ist entscheidend: Erst die Grundlagen ohne KI, dann KI als Werkzeug. Gestaffelte Übungen können helfen: In frühen Phasen selbst diagnostizieren, später mit KI-Tool vergleichen und Unterschiede analysieren. Mehr dazu im Leitfaden unter Die Sequenzierungsfrage und Übungsphasen schützen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDesirable Difficulties: Warum Anstrengung nötig ist\nDer Generierungseffekt\nRetrieval Practice",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Erwünschte Schwierigkeiten"
    ]
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#ein-überraschendes-ergebnis",
    "href": "slides/ai-higher-ed-short/index.html#ein-überraschendes-ergebnis",
    "title": "KI in der Hochschulbildung",
    "section": "Ein überraschendes Ergebnis",
    "text": "Ein überraschendes Ergebnis\n\n\n\nMit KI-Zugang:\n\n48% mehr Aufgaben\nkorrekt gelöst\n\nOhne KI (später):\n\n17% schlechter\nals die Kontrollgruppe\n\n\n\n\nQuelle: Bastani u. a. (2025):\n~1000 Gymnasiasten, GPT-4 Zugang während Mathe-Übungen\n\n\nIch möchte mit einem überraschenden Befund beginnen, der die Komplexität unseres Themas illustriert.\nIn einer gross angelegten Studie mit etwa 1000 Gymnasiasten in der Türkei erhielten Schüler Zugang zu GPT-4 während ihrer Mathematik-Übungen.\n[KLICK] Die Ergebnisse während der Übungsphase waren beeindruckend: 48 Prozent mehr Aufgaben korrekt gelöst.\n[KLICK] Klingt nach einem Erfolg, oder? Aber dann kam der Test ohne KI-Zugang.\n[KLICK] 17 Prozent schlechter als die Kontrollgruppe.\n[KLICK] Das ist die zentrale Spannung: Mehr Aufgaben gelöst bedeutet nicht automatisch mehr gelernt.\nDer 17%-Nachteil entspricht etwa 0.2-0.3 Standardabweichungen. Relevant, aber kein Totalausfall. Wichtig: Die Studie testete auch einen “GPT Tutor” mit pädagogischen Leitplanken, der deutlich bessere Ergebnisse zeigte. Das Problem ist nicht KI an sich, sondern wie sie eingesetzt wird."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#das-paradox",
    "href": "slides/ai-higher-ed-short/index.html#das-paradox",
    "title": "KI in der Hochschulbildung",
    "section": "Das Paradox",
    "text": "Das Paradox\n\n\n\n\nAufgabenleistung ≠ Lernen\n\nHier sehen wir das Paradox visualisiert.\nDie magentafarbene Linie zeigt die Gruppe mit KI-Zugang, die graue die Kontrollgruppe ohne KI.\nIn der Übungsphase links performt die KI-Gruppe deutlich besser. Das macht Sinn: Sie hatten ja Hilfe. Der Unterschied ist klar, die Fehlerbalken überlappen nicht.\nAber schauen Sie, was beim Test passiert. Die KI-Gruppe schneidet tendenziell schlechter ab, aber beachten Sie die Fehlerbalken: Sie überlappen sich. Der Unterschied ist statistisch nicht so dramatisch, wie die Linien allein suggerieren würden.\n[KLICK] Die Kernaussage: Aufgabenleistung ist nicht dasselbe wie Lernen. Wir verwechseln oft Performanz mit Kompetenz. Wenn Studierende mit KI-Hilfe eine Aufgabe lösen, sehen wir die Performanz des Systems, nicht unbedingt das Lernen des Studierenden."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#das-nadelöhr-des-lernens",
    "href": "slides/ai-higher-ed-short/index.html#das-nadelöhr-des-lernens",
    "title": "KI in der Hochschulbildung",
    "section": "Das Nadelöhr des Lernens",
    "text": "Das Nadelöhr des Lernens\n\n\n\n\n\n\n\n\n\n\n\n Kernaussage: Alles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses (Sweller 2024).\n\n\nUm zu verstehen, warum das passiert, müssen wir einen kurzen Ausflug in die Kognitionspsychologie machen.\nHier sehen Sie ein vereinfachtes Modell des menschlichen Gedächtnisses. Links die neue Information, rechts das Langzeitgedächtnis, und in der Mitte: das Nadelöhr.\nDas Arbeitsgedächtnis hat eine stark begrenzte Kapazität: etwa 4 plus/minus 1 Elemente gleichzeitig. Neue Information links ist unbegrenzt. Das Langzeitgedächtnis rechts ist praktisch unbegrenzt. Aber alles, was von links nach rechts wandern soll, muss durch dieses enge Nadelöhr.\n[KLICK] Das ist die Kernaussage der Cognitive Load Theory: Alles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses. Es gibt keinen Weg drumherum. Keine Abkürzung. Keine KI kann diesen biologischen Engpass umgehen."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#erwünschte-schwierigkeiten",
    "href": "slides/ai-higher-ed-short/index.html#erwünschte-schwierigkeiten",
    "title": "KI in der Hochschulbildung",
    "section": "Erwünschte Schwierigkeiten",
    "text": "Erwünschte Schwierigkeiten\n\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\n\n\nRobert Bjork (Bjork und Bjork 2011)\n\n\n\n\nSchwerer fühlt sich schlechter an, ist aber besser für langfristiges Lernen.\n\n\nDas bringt uns zu einem kontraintuitiven Konzept: den erwünschten Schwierigkeiten, oder auf Englisch “Desirable Difficulties”.\nHier ein Zitat von Robert Bjork: “Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\nÜbersetzt: Bedingungen, die das scheinbare Lernen verlangsamen, optimieren oft das langfristige Behalten und den Transfer.\n[KLICK] Oder noch kürzer: Schwerer fühlt sich schlechter an, ist aber besser für langfristiges Lernen.\nDas ist ein fundamentales Prinzip, das wir immer wieder vergessen. Wenn Lernen sich leicht anfühlt, lernen wir wahrscheinlich weniger, als wenn es sich anstrengend anfühlt."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-vier-strategien",
    "href": "slides/ai-higher-ed-short/index.html#die-vier-strategien",
    "title": "KI in der Hochschulbildung",
    "section": "Die vier Strategien",
    "text": "Die vier Strategien\n\n\n\n\n\nSelbst generieren\nEigene Antworten formulieren\n\n\n\nVerteilt lernen\nZeitliche Abstände einbauen\n\n\n\nAktiv abrufen\nWissen aus dem Gedächtnis holen\n\n\n\nVariieren\nThemen und Aufgaben mischen\n\n\n\n\n KI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit übernimmt.\n\n\nBjork hat vier konkrete Strategien identifiziert, die als erwünschte Schwierigkeiten fungieren:\n[KLICK] Erstens, selbst generieren. Eigene Antworten formulieren, statt vorgegebene zu lesen.\n[KLICK] Zweitens, verteilt lernen. Zeitliche Abstände einbauen.\n[KLICK] Drittens, aktiv abrufen. Wissen aus dem Gedächtnis holen, statt es nachzuschlagen.\n[KLICK] Viertens, variieren. Themen und Aufgabentypen mischen.\n[KLICK] Und hier kommt der kritische Punkt: KI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit übernimmt.\nWarum selbst generieren, wenn KI es besser kann? Warum sich anstrengen, wenn die Antwort einen Klick entfernt ist? Warum aus dem Gedächtnis abrufen, wenn ich nachfragen kann?"
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#der-generierungseffekt",
    "href": "slides/ai-higher-ed-short/index.html#der-generierungseffekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Generierungseffekt",
    "text": "Der Generierungseffekt\n\n\n\n\n\n\n\n\n\nSelbst generierte Information wird besser behalten (Slamecka und Graf 1978).\n\n\nWenn KI generiert, was Studierende selbst produzieren sollten, entfällt der Lerneffekt.\n\n\n\nDer Generierungseffekt ist nicht neu. Immer wenn Technologie kognitive Arbeit übernimmt, sehen wir ähnliche Muster…\n\nSchauen wir uns den Generierungseffekt genauer an, weil er besonders relevant für KI ist.\nDie Grafik zeigt die Behaltensleistung in Prozent. Selbst generierte Information wird am besten behalten, etwa 70 Prozent. Gelesene Information liegt bei etwa 50 Prozent. Und von KI erhaltene Information? Noch niedriger, hier illustrativ bei etwa 35 Prozent dargestellt.\nDie Forschung zum Generierungseffekt stammt aus den 1970er Jahren. Slamecka und Graf zeigten, dass selbst produziertes Material besser behalten wird als passiv aufgenommenes.\n[KLICK] Die Implikation ist klar: Wenn KI generiert, was Studierende selbst produzieren sollten, entfällt der Lerneffekt.\n[KLICK] Aber dieser Effekt ist nicht neu. Das bringt uns zu den historischen Analogien."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#historische-analogien",
    "href": "slides/ai-higher-ed-short/index.html#historische-analogien",
    "title": "KI in der Hochschulbildung",
    "section": "Historische Analogien",
    "text": "Historische Analogien\n\n\n\n\n\n\n\n\n\n\n\n\nDas Muster wiederholt sich. Aber: KI ist breiter als GPS oder Taschenrechner.\n(Dahmani und Bohbot 2020; Sparrow, Liu, und Wegner 2011)\n\n\nHier sehen Sie eine Zeitlinie technologischer Entwicklungen und ihrer Auswirkungen auf unsere kognitiven Fähigkeiten.\nDie 1970er: Der Taschenrechner. Studien zeigen, dass früher und intensiver Taschenrechner-Einsatz das konzeptuelle mathematische Verständnis beeinträchtigen kann.\nDie 1990er: GPS-Navigation. Habitueller GPS-Gebrauch ist mit schwächerem räumlichem Gedächtnis assoziiert.\nDie 2000er: Google. Der “Google-Effekt”: Wir erinnern besser, WO Information zu finden ist, als WAS die Information ist.\nDie 2020er: KI. Und jetzt? KI kombiniert und verstärkt all diese Effekte.\n[KLICK] Das Muster wiederholt sich. Aber der Unterschied: KI ist breiter als GPS oder Taschenrechner. Sie betrifft nicht eine kognitive Domäne, sondern potenziell alle."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-entscheidende-frage",
    "href": "slides/ai-higher-ed-short/index.html#die-entscheidende-frage",
    "title": "KI in der Hochschulbildung",
    "section": "Die entscheidende Frage",
    "text": "Die entscheidende Frage\n\n\nDasselbe Werkzeug, unterschiedliche Ergebnisse.\n\n\n\n\nTaschenrechner helfen Mathematikern, können aber Lernenden schaden.\nGPS unterstützt Taxifahrer, schwächt aber das räumliche Gedächtnis von Neulingen.\n\n\n\n\n\nDie Frage ist nicht ob KI, sondern wer davon profitiert.\n\n\n\n\nDie Antwort liegt in dem, was Experten von Lernenden unterscheidet.\n\nDas bringt uns zur entscheidenden Frage.\nDasselbe Werkzeug, unterschiedliche Ergebnisse.\n[KLICK] Taschenrechner helfen Mathematikern enorm. Aber für Lernende, die gerade erst das Rechnen verstehen sollen, können sie schädlich sein.\nGPS unterstützt Taxifahrer bei der Navigation. Aber es schwächt nachweislich das räumliche Gedächtnis von Menschen, die es noch nicht aufgebaut haben.\n[KLICK] Die Frage ist also nicht, OB KI nützt oder schadet. Die Frage ist: WER profitiert und wer nicht?\n[KLICK] Die Antwort liegt in dem, was Experten von Lernenden unterscheidet."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#was-experten-sehen",
    "href": "slides/ai-higher-ed-short/index.html#was-experten-sehen",
    "title": "KI in der Hochschulbildung",
    "section": "Was Experten sehen",
    "text": "Was Experten sehen\n\n\n\n\n\n\nNovize: sieht Einzelteile\n“64 Felder, 32 Figuren, viele Möglichkeiten”\n. . .\nExperte: sieht Muster und Bedeutung\n“Sizilianische Verteidigung, Königsangriff möglich, Schwäche auf f7”\n. . .\n\nExperten speichern Wissen in Chunks: vernetzte Wissensstrukturen, die automatisch abgerufen werden (Groot und Groot 1978; Chase und Simon 1973).\n\n\nSchauen wir uns an, was Experten von Novizen unterscheidet. Das klassische Beispiel kommt aus der Schachforschung.\nWas sieht ein Novize? 64 Felder, 32 Figuren, viele Möglichkeiten. Er sieht die Einzelteile.\n[KLICK] Was sieht ein Experte? “Sizilianische Verteidigung, Königsangriff möglich, Schwäche auf f7.” Er sieht Muster und Bedeutung.\n[KLICK] Das ist der fundamentale Unterschied. Experten speichern Wissen in sogenannten “Chunks”: vernetzte Wissensstrukturen, die automatisch abgerufen werden.\nEin Schachmeister hat etwa 50.000 solcher Chunks im Langzeitgedächtnis. Die Forschung dazu geht auf de Groot zurück und wurde von Chase und Simon quantifiziert."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#der-expertise-umkehr-effekt",
    "href": "slides/ai-higher-ed-short/index.html#der-expertise-umkehr-effekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Expertise-Umkehr-Effekt",
    "text": "Der Expertise-Umkehr-Effekt\n\n Interaktiv: Klicke auf die Prozentwerte, um zu sehen, wie sich die optimale Lehrmethode je nach Vorwissen verändert.\n\n\nconfig = ({\n  // Color palette\n  colors: {\n    highSupport: \"#A3195B\",\n    lowSupport: \"#666666\",\n    neutral: \"#333\",\n    background: \"#f5f5f5\"\n  },\n  // Line equations: y = intercept + slope * x\n  // Lines cross where: highIntercept + highSlope*x = lowIntercept + lowSlope*x\n  lines: {\n    high: { intercept: 65, slope: -0.4 },\n    low: { intercept: 25, slope: 0.4 }\n  },\n  // Input options\n  steps: [0, 20, 40, 60, 80, 100],\n  defaultValue: 20,\n  // Plot dimensions\n  plot: {\n    width: 900,\n    height: 480,\n    margins: { left: 70, bottom: 60, top: 30, right: 40 }\n  },\n  // Labels\n  labels: {\n    highSupport: \"Hohe Unterstützung\",\n    lowSupport: \"Niedrige Unterstützung\",\n    highExamples: [\"📖 Worked Examples\", \"🧭 Direkte Instruktion\"],\n    lowExamples: [\"🧩 Problembasiertes Lernen\", \"🔍 Eigene Lösungswege\"]\n  }\n})\n\n// =============================================================================\n// Derived values: Computed from config (no magic numbers)\n// =============================================================================\n\n// Crossover point: solve for x where both lines intersect\ncrossoverPoint = {\n  const { high, low } = config.lines;\n  return (high.intercept - low.intercept) / (low.slope - high.slope);\n}\n\n// Helper function to calculate y-value on a line\ncalcY = (line, x) =&gt; line.intercept + line.slope * x\n\n// =============================================================================\n// State: Single source of truth for user input (hidden, controlled by buttons)\n// =============================================================================\nviewof vorwissen = {\n  const input = Inputs.radio(config.steps, {\n    value: config.defaultValue,\n    label: \"\",\n    format: x =&gt; x + \"%\"\n  });\n  input.style.display = \"none\";\n  return input;\n}\n\n// =============================================================================\n// Reactive calculations based on current state\n// =============================================================================\ncurrentState = {\n  const x = vorwissen ?? config.defaultValue;\n  const highY = calcY(config.lines.high, x);\n  const lowY = calcY(config.lines.low, x);\n  const isHighBetter = x &lt;= crossoverPoint;\n\n  return {\n    x,\n    highY,\n    lowY,\n    isHighBetter,\n    optimalY: isHighBetter ? highY : lowY,\n    suboptimalY: isHighBetter ? lowY : highY,\n    optimalLabel: isHighBetter ? config.labels.highSupport : config.labels.lowSupport,\n    optimalColor: isHighBetter ? config.colors.highSupport : config.colors.lowSupport,\n    suboptimalColor: isHighBetter ? config.colors.lowSupport : config.colors.highSupport\n  };\n}\n\n// =============================================================================\n// Plot: Visualization with all marks\n// =============================================================================\nexpertisePlot = {\n  const { colors, lines, plot, labels } = config;\n  const { x, highY, lowY, isHighBetter, optimalY, suboptimalY, optimalColor, suboptimalColor } = currentState;\n\n  // Generate line data points\n  const highLineData = [{x: 0, y: calcY(lines.high, 0)}, {x: 100, y: calcY(lines.high, 100)}];\n  const lowLineData = [{x: 0, y: calcY(lines.low, 0)}, {x: 100, y: calcY(lines.low, 100)}];\n\n  // Label positions (relative to line endpoints)\n  const labelOffsetY = 7;\n  const exampleBaseY = calcY(lines.high, 0) + labelOffsetY;\n\n  return Plot.plot({\n    width: plot.width,\n    height: plot.height,\n    marginLeft: plot.margins.left,\n    marginBottom: plot.margins.bottom,\n    marginTop: plot.margins.top,\n    marginRight: plot.margins.right,\n    style: { fontSize: \"16px\" },\n    x: {\n      domain: [0, 100],\n      label: \"Vorwissen →\",\n      labelOffset: 45,\n      ticks: [0, 50, 100],\n      tickFormat: d =&gt; d === 0 ? \"Niedrig\" : d === 50 ? \"Mittel\" : \"Hoch\"\n    },\n    y: {\n      domain: [0, 100],\n      label: \"↑ Lerneffekt\",\n      labelOffset: 50,\n      grid: true\n    },\n    marks: [\n      // Support lines\n      Plot.line(highLineData, {x: \"x\", y: \"y\", stroke: colors.highSupport, strokeWidth: 3}),\n      Plot.line(lowLineData, {x: \"x\", y: \"y\", stroke: colors.lowSupport, strokeWidth: 3}),\n\n      // Vertical position indicator\n      Plot.ruleX([x], {stroke: colors.neutral, strokeWidth: 1.5, strokeDasharray: \"8,5\"}),\n\n      // Suboptimal dot (smaller, faded)\n      Plot.dot([{x, y: suboptimalY}], {\n        x: \"x\", y: \"y\",\n        fill: suboptimalColor,\n        r: 8,\n        opacity: 0.4\n      }),\n\n      // Optimal dot (larger, prominent with white stroke)\n      Plot.dot([{x, y: optimalY}], {\n        x: \"x\", y: \"y\",\n        fill: optimalColor,\n        r: 14,\n        stroke: \"white\",\n        strokeWidth: 3\n      }),\n\n      // High support examples (left side, near line start)\n      Plot.text([{x: 15, y: exampleBaseY}], {\n        x: \"x\", y: \"y\", text: [labels.highExamples[0]], fill: colors.highSupport, fontSize: 13\n      }),\n      Plot.text([{x: 15, y: exampleBaseY - 6}], {\n        x: \"x\", y: \"y\", text: [labels.highExamples[1]], fill: colors.highSupport, fontSize: 13\n      }),\n\n      // Low support examples (right side)\n      Plot.text([{x: 85, y: exampleBaseY}], {\n        x: \"x\", y: \"y\", text: [labels.lowExamples[0]], fill: colors.lowSupport, fontSize: 13\n      }),\n      Plot.text([{x: 85, y: exampleBaseY - 6}], {\n        x: \"x\", y: \"y\", text: [labels.lowExamples[1]], fill: colors.lowSupport, fontSize: 13\n      }),\n\n      // Line labels (near line ends)\n      Plot.text([{x: 88, y: calcY(lines.high, 100) - 5}], {\n        x: \"x\", y: \"y\", text: [labels.highSupport], fill: colors.highSupport, fontSize: 15, fontWeight: \"bold\"\n      }),\n      Plot.text([{x: 12, y: calcY(lines.low, 0) - 5}], {\n        x: \"x\", y: \"y\", text: [labels.lowSupport], fill: colors.lowSupport, fontSize: 15, fontWeight: \"bold\"\n      })\n    ]\n  });\n}\n\n// =============================================================================\n// Button Group: Custom styled segmented control\n// =============================================================================\nbuttonGroup = {\n  const { x, optimalColor } = currentState;\n  const { colors, steps } = config;\n\n  const buttonStyle = (isSelected, selectColor) =&gt; `\n    padding: 12px 18px;\n    border: none;\n    background: ${isSelected ? selectColor : colors.background};\n    color: ${isSelected ? 'white' : '#333'};\n    font-size: 1em;\n    font-weight: ${isSelected ? 'bold' : 'normal'};\n    cursor: pointer;\n    border-right: 1px solid #ddd;\n    transition: background 0.15s ease;\n  `;\n\n  const container = html`&lt;div style=\"display: flex; border-radius: 8px; overflow: hidden; border: 2px solid #ddd;\"&gt;&lt;/div&gt;`;\n\n  steps.forEach(v =&gt; {\n    const isSelected = x === v;\n    const selectColor = v &lt;= crossoverPoint ? colors.highSupport : colors.lowSupport;\n    const btn = html`&lt;button style=\"${buttonStyle(isSelected, selectColor)}\"&gt;${v}%&lt;/button&gt;`;\n    btn.onclick = () =&gt; {\n      viewof vorwissen.value = v;\n      viewof vorwissen.dispatchEvent(new Event('input', {bubbles: true}));\n    };\n    container.appendChild(btn);\n  });\n\n  return container;\n}\n\n// =============================================================================\n// Layout: Compose all elements\n// =============================================================================\nhtml`&lt;div style=\"display: flex; align-items: center; gap: 40px;\"&gt;\n  &lt;div&gt;${expertisePlot}&lt;/div&gt;\n  &lt;div style=\"display: flex; flex-direction: column; align-items: center; gap: 20px; min-width: 280px;\"&gt;\n    &lt;div style=\"font-weight: bold; font-size: 1.1em;\"&gt;Vorwissen des Lernenden&lt;/div&gt;\n    &lt;div&gt;${buttonGroup}&lt;/div&gt;\n    &lt;div style=\"font-size: 1.3em; text-align: center; padding: 15px; background: ${currentState.optimalColor}22; border-radius: 8px; border-left: 4px solid ${currentState.optimalColor};\"&gt;\n      &lt;span style=\"color: ${currentState.optimalColor}; font-weight: bold;\"&gt;${currentState.optimalLabel}&lt;/span&gt;&lt;br&gt;\n      &lt;span style=\"font-size: 0.8em; color: #666;\"&gt;ist effektiver&lt;/span&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nDer Expertise-Umkehr-Effekt (Kalyuga 2009).\n\nDas bringt uns zu einem der wichtigsten Befunde der Instruktionsforschung: dem Expertise-Umkehr-Effekt.\nSie können die Prozent-Buttons anklicken, um zu sehen, wie sich die optimale Lehrmethode verändert.\nAuf der x-Achse sehen Sie das Vorwissen des Lernenden. Auf der y-Achse den Lerneffekt.\nDie magentafarbene Linie zeigt hohe Unterstützung: ausgearbeitete Beispiele, direkte Instruktion. Die graue Linie zeigt niedrige Unterstützung: problembasiertes Lernen, eigene Lösungswege.\nBei niedrigem Vorwissen ist hohe Unterstützung klar besser. Novizen brauchen Struktur.\nAber bei hohem Vorwissen kehrt sich der Effekt um. Für Experten ist niedrige Unterstützung besser. Die detaillierten Anleitungen werden redundant und stören sogar.\nDas ist der Expertise-Umkehr-Effekt: Was für Novizen optimal ist, ist für Experten suboptimal. Und umgekehrt."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#warum-experten-profitieren-lernende-nicht",
    "href": "slides/ai-higher-ed-short/index.html#warum-experten-profitieren-lernende-nicht",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Experten profitieren, Lernende nicht",
    "text": "Warum Experten profitieren, Lernende nicht\n\n\n\nExperten:\n\n\n Können Routine auslagern\n Können KI-Output bewerten\n Mehr Kapazität für Komplexes\n\n\nLernende:\n\n\n Können nicht bewerten\n Überspringen Grundlagen\n Risiko: “Fliessende Inkompetenz”\n\n\n\n\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.\n\nJetzt können wir zusammenfassen, warum Experten und Lernende so unterschiedlich von KI-Werkzeugen betroffen sind.\n[KLICK] Experten können Routine auslagern. Sie können KI-Output bewerten. Und sie haben mehr Kapazität für Komplexes.\n[KLICK] Lernende hingegen können KI-Output nicht bewerten. Sie überspringen möglicherweise Grundlagen. Und das Risiko ist “fliessende Inkompetenz”: Sie können mit Hilfe alles, ohne Hilfe nichts.\n[KLICK] Das Fazit: Dasselbe Werkzeug, fundamental unterschiedliche Auswirkungen."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#kritisches-denken-braucht-fachwissen",
    "href": "slides/ai-higher-ed-short/index.html#kritisches-denken-braucht-fachwissen",
    "title": "KI in der Hochschulbildung",
    "section": "Kritisches Denken braucht Fachwissen",
    "text": "Kritisches Denken braucht Fachwissen\n\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\nDaniel Willingham (Willingham 2008)\n\n\n\n\n\nBiomedizin-Experte:\nErkennt, wenn ChatGPT bei Biochemie falsch liegt\n\nNovize:\nKann diese Bewertung nicht vornehmen\n\n\n\n\nDu kannst nicht kritisch bewerten, was du nicht verstehst.\n\n\n\nWarum ist Fachwissen so entscheidend? Weil es bestimmt, ob KI deine Kognition erweitert oder ersetzt.\n\nAn diesem Punkt höre ich oft einen Einwand: “Dann bringen wir den Studierenden eben bei, KI-Output kritisch zu prüfen.”\nAber hier kommt ein wichtiger Punkt von Daniel Willingham: Kritisches Denken ist keine kontextfreie Fähigkeit. Man kann nicht einfach “kritisch denken lernen” und es dann überall anwenden.\n[KLICK] Ein Biomedizin-Experte erkennt, wenn ChatGPT bei Biochemie falsch liegt. Ein Novize kann diese Bewertung nicht vornehmen.\n[KLICK] Die Kernaussage: Du kannst nicht kritisch bewerten, was du nicht verstehst.\n[KLICK] Und genau deshalb ist Fachwissen so entscheidend."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#kognition-erweitern-vs.-ersetzen",
    "href": "slides/ai-higher-ed-short/index.html#kognition-erweitern-vs.-ersetzen",
    "title": "KI in der Hochschulbildung",
    "section": "Kognition erweitern vs. ersetzen",
    "text": "Kognition erweitern vs. ersetzen\n\n\n\n Kognition erweitern:\n\n\nMensch bleibt kognitiv engagiert\nWerkzeug verstärkt, ersetzt nicht\nFähigkeiten bleiben erhalten\n\n\n Kognition ersetzen:\n\n\nMensch wird passiv\nWerkzeug übernimmt das Denken\nAbhängigkeit entsteht\n\n\n\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung (Clark 2025).\n\nAndy Clark, ein Philosoph, hat eine nützliche Unterscheidung eingeführt.\n[KLICK] Kognition erweitern: Der Mensch bleibt kognitiv engagiert. Das Werkzeug verstärkt, ersetzt nicht. Die Fähigkeiten bleiben erhalten.\n[KLICK] Kognition ersetzen: Der Mensch wird passiv. Das Werkzeug übernimmt das Denken. Es entsteht Abhängigkeit.\n[KLICK] Und hier ist der wichtige Punkt: Dasselbe Werkzeug kann beides sein, abhängig von der Nutzung.\nChatGPT kann ein Brainstorming-Partner sein, der die eigene Kreativität verstärkt. Oder es kann ein Ghostwriter sein, der das Denken ersetzt. Die Frage ist nicht das Werkzeug. Die Frage ist die Nutzung."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-sequenzierungsfrage",
    "href": "slides/ai-higher-ed-short/index.html#die-sequenzierungsfrage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Sequenzierungsfrage",
    "text": "Die Sequenzierungsfrage\n\n\nNovize ——— Schwelle? ——— Experte\n\n\nDie Schwelle ist unbekannt und empirisch nicht bestimmt\nSie variiert nach Domäne und Person\nDer Expertise-Umkehr-Effekt erfordert dynamische KI-Nutzungsempfehlungen\n\n\n\n\nWer profitiert von KI-Werkzeugen? Wer nicht?\n\n\nDas bringt uns zur praktischen Frage: Wenn Experten profitieren und Lernende Gefahr laufen, wann ist der Übergang?\nLinks der Novize, rechts der Experte. Irgendwo dazwischen liegt eine Schwelle.\n[KLICK] Das Problem ist: Diese Schwelle ist unbekannt.\n[KLICK] Sie variiert nach Domäne und Person.\n[KLICK] Der Expertise-Umkehr-Effekt erfordert dynamische Empfehlungen.\n[KLICK] Die praktische Frage: Wer profitiert von KI-Werkzeugen? Und wer nicht? Diese Frage können wir nicht pauschal beantworten."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#die-kernaussage",
    "href": "slides/ai-higher-ed-short/index.html#die-kernaussage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Kernaussage",
    "text": "Die Kernaussage\n\n\nKI-Werkzeuge sind für Experten gemacht.\n\n\n\n\n\nSie machen Experten produktiver.\n\n\nLernende profitieren oft nicht, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.\n\n\n\n\n\nLernende brauchen erst das Fundament, das kritische KI-Nutzung ermöglicht.\n\n\n[Pause, dann KLICK] KI-Werkzeuge sind für Experten gemacht.\n[KLICK] Das ist keine Wertung, sondern eine Feststellung. Diese Werkzeuge wurden von Experten entwickelt und funktionieren am besten für Menschen, die bereits wissen, was sie tun.\nSie machen Experten produktiver.\n[KLICK] Aber: Lernende profitieren oft nicht. Lernen erfordert genau die kognitive Anstrengung, die KI zu eliminieren droht.\nDas ist nicht KI-Feindlichkeit. Lernen braucht Anstrengung. KI kann diese Anstrengung reduzieren, wenn sie passiv genutzt wird. Aber: Es ist nicht unvermeidlich. Erinnern Sie sich an den GPT-Tutor? Die Art der Nutzung entscheidet.\n[KLICK] Die Konsequenz: Lernende brauchen erst das Fundament, das kritische KI-Nutzung ermöglicht. Nicht “keine KI”, aber “Fundament zuerst”."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#was-bedeutet-das-für-die-lehre",
    "href": "slides/ai-higher-ed-short/index.html#was-bedeutet-das-für-die-lehre",
    "title": "KI in der Hochschulbildung",
    "section": "Was bedeutet das für die Lehre?",
    "text": "Was bedeutet das für die Lehre?\n\n\n\n\n\nAnstrengung ist das Signal\n\n\n\nKI als Tutor, nicht als Antwortgeber\n\n\n\nExpertise bestimmt den Nutzen\n\n\n\n\nWenn Lernen sich zu leicht anfühlt, findet es wahrscheinlich nicht statt.\n\nKI soll Denkprozesse anregen, nicht ersetzen.\n\nDasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.\n\n\n\n\nGrundlagen BEVOR Werkzeuge\n\nZum Abschluss: Was bedeutet das konkret für unsere Lehre?\n[KLICK] Erstens: Anstrengung ist das Signal. Wenn Lernen sich zu leicht anfühlt, findet es wahrscheinlich nicht statt.\n[KLICK] Zweitens: KI als Tutor, nicht als Antwortgeber. KI soll Denkprozesse anregen, nicht ersetzen.\n[KLICK] Drittens: Expertise bestimmt den Nutzen. Dasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.\n[KLICK] Und die Zusammenfassung: Grundlagen BEVOR Werkzeuge.\nErst das Fundament, dann die Erweiterung. Erst verstehen, dann automatisieren. Erst selbst können, dann delegieren.\nVielen Dank."
  },
  {
    "objectID": "slides/ai-higher-ed-short/index.html#referenzen",
    "href": "slides/ai-higher-ed-short/index.html#referenzen",
    "title": "KI in der Hochschulbildung",
    "section": "Referenzen",
    "text": "Referenzen\n\n\nBastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, und Rei Mariman. 2025. „Generative AI Without Guardrails Can Harm Learning: Evidence from High School Mathematics“. Proceedings of the National Academy of Sciences of the United States of America 122 (26): e2422633122. https://doi.org/10.1073/pnas.2422633122.\n\n\nBjork, Elizabeth Ligon, und Robert A. Bjork. 2011. „Making Things Hard on Yourself, but in a Good Way: Creating Desirable Difficulties to Enhance Learning“. In Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society, 56–64. New York, NY, US: Worth Publishers.\n\n\nChase, William G., und Herbert A. Simon. 1973. „Perception in Chess“. Cognitive Psychology 4 (1): 55–81. https://doi.org/10.1016/0010-0285(73)90004-2.\n\n\nClark, Andy. 2025. „Extending Minds with Generative AI“. Nature Communications 16 (1): 4627. https://doi.org/10.1038/s41467-025-59906-9.\n\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nGroot, Adriaan D. De, und Adrianus Dingeman de Groot. 1978. Thought and Choice in Chess. Walter de Gruyter. https://books.google.com?id=EI4gr42NwDQC.\n\n\nKalyuga, Slava. 2009. „The Expertise Reversal Effect“. In Managing Cognitive Load in Adaptive Multimedia Learning, 58–80. IGI Global Scientific Publishing. https://doi.org/10.4018/978-1-60566-048-6.ch003.\n\n\nSlamecka, Norman J., und Peter Graf. 1978. „The Generation Effect: Delineation of a Phenomenon“. Journal of Experimental Psychology: Human Learning and Memory 4 (6): 592–604. https://doi.org/10.1037/0278-7393.4.6.592.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745.\n\n\nSweller, John. 2024. „Cognitive Load Theory and Individual Differences“. Learning and Individual Differences 110 (Februar): 102423. https://doi.org/10.1016/j.lindif.2024.102423.\n\n\nWillingham, Daniel T. 2008. „Critical Thinking: Why Is It So Hard to Teach?“ Arts Education Policy Review 109 (4): 21–32. https://doi.org/10.3200/AEPR.109.4.21-32."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KI in der Lehre: Refresher",
    "section": "",
    "text": "Diese Seite begleitet die Präsentation zum aktuellen Stand von KI in der Hochschulbildung.\n\n\n\nPräsentation: Slides zum Workshop (Voll- und Kurzversion)\nLeitfaden: Vertiefende Informationen zu KI in der Hochschulbildung\nQ & A: Fragen, Antworten und weiterführende Ressourcen"
  },
  {
    "objectID": "index.html#willkommen",
    "href": "index.html#willkommen",
    "title": "KI in der Lehre: Refresher",
    "section": "",
    "text": "Diese Seite begleitet die Präsentation zum aktuellen Stand von KI in der Hochschulbildung.\n\n\n\nPräsentation: Slides zum Workshop (Voll- und Kurzversion)\nLeitfaden: Vertiefende Informationen zu KI in der Hochschulbildung\nQ & A: Fragen, Antworten und weiterführende Ressourcen"
  },
  {
    "objectID": "index.html#kontakt",
    "href": "index.html#kontakt",
    "title": "KI in der Lehre: Refresher",
    "section": "Kontakt",
    "text": "Kontakt\nDr. Andrew Ellis ist Kognitionspsychologe und Wissenschaftlicher Mitarbeiter an der Virtuellen Akademie der Berner Fachhochschule. Er erforscht, wie künstliche Intelligenz in Bildungssystemen wirkungsvoll eingesetzt werden kann."
  },
  {
    "objectID": "presentation/index.html",
    "href": "presentation/index.html",
    "title": "Präsentation",
    "section": "",
    "text": "Fokussierter Vortrag (30 Min) mit anschliessender Diskussion (30 Min).\n    Folien in neuem Tab öffnen\n       \n      \n    \n  \n\n\nNutze die Pfeiltasten oder die Leertaste um durch die Präsentation zu navigieren. Drücke F für Vollbild.\n\nVertiefung\nFür eine umfassende Behandlung aller Konzepte, Beispiele und theoretischen Hintergründe siehe den Leitfaden.\n\nWeiterbildungsangebot\nDieser Refresher bietet einen kompakten Überblick über den aktuellen Forschungsstand und die lernwissenschaftlichen Grundlagen. Die BFH bietet drei aufbauende Kurse an, die diese Themen vertiefen:\nKI in der Lehre: Beginner: Grundlagen zu Sprachmodellen und Chatbots.\nKI in der Lehre: Intermediate: Lernpsychologie und KI-gestütztes Lerndesign.\nKI in der Lehre: Advanced: Workshop zur Entwicklung eines eigenen KI-gestützten Lerntools.\n\n\n\n\n\n\n Zurück nach oben"
  },
  {
    "objectID": "presentation/index.html#ki-in-der-hochschulbildung",
    "href": "presentation/index.html#ki-in-der-hochschulbildung",
    "title": "Präsentation",
    "section": "",
    "text": "Fokussierter Vortrag (30 Min) mit anschliessender Diskussion (30 Min).\n\n\n\n\n\n\n\n\nTippNavigation\n\n\n\nNutze die Pfeiltasten oder klicke auf die Slides, um durch die Präsentation zu navigieren. Drücke F für Vollbild.\n\n\n\n\nFür eine umfassende Behandlung aller Konzepte, Beispiele und theoretischen Hintergründe siehe den Leitfaden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-zentrale-frage",
    "href": "slides/ai-higher-ed/index.html#die-zentrale-frage",
    "title": "KI in der Hochschulbildung",
    "section": "Die zentrale Frage",
    "text": "Die zentrale Frage\n\n\nWas KI kann:\n\nAnwaltsprüfungen bestehen\nCode schreiben und debuggen\nKrankheiten diagnostizieren\nWissenschaftliche Texte verfassen\nKomplexe Analysen durchführen\n\n\nAber was bedeutet das für Lernen?\n\nMit KI → 48% mehr Aufgaben gelöst\nOhne KI → 17% schlechter an der Prüfung\n\n(Bastani u. a. 2025)\n\n\nDie Frage ist nicht ob KI hilft, sondern: Wann hilft sie, und wann schadet sie?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#wie-llms-text-produzieren",
    "href": "slides/ai-higher-ed/index.html#wie-llms-text-produzieren",
    "title": "KI in der Hochschulbildung",
    "section": "Wie LLMs Text produzieren",
    "text": "Wie LLMs Text produzieren\n\nNext-word prediction: Welches Wort kommt am wahrscheinlichsten als nächstes?\nTraining auf Milliarden von Textdokumenten\nErkennen von Mustern in Sprache, Argumentation, Stil\nMetapher: Extrem ausgeklügelte Autovervollständigung\n\n\n\n\n\n\n\n\nWichtig\n\n\nLLMs rufen kein Wissen ab. Sie generieren Text basierend auf statistischen Mustern."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#wie-denken-in-ki-funktioniert",
    "href": "slides/ai-higher-ed/index.html#wie-denken-in-ki-funktioniert",
    "title": "KI in der Hochschulbildung",
    "section": "Wie “Denken” in KI funktioniert",
    "text": "Wie “Denken” in KI funktioniert\nChain-of-Thought Reasoning:\n\n\nOhne Reasoning:\n“Was ist 17 × 24?” → “408”\n\nMit Reasoning:\n“Was ist 17 × 24?” → “Lass mich das aufteilen: 17 × 20 = 340 17 × 4 = 68 340 + 68 = 408”\n\n\nKernpunkt: Immer noch Mustererkennung, aber über Denkschritte statt nur über Antworten."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#werkzeug-fähige-agenten",
    "href": "slides/ai-higher-ed/index.html#werkzeug-fähige-agenten",
    "title": "KI in der Hochschulbildung",
    "section": "Werkzeug-fähige Agenten",
    "text": "Werkzeug-fähige Agenten\nLLM + Werkzeuge = Agent\n\nWebsuche durchführen\nCode ausführen\nDateien lesen und schreiben\nBerechnungen anstellen\nAPIs aufrufen\n\n\nKonsequenz: Agenten können fast jede kognitive Aufgabe ausführen:\n\nLiteraturrecherche\nDatenanalyse\nSchreiben und Überarbeiten\nProgrammieren"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion",
    "href": "slides/ai-higher-ed/index.html#diskussion",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion",
    "text": "Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nKurze Diskussion\n\n\n\nWelche KI-Fähigkeiten haben dich überrascht?\nWo hast du Studierende beim Einsatz von KI beobachtet?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#experten-und-novizen-sind-grundlegend-verschieden",
    "href": "slides/ai-higher-ed/index.html#experten-und-novizen-sind-grundlegend-verschieden",
    "title": "KI in der Hochschulbildung",
    "section": "Experten und Novizen sind grundlegend verschieden",
    "text": "Experten und Novizen sind grundlegend verschieden\n\n\nNicht nur “mehr Wissen”\nSondern eine andere kognitive Architektur\n\nKlassisches Beispiel: (Groot und Groot 1978; Chase und Simon 1973)\nSchachmeister sehen Muster und Strategien\nAnfänger sehen Figuren auf Feldern\n\n\n\n“Experts don’t just know more; they organize knowledge differently.”"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#von-schwachen-zu-starken-methoden",
    "href": "slides/ai-higher-ed/index.html#von-schwachen-zu-starken-methoden",
    "title": "KI in der Hochschulbildung",
    "section": "Von schwachen zu starken Methoden",
    "text": "Von schwachen zu starken Methoden\nNewell & Simon (Newell und Simon 1972) | ACT-R (Anderson 1982)\n\n\nNovizen: Schwache Methoden\n\nMittel-Ziel-Analyse\nVersuch und Irrtum\nAnalogiebildung\nRückwärtsarbeiten\n\n\nExperten: Starke Methoden\n\nAutomatische Mustererkennung\nProzeduralisiertes Wissen\nDirekte Lösungswege\n\n\n\nDer Übergang erfordert umfangreiche Übung."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#prozeduralisierung-und-kompilation",
    "href": "slides/ai-higher-ed/index.html#prozeduralisierung-und-kompilation",
    "title": "KI in der Hochschulbildung",
    "section": "Prozeduralisierung und Kompilation",
    "text": "Prozeduralisierung und Kompilation\n\nDeklaratives Wissen: “Man muss beim Autofahren die Kupplung treten, bevor man schaltet”\nBewusste Schritte: Aktiv an jeden Schritt denken\nProzeduralisierung: Schritte werden zu Einheiten zusammengefasst\nAutomatisierung: Unbewusste, flüssige Ausführung\n\n\nDiese Transformation kann nicht übersprungen werden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#cognitive-load-theory-die-grundlagen",
    "href": "slides/ai-higher-ed/index.html#cognitive-load-theory-die-grundlagen",
    "title": "KI in der Hochschulbildung",
    "section": "Cognitive Load Theory: Die Grundlagen",
    "text": "Cognitive Load Theory: Die Grundlagen\nJohn Sweller (Sweller 2024)\n\n\nArbeitsgedächtnis\n\n4±1 Elemente\n15-30 Sekunden\nDer Engpass allen Lernens\n\n\nLangzeitgedächtnis\n\nUnbegrenzte Kapazität\nDauerhafte Speicherung\nHier lebt Expertise\n\n\n\n\n\n\n\n\n\nKernaussage\n\n\nAlles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#drei-arten-kognitiver-belastung",
    "href": "slides/ai-higher-ed/index.html#drei-arten-kognitiver-belastung",
    "title": "KI in der Hochschulbildung",
    "section": "Drei Arten kognitiver Belastung",
    "text": "Drei Arten kognitiver Belastung\n\n\n\n\n\n\n\n\nTyp\nBeschreibung\nZiel\n\n\n\n\nIntrinsisch\nInhärente Komplexität des Materials\nKann nicht reduziert werden ohne Vereinfachung\n\n\nExtrinsisch\nSchlecht gestaltete Instruktion\nMinimieren\n\n\nLernförderlich (Germane)\nProduktive Anstrengung für Schemabildung\nErhalten\n\n\n\n(Anmerkung: Die Unterscheidung von lernförderlicher und intrinsischer Belastung ist in der Literatur umstritten)\n\nEntscheidende Frage: Welche Art der Belastung reduziert KI?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-expertise-umkehr-effekt",
    "href": "slides/ai-higher-ed/index.html#der-expertise-umkehr-effekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Expertise-Umkehr-Effekt",
    "text": "Der Expertise-Umkehr-Effekt\n\n Interaktiv: Klicke auf die Prozentwerte, um zu sehen, wie sich die optimale Lehrmethode je nach Vorwissen verändert.\n\n\nconfig = ({\n  // Color palette\n  colors: {\n    highSupport: \"#A3195B\",\n    lowSupport: \"#666666\",\n    neutral: \"#333\",\n    background: \"#f5f5f5\"\n  },\n  // Line equations: y = intercept + slope * x\n  // Lines cross where: highIntercept + highSlope*x = lowIntercept + lowSlope*x\n  lines: {\n    high: { intercept: 65, slope: -0.4 },\n    low: { intercept: 25, slope: 0.4 }\n  },\n  // Input options\n  steps: [0, 20, 40, 60, 80, 100],\n  defaultValue: 20,\n  // Plot dimensions\n  plot: {\n    width: 900,\n    height: 480,\n    margins: { left: 70, bottom: 60, top: 30, right: 40 }\n  },\n  // Labels\n  labels: {\n    highSupport: \"Hohe Unterstützung\",\n    lowSupport: \"Niedrige Unterstützung\",\n    highExamples: [\"📖 Worked Examples\", \"🧭 Direkte Instruktion\"],\n    lowExamples: [\"🧩 Problembasiertes Lernen\", \"🔍 Eigene Lösungswege\"]\n  }\n})\n\n// =============================================================================\n// Derived values: Computed from config (no magic numbers)\n// =============================================================================\n\n// Crossover point: solve for x where both lines intersect\ncrossoverPoint = {\n  const { high, low } = config.lines;\n  return (high.intercept - low.intercept) / (low.slope - high.slope);\n}\n\n// Helper function to calculate y-value on a line\ncalcY = (line, x) =&gt; line.intercept + line.slope * x\n\n// =============================================================================\n// State: Single source of truth for user input (hidden, controlled by buttons)\n// =============================================================================\nviewof vorwissen = {\n  const input = Inputs.radio(config.steps, {\n    value: config.defaultValue,\n    label: \"\",\n    format: x =&gt; x + \"%\"\n  });\n  input.style.display = \"none\";\n  return input;\n}\n\n// =============================================================================\n// Reactive calculations based on current state\n// =============================================================================\ncurrentState = {\n  const x = vorwissen ?? config.defaultValue;\n  const highY = calcY(config.lines.high, x);\n  const lowY = calcY(config.lines.low, x);\n  const isHighBetter = x &lt;= crossoverPoint;\n\n  return {\n    x,\n    highY,\n    lowY,\n    isHighBetter,\n    optimalY: isHighBetter ? highY : lowY,\n    suboptimalY: isHighBetter ? lowY : highY,\n    optimalLabel: isHighBetter ? config.labels.highSupport : config.labels.lowSupport,\n    optimalColor: isHighBetter ? config.colors.highSupport : config.colors.lowSupport,\n    suboptimalColor: isHighBetter ? config.colors.lowSupport : config.colors.highSupport\n  };\n}\n\n// =============================================================================\n// Plot: Visualization with all marks\n// =============================================================================\nexpertisePlot = {\n  const { colors, lines, plot, labels } = config;\n  const { x, highY, lowY, isHighBetter, optimalY, suboptimalY, optimalColor, suboptimalColor } = currentState;\n\n  // Generate line data points\n  const highLineData = [{x: 0, y: calcY(lines.high, 0)}, {x: 100, y: calcY(lines.high, 100)}];\n  const lowLineData = [{x: 0, y: calcY(lines.low, 0)}, {x: 100, y: calcY(lines.low, 100)}];\n\n  // Label positions (relative to line endpoints)\n  const labelOffsetY = 7;\n  const exampleBaseY = calcY(lines.high, 0) + labelOffsetY;\n\n  return Plot.plot({\n    width: plot.width,\n    height: plot.height,\n    marginLeft: plot.margins.left,\n    marginBottom: plot.margins.bottom,\n    marginTop: plot.margins.top,\n    marginRight: plot.margins.right,\n    style: { fontSize: \"16px\" },\n    x: {\n      domain: [0, 100],\n      label: \"Vorwissen →\",\n      labelOffset: 45,\n      ticks: [0, 50, 100],\n      tickFormat: d =&gt; d === 0 ? \"Niedrig\" : d === 50 ? \"Mittel\" : \"Hoch\"\n    },\n    y: {\n      domain: [0, 100],\n      label: \"↑ Lerneffekt\",\n      labelOffset: 50,\n      grid: true\n    },\n    marks: [\n      // Support lines\n      Plot.line(highLineData, {x: \"x\", y: \"y\", stroke: colors.highSupport, strokeWidth: 3}),\n      Plot.line(lowLineData, {x: \"x\", y: \"y\", stroke: colors.lowSupport, strokeWidth: 3}),\n\n      // Vertical position indicator\n      Plot.ruleX([x], {stroke: colors.neutral, strokeWidth: 1.5, strokeDasharray: \"8,5\"}),\n\n      // Suboptimal dot (smaller, faded)\n      Plot.dot([{x, y: suboptimalY}], {\n        x: \"x\", y: \"y\",\n        fill: suboptimalColor,\n        r: 8,\n        opacity: 0.4\n      }),\n\n      // Optimal dot (larger, prominent with white stroke)\n      Plot.dot([{x, y: optimalY}], {\n        x: \"x\", y: \"y\",\n        fill: optimalColor,\n        r: 14,\n        stroke: \"white\",\n        strokeWidth: 3\n      }),\n\n      // High support examples (left side, near line start)\n      Plot.text([{x: 15, y: exampleBaseY}], {\n        x: \"x\", y: \"y\", text: [labels.highExamples[0]], fill: colors.highSupport, fontSize: 13\n      }),\n      Plot.text([{x: 15, y: exampleBaseY - 6}], {\n        x: \"x\", y: \"y\", text: [labels.highExamples[1]], fill: colors.highSupport, fontSize: 13\n      }),\n\n      // Low support examples (right side)\n      Plot.text([{x: 85, y: exampleBaseY}], {\n        x: \"x\", y: \"y\", text: [labels.lowExamples[0]], fill: colors.lowSupport, fontSize: 13\n      }),\n      Plot.text([{x: 85, y: exampleBaseY - 6}], {\n        x: \"x\", y: \"y\", text: [labels.lowExamples[1]], fill: colors.lowSupport, fontSize: 13\n      }),\n\n      // Line labels (near line ends)\n      Plot.text([{x: 88, y: calcY(lines.high, 100) - 5}], {\n        x: \"x\", y: \"y\", text: [labels.highSupport], fill: colors.highSupport, fontSize: 15, fontWeight: \"bold\"\n      }),\n      Plot.text([{x: 12, y: calcY(lines.low, 0) - 5}], {\n        x: \"x\", y: \"y\", text: [labels.lowSupport], fill: colors.lowSupport, fontSize: 15, fontWeight: \"bold\"\n      })\n    ]\n  });\n}\n\n// =============================================================================\n// Button Group: Custom styled segmented control\n// =============================================================================\nbuttonGroup = {\n  const { x, optimalColor } = currentState;\n  const { colors, steps } = config;\n\n  const buttonStyle = (isSelected, selectColor) =&gt; `\n    padding: 12px 18px;\n    border: none;\n    background: ${isSelected ? selectColor : colors.background};\n    color: ${isSelected ? 'white' : '#333'};\n    font-size: 1em;\n    font-weight: ${isSelected ? 'bold' : 'normal'};\n    cursor: pointer;\n    border-right: 1px solid #ddd;\n    transition: background 0.15s ease;\n  `;\n\n  const container = html`&lt;div style=\"display: flex; border-radius: 8px; overflow: hidden; border: 2px solid #ddd;\"&gt;&lt;/div&gt;`;\n\n  steps.forEach(v =&gt; {\n    const isSelected = x === v;\n    const selectColor = v &lt;= crossoverPoint ? colors.highSupport : colors.lowSupport;\n    const btn = html`&lt;button style=\"${buttonStyle(isSelected, selectColor)}\"&gt;${v}%&lt;/button&gt;`;\n    btn.onclick = () =&gt; {\n      viewof vorwissen.value = v;\n      viewof vorwissen.dispatchEvent(new Event('input', {bubbles: true}));\n    };\n    container.appendChild(btn);\n  });\n\n  return container;\n}\n\n// =============================================================================\n// Layout: Compose all elements\n// =============================================================================\nhtml`&lt;div style=\"display: flex; align-items: center; gap: 40px;\"&gt;\n  &lt;div&gt;${expertisePlot}&lt;/div&gt;\n  &lt;div style=\"display: flex; flex-direction: column; align-items: center; gap: 20px; min-width: 280px;\"&gt;\n    &lt;div style=\"font-weight: bold; font-size: 1.1em;\"&gt;Vorwissen des Lernenden&lt;/div&gt;\n    &lt;div&gt;${buttonGroup}&lt;/div&gt;\n    &lt;div style=\"font-size: 1.3em; text-align: center; padding: 15px; background: ${currentState.optimalColor}22; border-radius: 8px; border-left: 4px solid ${currentState.optimalColor};\"&gt;\n      &lt;span style=\"color: ${currentState.optimalColor}; font-weight: bold;\"&gt;${currentState.optimalLabel}&lt;/span&gt;&lt;br&gt;\n      &lt;span style=\"font-size: 0.8em; color: #666;\"&gt;ist effektiver&lt;/span&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nDer Expertise-Umkehr-Effekt (Kalyuga 2009).\n\nDas bringt uns zu einem der wichtigsten Befunde der Instruktionsforschung: dem Expertise-Umkehr-Effekt.\nSie können die Prozent-Buttons anklicken, um zu sehen, wie sich die optimale Lehrmethode verändert.\nAuf der x-Achse sehen Sie das Vorwissen des Lernenden. Auf der y-Achse den Lerneffekt.\nDie magentafarbene Linie zeigt hohe Unterstützung: ausgearbeitete Beispiele, direkte Instruktion. Die graue Linie zeigt niedrige Unterstützung: problembasiertes Lernen, eigene Lösungswege.\nBei niedrigem Vorwissen ist hohe Unterstützung klar besser. Novizen brauchen Struktur.\nAber bei hohem Vorwissen kehrt sich der Effekt um. Für Experten ist niedrige Unterstützung besser. Die detaillierten Anleitungen werden redundant und stören sogar.\nDas ist der Expertise-Umkehr-Effekt: Was für Novizen optimal ist, ist für Experten suboptimal. Und umgekehrt."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#explizite-instruktion-was-lernen-fördert",
    "href": "slides/ai-higher-ed/index.html#explizite-instruktion-was-lernen-fördert",
    "title": "KI in der Hochschulbildung",
    "section": "Explizite Instruktion: Was Lernen fördert",
    "text": "Explizite Instruktion: Was Lernen fördert\nDas Problem mit minimaler Anleitung (Kirschner, und and Clark 2006)\n\nKonstruktivistische, entdeckende Ansätze klingen attraktiv\nAber: Für Novizen ist minimale Anleitung weniger effektiv\nNovizen haben keine Schemata im Langzeitgedächtnis\nIhr Arbeitsgedächtnis wird schnell überlastet\n\n\nEvidenzbasierte Alternative: Explizite Instruktion mit Worked Examples"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#worked-examples-ein-robuster-befund",
    "href": "slides/ai-higher-ed/index.html#worked-examples-ein-robuster-befund",
    "title": "KI in der Hochschulbildung",
    "section": "Worked Examples: Ein robuster Befund",
    "text": "Worked Examples: Ein robuster Befund\nStatt Probleme selbst lösen: Ausgearbeitete Lösungswege zeigen (Cooper und Sweller 1987)\n\n\nFür Novizen:\n\nReduziert extrinsische Belastung\nLässt Kapazität für Schemabildung\nEiner der robustesten Befunde der Instruktionsforschung\n\n\nAber Achtung:\nWorked Examples ≠ KI-generierte Lösungen\n\n\n\n\n\n\n\n\nDer entscheidende Unterschied\n\n\nWorked Examples sind didaktisch gestaltet, heben relevante Schritte hervor, bauen systematisch Komplexität auf und werden von Lehrenden ausgewählt.\nKI-generierte Antworten beantworten die gestellte Frage, aber ohne Einbettung in eine geplante Lernprogression.\n\n\n\n\n\n\n\n\n\n\n\nNuance\n\n\nLLMs können mit entsprechendem Prompting didaktisch strukturierte Erklärungen liefern, aber das erfordert pädagogisches Wissen, das Novizen typischerweise nicht haben."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#von-worked-examples-zu-selbständigem-lösen",
    "href": "slides/ai-higher-ed/index.html#von-worked-examples-zu-selbständigem-lösen",
    "title": "KI in der Hochschulbildung",
    "section": "Von Worked Examples zu selbständigem Lösen",
    "text": "Von Worked Examples zu selbständigem Lösen\nFading: Unterstützung systematisch reduzieren\n\nVollständige Worked Examples zeigen\nCompletion Problems: Teilweise gelöste Aufgaben vervollständigen\nZunehmend weniger Vorgaben\nSelbständiges Lösen ohne Unterstützung\n\n\nVerbindung zum Expertise-Umkehr-Effekt:\nWas Novizen hilft, kann Experten behindern. Daher: dynamische Anpassung."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion-think-pair-share",
    "href": "slides/ai-higher-ed/index.html#diskussion-think-pair-share",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion: Think-Pair-Share",
    "text": "Diskussion: Think-Pair-Share\n                    \n                    \n                \n\n\n\n\n\n\nReflexion\n\n\nThink: Denke an eine Fähigkeit, die du gemeistert hast. Wie hat sich der Lernprozess angefühlt?\nPair: Tausche dich mit deinem Nachbarn aus.\nShare: Wie hat sich dein Denken verändert, als du Experte wurdest?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-traditionelle-annahme",
    "href": "slides/ai-higher-ed/index.html#die-traditionelle-annahme",
    "title": "KI in der Hochschulbildung",
    "section": "Die traditionelle Annahme",
    "text": "Die traditionelle Annahme\n\nKritisches Denken als übertragbare Fähigkeit\n“21st Century Skills”-Initiativen\nKI-Kompetenz als generische Fertigkeit\n“Wir müssen Studierende lehren, KI kritisch zu nutzen”\n\n\nAber stimmt diese Annahme?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#willinghams-herausforderung",
    "href": "slides/ai-higher-ed/index.html#willinghams-herausforderung",
    "title": "KI in der Hochschulbildung",
    "section": "Willinghams Herausforderung",
    "text": "Willinghams Herausforderung\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n(Willingham 2008)\n\n\nDenkprozesse sind eng mit Fachwissen verflochten.\nWillinghams Formulierung ist zugespitzt — aber der Kern stimmt: Transfer ist schwieriger als oft angenommen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#evidenz-für-domänenspezifität",
    "href": "slides/ai-higher-ed/index.html#evidenz-für-domänenspezifität",
    "title": "KI in der Hochschulbildung",
    "section": "Evidenz für Domänenspezifität",
    "text": "Evidenz für Domänenspezifität\n\nNeurologen können Herzerkrankungen nicht gut diagnostizieren\nFachredakteure können keine Zeitungsartikel schreiben\nSelbst Philosophen werden von irrelevanten Merkmalen beeinflusst\n\n\n\n“Abstract principles like ‘look for hidden assumptions’ won’t help much in evaluating an argument about a topic you know little about.”"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#angewendet-auf-ki-bewertung",
    "href": "slides/ai-higher-ed/index.html#angewendet-auf-ki-bewertung",
    "title": "KI in der Hochschulbildung",
    "section": "Angewendet auf KI-Bewertung",
    "text": "Angewendet auf KI-Bewertung\n\n\nExperte in Biomedizin:\nErkennt, wenn ChatGPT bei Biochemie falsch liegt\nHat das Domänenwissen zur Bewertung\n\nNovize:\nKann diese Bewertung nicht vornehmen, unabhängig von “kritischem Denken”\nFehlendes Fachwissen verhindert Evaluation\n\n\nWas wie “kritisches Denken” aussieht, ist oft Domänenwissen in Aktion."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-transferiert-und-was-nicht",
    "href": "slides/ai-higher-ed/index.html#was-transferiert-und-was-nicht",
    "title": "KI in der Hochschulbildung",
    "section": "Was transferiert — und was nicht",
    "text": "Was transferiert — und was nicht\n\n\nTransferiert (teilweise):\n\nPlanung des Vorgehens\nÜberwachung des Verständnisses\nSelbstregulation\nBereitschaft, Annahmen zu hinterfragen\n\nMetakognitive Strategien zeigen gewisse Generalisierung\n\nTransferiert kaum:\n\nWissen, was plausibel ist\nWissen, welche Quellen autoritativ sind\nErkennen von fachspezifischen Fehlern\n\nInhaltliche Bewertung erfordert Domänenwissen\n\n\nKernpunkt: Die Strategien kann man lehren — ihre Anwendung erfordert Fachwissen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-zentrale-implikation",
    "href": "slides/ai-higher-ed/index.html#die-zentrale-implikation",
    "title": "KI in der Hochschulbildung",
    "section": "Die zentrale Implikation",
    "text": "Die zentrale Implikation\n\n\n\n\n\n\nKernaussage\n\n\n\nStudierende, die “mit hohem kritischem Denken” von KI profitieren, haben wahrscheinlich mehr Domänenexpertise\nDie beste Vorbereitung für kritische KI-Nutzung ist tiefes Fachlernen\nGenerische “KI-Kompetenz” kann Fachwissen ergänzen, aber nicht ersetzen"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion-1",
    "href": "slides/ai-higher-ed/index.html#diskussion-1",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion",
    "text": "Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nKurze Diskussion\n\n\n\nHast du beobachtet, dass Studierende KI-Outputs in deinem Fach nicht bewerten können?\nWelches Domänenwissen wäre nötig?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-zentrale-paradox",
    "href": "slides/ai-higher-ed/index.html#das-zentrale-paradox",
    "title": "KI in der Hochschulbildung",
    "section": "Das zentrale Paradox",
    "text": "Das zentrale Paradox\n\n“Learning and task completion are not synonymous.”\n(Jose u. a. 2025)\n\n\n\n\nKI verbessert nachweislich:\n\nAufgabenleistung\nGeschwindigkeit\nOutput-Qualität\n\n\nAber:\nAufgabenleistung ≠ Lernen\nProduktivität ≠ Kompetenzaufbau"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-bastani-studie-mathematik",
    "href": "slides/ai-higher-ed/index.html#die-bastani-studie-mathematik",
    "title": "KI in der Hochschulbildung",
    "section": "Die Bastani-Studie: Mathematik",
    "text": "Die Bastani-Studie: Mathematik\nRandomisierte kontrollierte Studie (Bastani u. a. 2025)\nEinzelstudie, Replikation ausstehend\n\n~1000 türkische Gymnasiasten\nGPT-4 Zugang während des Übens\n\n\n\n\nMit KI:\n48% mehr Aufgaben korrekt gelöst (direkter Zugang)\n127% mit “GPT Tutor” (strukturierte Unterstützung)\n\nOhne KI (später):\n17% schlechter als Kontrollgruppe\nDie nie KI hatte\n\n\n\n\n“Students attempt to use GPT-4 as a ‘crutch’ during practice sessions, and when successful, perform worse on their own.”\n\n\n\n\n\n\n\n\n\nNuance\n\n\nDie Schlussfolgerungen gelten hauptsächlich für KI als Antwortgeber. KI als pädagogisch gestalteter Tutor könnte andere Effekte haben — wie die 127% beim “GPT Tutor” andeuten."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#desirable-difficulties-warum-anstrengung-nötig-ist",
    "href": "slides/ai-higher-ed/index.html#desirable-difficulties-warum-anstrengung-nötig-ist",
    "title": "KI in der Hochschulbildung",
    "section": "Desirable Difficulties: Warum Anstrengung nötig ist",
    "text": "Desirable Difficulties: Warum Anstrengung nötig ist\nRobert Bjork (Bjork und Bjork 2011)\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\n\nVier bewährte “erwünschte Schwierigkeiten”:\n\nVariation der Lernbedingungen\nInterleaving: Mischen von Aufgabentypen\nSpacing: Verteiltes statt massiertes Lernen\nRetrieval Practice: Abrufen statt Wiederlesen (Roediger und Karpicke 2006)\n\n\n\n\n\n\n\n\n\nMechanismus\n\n\nSofortiger KI-Zugang kann Abrufversuche kurzschliessen, bevor sie Gedächtnisspuren stärken können."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-generierungseffekt",
    "href": "slides/ai-higher-ed/index.html#der-generierungseffekt",
    "title": "KI in der Hochschulbildung",
    "section": "Der Generierungseffekt",
    "text": "Der Generierungseffekt\n\n\n\n\n\n\n\n\n\nSelbst generierte Information wird besser behalten (Slamecka und Graf 1978).\n\n\nWenn KI generiert, was Studierende selbst produzieren sollten, entfällt der Lerneffekt.\n\n\n\nDer Generierungseffekt ist nicht neu. Immer wenn Technologie kognitive Arbeit übernimmt, sehen wir ähnliche Muster…\n\nSchauen wir uns den Generierungseffekt genauer an, weil er besonders relevant für KI ist.\nDie Grafik zeigt die Behaltensleistung in Prozent. Selbst generierte Information wird am besten behalten, etwa 70 Prozent. Gelesene Information liegt bei etwa 50 Prozent. Und von KI erhaltene Information? Noch niedriger, hier illustrativ bei etwa 35 Prozent dargestellt.\nDie Forschung zum Generierungseffekt stammt aus den 1970er Jahren. Slamecka und Graf zeigten, dass selbst produziertes Material besser behalten wird als passiv aufgenommenes.\n[KLICK] Die Implikation ist klar: Wenn KI generiert, was Studierende selbst produzieren sollten, entfällt der Lerneffekt.\n[KLICK] Aber dieser Effekt ist nicht neu. Das bringt uns zu den historischen Analogien."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-scaffolding-hypothese",
    "href": "slides/ai-higher-ed/index.html#die-scaffolding-hypothese",
    "title": "KI in der Hochschulbildung",
    "section": "Die Scaffolding-Hypothese",
    "text": "Die Scaffolding-Hypothese\nWas wissen wir, was vermuten wir?\n\nWas wir wissen (Evidenz): Atrophie von Fähigkeiten ist dokumentiert. Eine vorhandene Fähigkeit verkümmert durch Nichtgebrauch. Das ist reversibel.\nWas wir theoretisch ableiten: Wenn KI die kognitiven Prozesse übernimmt, die für Lernen notwendig sind, sollte weniger Lernen stattfinden. Das folgt aus der CLT.\nWas wir vermuten (Hypothese): Es könnte einen Unterschied geben zwischen Fertigkeitsatrophie und Entwicklungsbeeinträchtigung.\n\n\nDie Hypothese: Grundfertigkeiten wie Schreiben sind nicht nur Fertigkeiten, sondern Prozesse, die kognitive Architektur aufbauen. Schreiben könnte ein “epistemisches Werkzeug” sein.\n\n\n\n\n\n\n\n\nVorsicht\n\n\nDiese Hypothese ist plausibel, aber nicht empirisch belegt. Wir haben keine Längsschnittstudien. Die Bedenken verdienen Aufmerksamkeit, sollten aber nicht als gesicherte Fakten behandelt werden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#historische-analogien",
    "href": "slides/ai-higher-ed/index.html#historische-analogien",
    "title": "KI in der Hochschulbildung",
    "section": "Historische Analogien",
    "text": "Historische Analogien\n\n\n\n\n\n\n\n\n\n\n\n\nDas Muster wiederholt sich. Aber: KI ist breiter als GPS oder Taschenrechner.\n(Dahmani und Bohbot 2020; Sparrow, Liu, und Wegner 2011)\n\n\nHier sehen Sie eine Zeitlinie technologischer Entwicklungen und ihrer Auswirkungen auf unsere kognitiven Fähigkeiten.\nDie 1970er: Der Taschenrechner. Studien zeigen, dass früher und intensiver Taschenrechner-Einsatz das konzeptuelle mathematische Verständnis beeinträchtigen kann.\nDie 1990er: GPS-Navigation. Habitueller GPS-Gebrauch ist mit schwächerem räumlichem Gedächtnis assoziiert.\nDie 2000er: Google. Der “Google-Effekt”: Wir erinnern besser, WO Information zu finden ist, als WAS die Information ist.\nDie 2020er: KI. Und jetzt? KI kombiniert und verstärkt all diese Effekte.\n[KLICK] Das Muster wiederholt sich. Aber der Unterschied: KI ist breiter als GPS oder Taschenrechner. Sie betrifft nicht eine kognitive Domäne, sondern potenziell alle."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#grenzen-historischer-analogien",
    "href": "slides/ai-higher-ed/index.html#grenzen-historischer-analogien",
    "title": "KI in der Hochschulbildung",
    "section": "Grenzen historischer Analogien",
    "text": "Grenzen historischer Analogien\n\nGPS, Taschenrechner, Google: jeweils spezifische, enge kognitive Funktionen\nGenerative KI kann fast jede kognitive Aufgabe übernehmen\nSchreiben, Argumentieren, Analysieren, Synthetisieren, Bewerten\nDie Breite ist beispiellos\n\n\nAber: Die historischen Bedenken hatten oft Berechtigung. GPS beeinflusst räumliche Kognition. Taschenrechner veränderten Mathematikunterricht."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-edtech-hype-zyklus",
    "href": "slides/ai-higher-ed/index.html#der-edtech-hype-zyklus",
    "title": "KI in der Hochschulbildung",
    "section": "Der EdTech-Hype-Zyklus",
    "text": "Der EdTech-Hype-Zyklus\nBildungstechnologien folgen einem wiederkehrenden Muster (Reich 2020)\n\nRadio sollte die besten Vorlesungen in jedes Klassenzimmer bringen\nFernsehen sollte Lernen revolutionieren\nComputer sollten Unterricht personalisieren\nMOOCs sollten Elite-Bildung demokratisieren\n\n\nJede Technologie fand eine Nische, aber keine erfüllte die transformativen Versprechen.\n\n\nWas macht KI anders? Die Breite ist beispiellos. Aber dieselben strukturellen Kräfte könnten wirken."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-haben-sie-über-das-schreiben-auch-gesagt",
    "href": "slides/ai-higher-ed/index.html#das-haben-sie-über-das-schreiben-auch-gesagt",
    "title": "KI in der Hochschulbildung",
    "section": "“Das haben sie über das Schreiben auch gesagt”",
    "text": "“Das haben sie über das Schreiben auch gesagt”\nSokrates’ Warnung im Phaidros: Schrift wird das Gedächtnis schwächen.\n\nDrei Antworten:\n\nSchrift hat Kognition tiefgreifend verändert\nEinige Bedenken waren berechtigt (mündliche Gedächtnistraditionen sind zurückgegangen)\nSchriftkultur entwickelte sich über Jahrhunderte — KI-Integration geschieht in Jahren"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#warum-experten-profitieren-lernende-nicht",
    "href": "slides/ai-higher-ed/index.html#warum-experten-profitieren-lernende-nicht",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Experten profitieren, Lernende nicht",
    "text": "Warum Experten profitieren, Lernende nicht\n\n\n\nExperten:\n\n\n Können Routine auslagern\n Können KI-Output bewerten\n Mehr Kapazität für Komplexes\n\n\nLernende:\n\n\n Können nicht bewerten\n Überspringen Grundlagen\n Risiko: “Fliessende Inkompetenz”\n\n\n\n\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.\n\nJetzt können wir zusammenfassen, warum Experten und Lernende so unterschiedlich von KI-Werkzeugen betroffen sind.\n[KLICK] Experten können Routine auslagern. Sie können KI-Output bewerten. Und sie haben mehr Kapazität für Komplexes.\n[KLICK] Lernende hingegen können KI-Output nicht bewerten. Sie überspringen möglicherweise Grundlagen. Und das Risiko ist “fliessende Inkompetenz”: Sie können mit Hilfe alles, ohne Hilfe nichts.\n[KLICK] Das Fazit: Dasselbe Werkzeug, fundamental unterschiedliche Auswirkungen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#diskussion-think-pair-share-1",
    "href": "slides/ai-higher-ed/index.html#diskussion-think-pair-share-1",
    "title": "KI in der Hochschulbildung",
    "section": "Diskussion: Think-Pair-Share",
    "text": "Diskussion: Think-Pair-Share\n                    \n                    \n                \n\n\n\n\n\n\nReflexion\n\n\nThink: Wo könnte KI-Unterstützung in deinem Fach die produktive Anstrengung eliminieren, die Lernen ermöglicht?\nPair: Diskutiere mit deinem Nachbarn.\nShare: Welche Grundfähigkeiten könnten bei KI-Nutzung verkümmern?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-hype-um-den-digitalen-sokrates",
    "href": "slides/ai-higher-ed/index.html#der-hype-um-den-digitalen-sokrates",
    "title": "KI in der Hochschulbildung",
    "section": "Der Hype um den digitalen Sokrates",
    "text": "Der Hype um den digitalen Sokrates\n\nEdTech verspricht: KI-Tutoren mit “sokratischer Methode”\nBlooms “Two Sigma Problem” (BLOOM 1984): 1:1-Tutoring erzielt 2 SD Verbesserung\nVersprechen: Demokratisierung personalisierter Bildung durch KI\n\n\n\n\n\n\n\n\nAber\n\n\nDie Begeisterung übersteigt die Evidenz erheblich."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#warum-fragen-theoretisch-helfen-könnten",
    "href": "slides/ai-higher-ed/index.html#warum-fragen-theoretisch-helfen-könnten",
    "title": "KI in der Hochschulbildung",
    "section": "Warum Fragen theoretisch helfen könnten",
    "text": "Warum Fragen theoretisch helfen könnten\n\n\nGenerierungseffekt\nSelbst erzeugte Antworten werden besser behalten als passiv erhaltene (Slamecka und Graf 1978)\n\nSelbsterklärungseffekt\nErklären fördert tiefere Verarbeitung und deckt Wissenslücken auf (Chi u. a. 1994)\n\n\nAber: Diese Effekte erfordern, dass Lernende genug Vorwissen haben, um sinnvolle Antworten zu generieren."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-die-evidenz-tatsächlich-zeigt",
    "href": "slides/ai-higher-ed/index.html#was-die-evidenz-tatsächlich-zeigt",
    "title": "KI in der Hochschulbildung",
    "section": "Was die Evidenz tatsächlich zeigt",
    "text": "Was die Evidenz tatsächlich zeigt\nVanLEHN (2011): Meta-Analyse zu Tutoring\n\nMenschliche Tutoren: d = 0.79 (nicht 2.0 wie Bloom behauptete)\nIntelligente Tutorsysteme: d = 0.76 (vergleichbar)\nAber: Schritt-für-Schritt-Feedback war wesentlich; die Rolle des sokratischen Dialogs ist schwer zu isolieren\n\n\n\n\n\n\n\n\nZu LLM-basierten sokratischen Tutoren\n\n\nKeine gut kontrollierten RCTs vorhanden. Die Evidenz besteht hauptsächlich aus Zufriedenheitsumfragen und Vergleichen mit “kein Tutoring”."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-diagnose-problem",
    "href": "slides/ai-higher-ed/index.html#das-diagnose-problem",
    "title": "KI in der Hochschulbildung",
    "section": "Das Diagnose-Problem",
    "text": "Das Diagnose-Problem\nEffektives sokratisches Fragen erfordert:\n\nGenaue Einschätzung des aktuellen Wissensstands\nUnterscheidung verschiedener Fehlertypen\nAnpassung der Fragen an den Lernenden\n\n\nBeispiel: “1/2 + 1/3 = 2/5” kann bedeuten:\n\nProzeduraler Fehler (Zähler und Nenner addiert)\nKonzeptueller Fehler (versteht Brüche nicht)\nFlüchtigkeitsfehler\n\n\n\nKI-Systeme können diese Unterscheidung nicht zuverlässig treffen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#weitere-implementierungsherausforderungen",
    "href": "slides/ai-higher-ed/index.html#weitere-implementierungsherausforderungen",
    "title": "KI in der Hochschulbildung",
    "section": "Weitere Implementierungsherausforderungen",
    "text": "Weitere Implementierungsherausforderungen\n\n\nFragesequenzierung\n\nSokratischer Dialog ist kontingent\nJede Frage baut auf vorherigen Antworten auf\nLLMs generieren Token, keine pädagogischen Pläne\n\n\nFeedback-Timing\n\nWann korrigieren, wann weiter fragen?\nAbhängig von Lernenden und Fehlertyp\nKI kann das nicht zuverlässig beurteilen\n\n\n\nTendenz von LLMs: Zu nachgiebig, akzeptieren falsche Antworten, vermeiden produktives Unbehagen"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#praktische-empfehlungen",
    "href": "slides/ai-higher-ed/index.html#praktische-empfehlungen",
    "title": "KI in der Hochschulbildung",
    "section": "Praktische Empfehlungen",
    "text": "Praktische Empfehlungen\n\nEvidenz verlangen: Peer-Review-Studien mit Lernoutcomes, nicht nur Zufriedenheit\nDiagnose-Fähigkeit prüfen: Kann das System verschiedene Fehlertypen unterscheiden?\nOpportunitätskosten bedenken: Ist KI-Tutoring besser als Alternativen?\nMit strukturierten Domänen beginnen: Mathematik vor Literaturanalyse\nAuf unbeabsichtigte Folgen achten: Gaming, Abhängigkeit von externen Prompts"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#fazit-zum-sokratischen-ki-tutoring",
    "href": "slides/ai-higher-ed/index.html#fazit-zum-sokratischen-ki-tutoring",
    "title": "KI in der Hochschulbildung",
    "section": "Fazit zum sokratischen KI-Tutoring",
    "text": "Fazit zum sokratischen KI-Tutoring\n\n“Die ehrliche Antwort ist: Wir wissen es noch nicht.”\n\n\n\n\nWas plausibel ist:\nSelbsterklärung und Generierung fördern Lernen\n\nWas nicht belegt ist:\nDass aktuelle KI-Systeme dies effektiv implementieren können\n\n\n\nSokrates würde es schätzen: Die beste Art, Werkzeuge zu bewerten, die seine Methode beanspruchen, ist, kritische Fragen zu stellen und unbegründete Antworten nicht zu akzeptieren."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-unbequeme-wahrheit",
    "href": "slides/ai-higher-ed/index.html#die-unbequeme-wahrheit",
    "title": "KI in der Hochschulbildung",
    "section": "Die unbequeme Wahrheit",
    "text": "Die unbequeme Wahrheit\n\n\n\n\n\n\nKernaussage\n\n\nWas KI für Produktivität nützlich macht, droht sie für Lernen schädlich zu machen.\nSofortige Antworten können die Anstrengung eliminieren, die Kompetenz aufbaut.\nDies ist kein Mangel aktueller KI. Es folgt aus etablierten Prinzipien der Kognitionswissenschaft. Die Frage ist daher nicht ob, sondern wie KI eingesetzt wird.\n\n\n\n\n\n\n\n\n\n\nEinschränkung\n\n\nEs gibt noch wenige Studien, die direkt messen, wie KI-Nutzung Lernen über längere Zeit beeinflusst. Die theoretische Argumentation basiert auf etablierten Prinzipien, aber empirische Langzeitstudien zu generativer KI fehlen noch."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#mind-extending-vs.-mind-replacing",
    "href": "slides/ai-higher-ed/index.html#mind-extending-vs.-mind-replacing",
    "title": "KI in der Hochschulbildung",
    "section": "Mind-extending vs. Mind-replacing",
    "text": "Mind-extending vs. Mind-replacing\nAndy Clark (Clark 2025)\n\n\nKognition erweitern:\n\nDer Mensch bleibt kognitiv engagiert\nWerkzeug verstärkt, ersetzt nicht\nBeispiel: Taschenrechner für Mathematiker\nFähigkeiten bleiben erhalten und werden ausgebaut\n\n\nKognition ersetzen:\n\nDer Mensch wird passiv\nWerkzeug übernimmt das Denken\nBeispiel: KI schreibt Essay, Studierender submittet\nAbhängigkeit entsteht, Fähigkeiten verkümmern\n\n\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung.\n\n\n\n\n\n\n\n\nAus Sicht der Cognitive Load Theory\n\n\nWissen im Langzeitgedächtnis unterscheidet sich fundamental von extern zugänglichem Wissen. Internalisiertes Wissen ermöglicht automatische Mustererkennung, befreit das Arbeitsgedächtnis und erlaubt höheres Denken. Externer Zugang erfordert immer bewusste Abrufprozesse."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-sequenzierungsfrage",
    "href": "slides/ai-higher-ed/index.html#die-sequenzierungsfrage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Sequenzierungsfrage",
    "text": "Die Sequenzierungsfrage\n\n\nNovize ——— Schwelle? ——— Experte\n\n\nDie Schwelle ist unbekannt und empirisch nicht bestimmt\nSie variiert nach Domäne und Person\nDer Expertise-Umkehr-Effekt erfordert dynamische KI-Nutzungsempfehlungen\n\n\n\n\nWer profitiert von KI-Werkzeugen? Wer nicht?\n\n\nDas bringt uns zur praktischen Frage: Wenn Experten profitieren und Lernende Gefahr laufen, wann ist der Übergang?\nLinks der Novize, rechts der Experte. Irgendwo dazwischen liegt eine Schwelle.\n[KLICK] Das Problem ist: Diese Schwelle ist unbekannt.\n[KLICK] Sie variiert nach Domäne und Person.\n[KLICK] Der Expertise-Umkehr-Effekt erfordert dynamische Empfehlungen.\n[KLICK] Die praktische Frage: Wer profitiert von KI-Werkzeugen? Und wer nicht? Diese Frage können wir nicht pauschal beantworten."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-entwicklungsfrage",
    "href": "slides/ai-higher-ed/index.html#die-entwicklungsfrage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Entwicklungsfrage",
    "text": "Die Entwicklungsfrage\nKognitive Entwicklung und KI\n\nDer präfrontale Kortex entwickelt sich bis etwa Mitte 20 (individuelle Variation erheblich)\nExekutive Funktionen, Metakognition, Selbstregulation sind bei vielen Studierenden noch in Entwicklung\nParadox: Jene, die KI-Nutzung am wenigsten regulieren können, sind möglicherweise am verletzlichsten\n\n\n\n\n\n\n\n\nDie Kohortenfrage\n\n\nDie aktuelle Studierendengeneration ist möglicherweise die erste, die ihre gesamte Bildungslaufbahn mit generativer KI durchläuft.\nWenn wir Langzeitdaten haben, wird eine Generation bereits das Experiment gewesen sein."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-soziale-dimension",
    "href": "slides/ai-higher-ed/index.html#die-soziale-dimension",
    "title": "KI in der Hochschulbildung",
    "section": "Die soziale Dimension",
    "text": "Die soziale Dimension\nLernen ist nicht nur ein kognitiver, sondern ein sozialer Prozess (Reich 2020)\n\nStudierende lernen besser, wenn sie sich mit Lehrenden und Peers verbunden fühlen\nPeers werden seltener konsultiert, wenn KI antwortet: kollaboratives Lernen leidet\nBeziehungen zu Lehrenden werden oberflächlicher, wenn Rückfragen an die KI gehen\nGelegenheiten für Mentoring und informelles Lernen nehmen ab\n\n\nDie Rolle der Lehrperson: Wenn KI sofortige Antworten und Feedback liefert, verschiebt sich die Rolle der Lehrenden. Beziehung, Motivation, Vorbild, Kontext: diese unersetzliche Funktion muss neu definiert werden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-equity-dimension",
    "href": "slides/ai-higher-ed/index.html#die-equity-dimension",
    "title": "KI in der Hochschulbildung",
    "section": "Die Equity-Dimension",
    "text": "Die Equity-Dimension\nDie dritte digitale Kluft (Michael Trucano 2023)\n\n\n\n\n\n\n\n\n\nErste Kluft\nZweite Kluft\nDritte Kluft\n\n\n\n\nZugang zu Geräten\nFähigkeit zur sinnvollen Nutzung\nQualität der pädagogischen Integration\n\n\n\n\n\nKonkrete Ungleichheiten:\n\nKosten: Premium-KI-Werkzeuge kosten Geld. Wer kann sich ChatGPT Plus leisten?\nInstitutionelle Ressourcen: Welche Hochschulen haben Zeit und Expertise für durchdachte Integration?\nBetreuung: Wer hat Dozierende, die über KI-Risiken aufklären?\n\n\n\n\n\n\n\n\n\nRisiko\n\n\n“Demokratisierung” von Bildung durch KI könnte genau jene benachteiligen, denen sie helfen soll.\nDas MOOC-Muster wiederholt sich möglicherweise: Eine Technologie, die “allen” zugänglich ist, nützt vor allem jenen, die bereits die Voraussetzungen mitbringen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#der-stärkste-gegeneinwand",
    "href": "slides/ai-higher-ed/index.html#der-stärkste-gegeneinwand",
    "title": "KI in der Hochschulbildung",
    "section": "Der stärkste Gegeneinwand",
    "text": "Der stärkste Gegeneinwand\n\n“Wenn KI immer verfügbar ist, müssen Fähigkeiten nicht internalisiert werden.”\n\n\nVier Antworten:\n\nPermanenzannahme: Setzt voraus, dass KI immer verfügbar, funktional und bezahlbar bleibt\nRekursionsproblem: Wer erkennt, wenn KI falsch liegt? Wer erweitert menschliches Wissen?\nAutonomie-Argument: Eigenständige kognitive Fähigkeit hat intrinsischen Wert\nUnbekannte Unbekannte: Wir wissen nicht, welche Kaskadeneffekte folgen könnten"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-wir-noch-nicht-wissen",
    "href": "slides/ai-higher-ed/index.html#was-wir-noch-nicht-wissen",
    "title": "KI in der Hochschulbildung",
    "section": "Was wir noch nicht wissen",
    "text": "Was wir noch nicht wissen\n\nLängsschnittstudien über Jahre: Praktisch nicht vorhanden\nTransfer auf neue Kontexte: Unerforscht\nOptimale Scaffolding-Bedingungen: Unbekannt\nDisziplinspezifische Effekte: Untererforscht\nPublikationsbias: Wahrscheinlich vorhanden\n\n\nEpistemische Bescheidenheit ist angebracht."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#fazit-die-zentrale-botschaft",
    "href": "slides/ai-higher-ed/index.html#fazit-die-zentrale-botschaft",
    "title": "KI in der Hochschulbildung",
    "section": "Fazit: Die zentrale Botschaft",
    "text": "Fazit: Die zentrale Botschaft\n\nKI-Werkzeuge sind primär für Experten konzipiert. Sie machen Experten produktiver, während Lernende ohne durchdachte Integration oft nicht profitieren, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.\n\n\nDie Argumentation stützt sich auf:\n\nCognitive Load Theory: Produktive Anstrengung durch das Nadelöhr des Arbeitsgedächtnisses\nExpertise-Umkehr-Effekt: Dieselbe Unterstützung kann Novizen helfen und Experten schaden\nDomänenspezifität: Kritische KI-Bewertung erfordert Fachwissen\nDesirable Difficulties: Schwierigkeiten optimieren oft Langzeitbehalten\nGenerierungseffekt: Selbst erzeugte Information wird besser behalten\n\n\n\nDie praktischen Implikationen: Grundlagen vor Werkzeugen | Prozess bewerten | Nach Vorwissen differenzieren | “Ohne-KI”-Phasen | Kritische KI-Nutzung im Fachkontext üben"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#abschliessende-provokationen",
    "href": "slides/ai-higher-ed/index.html#abschliessende-provokationen",
    "title": "KI in der Hochschulbildung",
    "section": "Abschliessende Provokationen",
    "text": "Abschliessende Provokationen\n\n“If AI assistance during education impairs independent capability, students may graduate less prepared for contexts where AI is unavailable.”\n\n\n\n“The productivity gains during education would come at the cost of capability thereafter.”\n\n\n\n\n“Whether this tradeoff is acceptable depends on assumptions about the future that educators cannot verify.”\n\n\n\n\n“Wenn wir uns bei den Risiken irren, haben wir die Einführung nützlicher Technologie etwas verlangsamt. Wenn sich die Kritiker bei der Sicherheit irren, haben wir möglicherweise die kognitive Entwicklung einer Generation beeinträchtigt.”"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#offene-diskussion",
    "href": "slides/ai-higher-ed/index.html#offene-diskussion",
    "title": "KI in der Hochschulbildung",
    "section": "Offene Diskussion",
    "text": "Offene Diskussion\n                    \n                    \n                \n\n\n\n\n\n\nDiskussionsfragen\n\n\n\nWas bedeutet das für deine Lehre?\nWo siehst du die Experten-Lernenden-Unterscheidung in der Praxis?\nWas sind die schwierigsten Fragen, die das aufwirft?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#referenzen",
    "href": "slides/ai-higher-ed/index.html#referenzen",
    "title": "KI in der Hochschulbildung",
    "section": "Referenzen",
    "text": "Referenzen\n\n\nBastani, Hamsa, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakcı, und Rei Mariman. 2025. „Generative AI Without Guardrails Can Harm Learning: Evidence from High School Mathematics“. Proceedings of the National Academy of Sciences of the United States of America 122 (26): e2422633122. https://doi.org/10.1073/pnas.2422633122.\n\n\nBjork, Elizabeth Ligon, und Robert A. Bjork. 2011. „Making Things Hard on Yourself, but in a Good Way: Creating Desirable Difficulties to Enhance Learning“. In Psychology and the Real World: Essays Illustrating Fundamental Contributions to Society, 56–64. New York, NY, US: Worth Publishers.\n\n\nChase, William G., und Herbert A. Simon. 1973. „Perception in Chess“. Cognitive Psychology 4 (1): 55–81. https://doi.org/10.1016/0010-0285(73)90004-2.\n\n\nClark, Andy. 2025. „Extending Minds with Generative AI“. Nature Communications 16 (1): 4627. https://doi.org/10.1038/s41467-025-59906-9.\n\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nGroot, Adriaan D. De, und Adrianus Dingeman de Groot. 1978. Thought and Choice in Chess. Walter de Gruyter. https://books.google.com?id=EI4gr42NwDQC.\n\n\nKalyuga, Slava. 2009. „The Expertise Reversal Effect“. In Managing Cognitive Load in Adaptive Multimedia Learning, 58–80. IGI Global Scientific Publishing. https://doi.org/10.4018/978-1-60566-048-6.ch003.\n\n\nSlamecka, Norman J., und Peter Graf. 1978. „The Generation Effect: Delineation of a Phenomenon“. Journal of Experimental Psychology: Human Learning and Memory 4 (6): 592–604. https://doi.org/10.1037/0278-7393.4.6.592.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745.\n\n\nSweller, John. 2024. „Cognitive Load Theory and Individual Differences“. Learning and Individual Differences 110 (Februar): 102423. https://doi.org/10.1016/j.lindif.2024.102423.\n\n\nWillingham, Daniel T. 2008. „Critical Thinking: Why Is It So Hard to Teach?“ Arts Education Policy Review 109 (4): 21–32. https://doi.org/10.3200/AEPR.109.4.21-32."
  },
  {
    "objectID": "qa/experten-vs-lernende/index.html",
    "href": "qa/experten-vs-lernende/index.html",
    "title": "Experten vs. Lernende",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Experten vs. Lernende"
    ]
  },
  {
    "objectID": "qa/experten-vs-lernende/index.html#warum-dasselbe-werkzeug-unterschiedlich-wirkt",
    "href": "qa/experten-vs-lernende/index.html#warum-dasselbe-werkzeug-unterschiedlich-wirkt",
    "title": "Experten vs. Lernende",
    "section": "Warum dasselbe Werkzeug unterschiedlich wirkt",
    "text": "Warum dasselbe Werkzeug unterschiedlich wirkt\nExperten haben eine qualitativ andere kognitive Architektur. Sie sehen Muster und Bedeutung statt Einzelteile. Sie speichern Wissen in “Chunks”: vernetzte Wissensstrukturen, die automatisch abgerufen werden.\nExperten können:\n\nRoutine auslagern\nKI-Output bewerten\nMehr Kapazität für Komplexes nutzen\n\nLernende hingegen:\n\nKönnen nicht bewerten\nÜberspringen möglicherweise Grundlagen\nRisiko: “Fliessende Inkompetenz”\n\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Experten vs. Lernende"
    ]
  },
  {
    "objectID": "qa/experten-vs-lernende/index.html#häufige-fragen",
    "href": "qa/experten-vs-lernende/index.html#häufige-fragen",
    "title": "Experten vs. Lernende",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Prüfungen und praktische Kompetenz\nIm klinischen Reasoning im 2. Semester Pflege zeigt sich folgendes Risiko: Studierende könnten mit ChatGPT sehr flüssig klingende Pflegediagnosen erstellen, ohne die zugrundeliegenden Symptommuster wirklich zu erkennen.\nFrage: Wie kann in Prüfungssituationen überhaupt noch festgestellt werden, ob jemand eine Situation selbstständig einschätzen kann? Und noch wichtiger: Wenn Studierende im Praktikum möglicherweise KI-Tools nutzen, um Dokumentationen zu schreiben, wie stellt man sicher, dass sie die kritischen Warnsignale bei Patienten trotzdem wahrnehmen und nicht nur schön formulierte, aber inhaltlich falsche Einschätzungen abgeben?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Risiko der “fliessenden Inkompetenz” ist hier besonders kritisch. Praktische Prüfungen (OSCE), mündliche Fallbesprechungen und Prozessbeobachtung im Praktikum können helfen, die tatsächliche Kompetenz zu erfassen. Mehr dazu im Leitfaden unter Fliessende Inkompetenz und Prozess bewerten, nicht nur Produkt.\n\n\n\n\n\n\nTechnik und Informatik: Grundstudium ohne Code-Assistenten?\nIn der Informatik zeigt sich das Paradox täglich: Studierende können mit GitHub Copilot funktionierenden Code produzieren, aber wenn nachgefragt wird, warum sie genau diese Datenstruktur gewählt haben, kommt oft nichts.\nFrage: Sollte im Grundstudium bewusst auf Code-Assistenten verzichtet werden, damit Studierende erst mal die fundamentalen Patterns selbst entwickeln? Oder ist das realitätsfern, weil sie in der Berufswelt ja sowieso mit diesen Tools arbeiten werden? Und wie baut man Übungen, bei denen sie lernen, KI-generierten Code kritisch zu evaluieren, wenn sie dafür ja genau das Expertenwissen brauchen, das sie erst aufbauen sollten?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas ist das Kerndilemma: Um KI kritisch zu nutzen, braucht man Expertise. Um Expertise aufzubauen, braucht man Übung ohne Abkürzungen. Die Sequenzierung “Grundlagen zuerst” ist wahrscheinlich der richtige Ansatz. Später kann KI als Werkzeug dienen. Mehr dazu im Leitfaden unter Warum Experten profitieren, Lernende nicht und Die Sequenzierungsfrage.\n\n\n\n\n\n\nSoziale Arbeit: Systemisches Verstehen vs. Textbausteine\nDas Konzept der “Chunks” und Erfahrungsmuster ist relevant für die Soziale Arbeit, wo viel mit Falldokumentationen und Analysen komplexer Lebenssituationen gearbeitet wird.\nFrage: Wenn Studierende KI nutzen, um Sozialberichte zu schreiben oder Interventionsstrategien zu entwickeln: Wie unterscheidet man, ob sie wirklich die systemischen Zusammenhänge verstehen oder nur AI-generierte Fachliteratur-Versatzstücke aneinanderreihen? Besonders kritisch ist das bei ethischen Dilemmata: KI kann durchaus schlüssig klingende Argumentationen liefern, aber erfasst sie die moralische Komplexität realer Fälle? Wie trainiert man diese professionelle Urteilsfähigkeit, wenn Studierende sich an KI-Output gewöhnen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie professionelle Urteilsfähigkeit ist das, was Experten von Novizen unterscheidet. KI kann plausibel klingende Texte produzieren, aber nicht die kontextspezifische Einschätzung leisten. Fallbesprechungen, Supervisionen und Reflexion über die eigene Entscheidungsfindung sind hier wichtiger als schriftliche Produkte. Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen.\n\n\n\n\n\n\nWirtschaft: Business-Logik vs. formale Korrektheit\nIm strategischen Management und Business Analytics zeigt sich ein Problem: Studierende können mit KI-Tools beeindruckende Marktanalysen erstellen, aber auf die Frage “Ist diese Strategie für dieses spezifische Unternehmen sinnvoll?” fehlt ihnen das Gespür.\nFrage: Wie gestaltet man Fallstudien und Prüfungen so, dass Studierende zeigen müssen, dass sie die Business-Logik verstehen und nicht nur KI-Output aufhübschen? Und praktisch: Wenn in Gruppenarbeiten die Analyse zwar formal korrekt ist, aber komplett an der Realität des Unternehmens vorbeigeht, wie thematisiert man das, ohne dass es wie ein generelles KI-Verbot klingt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nPrüfungsformate, die Begründungen und kontextspezifische Anpassungen fordern, können helfen. Mündliche Verteidigung von Analysen, unerwartete Folgefragen, Anwendung auf neue Szenarien. Das Thematisieren des Problems ist wichtig: Es geht nicht um KI-Verbot, sondern um Lernziele. Mehr dazu im Leitfaden unter Warum Experten profitieren, Lernende nicht und Entscheidungsrahmen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nWie Expertise entsteht\nExperten und Novizen sind grundlegend verschieden\nWarum Experten profitieren, Lernende nicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Experten vs. Lernende"
    ]
  },
  {
    "objectID": "qa/generierungseffekt/index.html",
    "href": "qa/generierungseffekt/index.html",
    "title": "Der Generierungseffekt",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Generierungseffekt"
    ]
  },
  {
    "objectID": "qa/generierungseffekt/index.html#selbst-generiert-wird-besser-behalten",
    "href": "qa/generierungseffekt/index.html#selbst-generiert-wird-besser-behalten",
    "title": "Der Generierungseffekt",
    "section": "Selbst generiert wird besser behalten",
    "text": "Selbst generiert wird besser behalten\nDer Generierungseffekt ist ein robuster Befund der Gedächtnisforschung: Selbst generierte Information wird besser behalten als passiv erhaltene.\nDie Implikation für KI: Wenn KI generiert, was Studierende selbst produzieren sollten, entfällt der Lerneffekt. Das Endprodukt mag ähnlich aussehen, aber der Lernprozess ist fundamental anders.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Generierungseffekt"
    ]
  },
  {
    "objectID": "qa/generierungseffekt/index.html#häufige-fragen",
    "href": "qa/generierungseffekt/index.html#häufige-fragen",
    "title": "Der Generierungseffekt",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Pflegepläne und professionelles Verständnis\nIm Fachbereich Pflege erstellen Studierende Pflegepläne für Fallbeispiele. Einige nutzen mittlerweile ChatGPT, um diese Pflegepläne zu generieren. Das Endprodukt sieht oft sehr professionell aus, aber im Praktikum zeigt sich, dass ihnen das Verständnis fehlt.\nFrage: Wie kann die Aufgabenstellung so angepasst werden, dass Studierende den Generierungseffekt wirklich nutzen, aber trotzdem von KI profitieren können? Soll KI komplett verboten werden oder gibt es einen Mittelweg?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nEin Mittelweg könnte sein: Erst eigenen Entwurf erstellen (Generierungseffekt nutzen), dann mit KI-Version vergleichen und Unterschiede analysieren. Der Prozess der eigenen Erstellung ist der Lernmoment, nicht das Endprodukt. Mehr dazu im Leitfaden unter Der Generierungseffekt.\n\n\n\n\n\n\nWirtschaft: Analysefähigkeit vs. Tool-Kompetenz\nIm Kurs “Strategisches Management” müssen Studierende Unternehmensanalysen durchführen. Wenn sie einfach eine SWOT-Analyse von ChatGPT generieren lassen, ist das Problem mit dem Generierungseffekt klar.\nFrage: Aber gleichzeitig werden sie später im Beruf genau solche Tools nutzen. Wie bereitet man sie realistisch auf die Praxis vor, ohne dass sie das analytische Denken verlernen? Ist es nicht widersprüchlich, wenn im Studium KI verboten wird, aber in der Wirtschaft ist sie Standard?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nEs geht nicht um Verbot, sondern um Sequenzierung. Experten können KI produktiv nutzen, weil sie den Output bewerten können. Studierende müssen erst die analytischen Grundlagen aufbauen. Später kann KI als Werkzeug dienen, dessen Output kritisch geprüft wird. Mehr dazu im Leitfaden unter Warum Experten profitieren, Lernende nicht und Kognition erweitern vs. ersetzen.\n\n\n\n\n\n\nKünste: Kreativer Prozess vs. KI-Varianten\nIn Visueller Kommunikation und Design geht es sehr viel um den kreativen Prozess: Skizzieren, Iterieren, Verwerfen, Neuanfangen. Das ist der Kern des Lernens. Wenn Studierende jetzt mit Midjourney oder DALL-E arbeiten und in Sekunden 20 Designvarianten bekommen, fehlt dieser ganze Prozess.\nFrage: Andererseits experimentieren sie vielleicht dadurch mit Ideen, auf die sie sonst nicht gekommen wären. Wie bewertet man das? Wie stellt man sicher, dass der Generierungseffekt nicht verloren geht, wenn das eigene Gestalten quasi ausgelagert wird?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer kreative Prozess des Skizzierens und Iterierens hat eigenen Lernwert. KI-generierte Varianten können als Inspiration dienen, sollten aber nicht das eigene Gestalten ersetzen. Möglicher Ansatz: Erst eigene Skizzen, dann KI als Ideengeber, dann bewusste Auswahl und Weiterentwicklung mit eigener Hand. Mehr dazu im Leitfaden unter Die Scaffolding-Hypothese.\n\n\n\n\n\n\nHAFL: Vernetztes Denken in der Landwirtschaft\nIn der Agronomie sollen Studierende Bewirtschaftungspläne für landwirtschaftliche Betriebe entwickeln. Dabei müssen sie Fruchtfolgen planen, Nährstoffbilanzen berechnen, Arbeitsspitzen berücksichtigen: Das ist komplexes, vernetztes Denken.\nFrage: Wenn Studierende das von einer KI machen lassen, haben sie vielleicht ein korrektes Resultat, aber verstehen nicht die Zusammenhänge. Später als Berater müssen sie aber genau diese Entscheidungen begründen und anpassen können. Wie kann sichergestellt werden, dass sie den Denkprozess durchlaufen, auch wenn KI-Tools in der Praxis immer verfügbarer werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Verstehen der Zusammenhänge ist die Kernkompetenz. Aufgaben sollten Begründungen und Anpassungen an veränderte Bedingungen fordern. KI kann das Resultat liefern, aber nicht die Anpassungsfähigkeit an unvorhergesehene Situationen. Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDer Generierungseffekt\nDie Scaffolding-Hypothese\nKognition erweitern vs. ersetzen",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Generierungseffekt"
    ]
  },
  {
    "objectID": "qa/index.html",
    "href": "qa/index.html",
    "title": "Anwendungsfragen",
    "section": "",
    "text": "Diese Seite sammelt typische Fragen und Anwendungsszenarien zur Präsentation “KI in der Hochschulbildung: Werkzeuge für Experten, Herausforderungen für Lernende”.\nDie Fragen wurden als repräsentative Beispiele entwickelt und illustrieren, wie die vorgestellten Konzepte in verschiedenen Fachbereichen relevant werden. Sie laden zur eigenen Reflexion ein.\nDie Fragen sind nach Themen geordnet. Für vertiefte Informationen verweisen wir auf den Leitfaden.",
    "crumbs": [
      "Präsentation",
      "Anwendungsfragen"
    ]
  },
  {
    "objectID": "qa/index.html#themenübersicht",
    "href": "qa/index.html#themenübersicht",
    "title": "Anwendungsfragen",
    "section": "Themenübersicht",
    "text": "Themenübersicht\n\n\n\nThema\nBeschreibung\n\n\n\n\nDas Produktivitäts-Lern-Paradox\nWarum können Studierende mit KI mehr Aufgaben lösen, aber trotzdem weniger lernen?\n\n\nKognitive Grundlagen\nDas Arbeitsgedächtnis als Nadelöhr des Lernens und die Cognitive Load Theory.\n\n\nErwünschte Schwierigkeiten\nWarum Anstrengung beim Lernen notwendig ist und wie KI diese untergraben kann.\n\n\nDer Generierungseffekt\nWarum selbst generierte Information besser behalten wird.\n\n\nHistorische Analogien\nWas wir von Taschenrechner, GPS und Google über KI lernen können.\n\n\nExperten vs. Lernende\nWarum dasselbe Werkzeug unterschiedliche Auswirkungen hat.\n\n\nDer Expertise-Umkehr-Effekt\nWie das Vorwissen bestimmt, welche Lehrmethode optimal ist.\n\n\nKritisches Denken und Fachwissen\nWarum kritische KI-Bewertung Domänenwissen erfordert.\n\n\nPraktische Implikationen\nWas bedeutet das konkret für die Lehre?",
    "crumbs": [
      "Präsentation",
      "Anwendungsfragen"
    ]
  },
  {
    "objectID": "qa/index.html#weiterführende-ressourcen",
    "href": "qa/index.html#weiterführende-ressourcen",
    "title": "Anwendungsfragen",
    "section": "Weiterführende Ressourcen",
    "text": "Weiterführende Ressourcen\n\nLeitfaden: KI in der Hochschulbildung\nBFH Weiterbildungen: KI in der Lehre\nVirtuelle Akademie Knowledge Base",
    "crumbs": [
      "Präsentation",
      "Anwendungsfragen"
    ]
  },
  {
    "objectID": "qa/kritisches-denken/index.html",
    "href": "qa/kritisches-denken/index.html",
    "title": "Kritisches Denken und Fachwissen",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kritisches Denken und Fachwissen"
    ]
  },
  {
    "objectID": "qa/kritisches-denken/index.html#warum-kritische-bewertung-domänenwissen-erfordert",
    "href": "qa/kritisches-denken/index.html#warum-kritische-bewertung-domänenwissen-erfordert",
    "title": "Kritisches Denken und Fachwissen",
    "section": "Warum kritische Bewertung Domänenwissen erfordert",
    "text": "Warum kritische Bewertung Domänenwissen erfordert\nDaniel Willingham fasst die Forschung zusammen:\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n\nEin Biomedizin-Experte erkennt, wenn ChatGPT bei Biochemie falsch liegt. Ein Novize kann diese Bewertung nicht vornehmen, unabhängig von “kritischen Denkfähigkeiten”.\nDu kannst nicht kritisch bewerten, was du nicht verstehst.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kritisches Denken und Fachwissen"
    ]
  },
  {
    "objectID": "qa/kritisches-denken/index.html#häufige-fragen",
    "href": "qa/kritisches-denken/index.html#häufige-fragen",
    "title": "Kritisches Denken und Fachwissen",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Subtile Fehler erkennen ohne Grundwissen\nIm Unterricht von Anatomie und Physiologie im ersten Semester Pflege nutzen Studierende ChatGPT für Zusammenfassungen, obwohl sie noch kein fundiertes Grundwissen haben.\nFrage: Wie soll man reagieren, wenn Studierende KI-generierte Erklärungen zu einem Krankheitsbild zeigen, die subtile Fehler enthalten, die sie selbst nicht erkennen können? Sollte die Nutzung komplett verboten werden in dieser Phase, oder wie baut man gezielt die Fähigkeit auf, KI-Outputs kritisch zu prüfen, wenn das Fachwissen noch fehlt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Dilemma ist real: Um KI kritisch zu prüfen, braucht man das Wissen, das man aufbauen will. In frühen Phasen ist Zurückhaltung bei KI-Nutzung sinnvoll. Die Fähigkeit zur Prüfung entwickelt sich mit dem Fachwissen. Gemeinsame Analyse von KI-Fehlern kann lehrreich sein, wenn die Grundlagen vorhanden sind. Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen und Was transferiert, und was nicht.\n\n\n\n\n\n\nTechnik und Informatik: Code verstehen vs. Code produzieren\nDie Situation in der Informatik ist paradox: Studierende nutzen GitHub Copilot und ChatGPT für Code, aber viele verstehen die Grundlagen nicht wirklich. Es kommt vor, dass Code eingereicht wird, der funktioniert, aber nicht erklärt werden kann.\nFrage: Willingham sagt, kritisches Denken ist kontextabhängig. Heisst das, dass zuerst darauf bestanden werden muss, dass Studierende ohne KI die Grundlagen lernen? Oder soll ihnen beigebracht werden, KI-generierten Code zu lesen und zu bewerten, auch wenn sie ihn noch nicht selbst schreiben könnten?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nFunktionierender Code, den man nicht versteht, ist ein Symptom für fehlendes Grundlagenwissen. Die Fähigkeit, Code zu bewerten, setzt Verständnis voraus. Die Sequenz “erst selbst schreiben, dann mit KI arbeiten” ist wahrscheinlich effektiver. Code Review als Lernmethode kann helfen, erfordert aber bereits Grundwissen. Mehr dazu im Leitfaden unter Evidenz für Domänenspezifität.\n\n\n\n\n\n\nSoziale Arbeit: KI und professionelle Urteilsfähigkeit\nIn der Sozialen Arbeit geht es viel um Fallanalyse und professionelle Urteilsfähigkeit. Studierende verwenden zunehmend ChatGPT, um Fallsituationen zu analysieren oder Interventionsvorschläge zu entwickeln.\nFrage: Das Problem: Sie können noch nicht einschätzen, ob die KI wichtige Kontextfaktoren übersieht oder zu vereinfachte Lösungen vorschlägt. Wenn kritisches Denken wirklich so stark vom Fachwissen abhängt, wie strukturiert man die Kurse? Erst Theorie und Praxis ohne KI, dann später mit KI? Oder integriert man KI von Anfang an als Diskussionspartner, dessen Schwächen gemeinsam analysiert werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Fähigkeit, Kontextfaktoren zu erkennen, ist das, was Experten von Novizen unterscheidet. Gemeinsame Analyse von KI-Output kann lehrreich sein, wenn Dozierende die Schwächen aufzeigen. Die Gefahr ist, dass Studierende allein nicht erkennen können, was fehlt. Sequenzierung (erst Grundlagen) ist wahrscheinlich sicherer. Mehr dazu im Leitfaden unter Angewendet auf KI-Bewertung und Die zentrale Implikation.\n\n\n\n\n\n\nWirtschaft: Oberflächliche Analysen erkennen\nStudierende im Bachelor Business Administration nutzen KI-Tools für Marktanalysen und Businesspläne. Es kommt vor, dass Wettbewerbsanalysen präsentiert werden, die auf ChatGPT basieren. Die Struktur ist gut, aber die strategischen Schlussfolgerungen sind oberflächlich und teilweise falsch.\nFrage: Studierende können nicht beurteilen, was fehlt, weil ihnen das betriebswirtschaftliche Fundament fehlt. Wie geht man damit um in Modulen, wo genau diese Analysefähigkeit aufgebaut werden soll? Muss KI-Nutzung in den ersten Semestern eingeschränkt werden, oder gibt es einen Weg, damit zu arbeiten, ohne dass das Grundlagenlernen leidet?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Problem illustriert genau den Punkt: Ohne Fachwissen kann man die Qualität nicht beurteilen. Einschränkung in frühen Phasen ist wahrscheinlich nötig, um die Analysefähigkeit aufzubauen. Später kann KI als Werkzeug dienen, dessen Output kritisch geprüft wird. Die Fähigkeit zur Prüfung entwickelt sich aber erst mit dem Wissen. Mehr dazu im Leitfaden unter Fach-spezifisches Lernen priorisieren.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nKritisches Denken erfordert Fachwissen\nWillinghams Herausforderung\nWas transferiert, und was nicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kritisches Denken und Fachwissen"
    ]
  },
  {
    "objectID": "qa/praktische-implikationen/index.html",
    "href": "qa/praktische-implikationen/index.html",
    "title": "Praktische Implikationen für die Lehre",
    "section": "",
    "text": "← Zurück zur Übersicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Praktische Implikationen für die Lehre"
    ]
  },
  {
    "objectID": "qa/praktische-implikationen/index.html#was-bedeutet-das-konkret",
    "href": "qa/praktische-implikationen/index.html#was-bedeutet-das-konkret",
    "title": "Praktische Implikationen für die Lehre",
    "section": "Was bedeutet das konkret?",
    "text": "Was bedeutet das konkret?\nDrei zentrale Prinzipien:\n\nAnstrengung ist das Signal: Wenn Lernen sich zu leicht anfühlt, findet es wahrscheinlich nicht statt.\nKI als Tutor, nicht als Antwortgeber: KI soll Denkprozesse anregen, nicht ersetzen.\nExpertise bestimmt den Nutzen: Dasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.\n\nDie Kernaussage: Grundlagen BEVOR Werkzeuge. Erst das Fundament, dann die Erweiterung.",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Praktische Implikationen für die Lehre"
    ]
  },
  {
    "objectID": "qa/praktische-implikationen/index.html#häufige-fragen",
    "href": "qa/praktische-implikationen/index.html#häufige-fragen",
    "title": "Praktische Implikationen für die Lehre",
    "section": "Häufige Fragen",
    "text": "Häufige Fragen\n\nGesundheit: Grundlagen sicherstellen in der Praxis\nDie Aussage, dass Grundlagen vor Werkzeugen kommen müssen, ist relevant für die Physiotherapie. Im ersten Jahr lernen Studierende die Anatomie und die manuelle Befundaufnahme. Es zeigt sich aber immer mehr, dass sie ChatGPT nutzen, um Diagnosen zu “checken” oder Behandlungspläne zu erstellen, ohne die muskuloskelettalen Zusammenhänge wirklich zu verstehen.\nFrage: Wie kann konkret sichergestellt werden, dass Studierende diese Grundlagen wirklich beherrschen, bevor sie KI-Tools nutzen? Sollte die Nutzung in den ersten Semestern komplett verboten werden, oder gibt es einen Weg, KI so einzusetzen, dass sie das Verständnis fördert statt ersetzt? Bei praktischen Prüfungen am Patienten zeigt sich nämlich, dass einige zwar theoretisch viel wissen, aber die Hände nicht richtig einsetzen können.\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie praktischen Fertigkeiten (“Hände einsetzen”) erfordern Prozeduralisierung, die nur durch Übung entsteht. KI kann hier nicht helfen. Formative Assessments ohne KI können den Lernstand erfassen. In frühen Phasen ist Zurückhaltung sinnvoll, später kann KI als Werkzeug dienen, dessen Vorschläge kritisch geprüft werden. Mehr dazu im Leitfaden unter Prozeduralisierung: Vom Wissen zum Können und Übungsphasen schützen.\n\n\n\n\n\n\nTechnik und Informatik: Differenzierung nach Niveau\nDie Aussage “Expertise bestimmt den Nutzen” ist interessant. Im Software Engineering zeigt sich genau dieses Paradox: Studierende nutzen GitHub Copilot und ChatGPT schon ab dem ersten Semester für ihre Programmieraufgaben. Die fortgeschrittenen Studierenden nutzen es effektiv als Pair-Programming-Partner, aber die Anfänger kopieren Code, den sie nicht verstehen.\nFrage: Wie unterscheidet man in der Aufgabenstellung zwischen Anfängern und Fortgeschrittenen? Sollten für Erstsemester andere Regeln gelten als für Masterstudierende? Und wie formuliert man Programmieraufgaben so, dass auch mit KI-Unterstützung noch echtes Lernen stattfindet? Reicht es, wenn verlangt wird, dass sie den generierten Code erklären können, oder braucht es fundamentale Coding-Aufgaben komplett ohne KI?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDifferenzierung nach Niveau ist sinnvoll. Für Anfänger: Grundlagen ohne KI aufbauen. Für Fortgeschrittene: KI als Werkzeug erlauben, aber Verständnis prüfen. Code erklären lassen ist ein guter Ansatz, aber nicht ausreichend. Auch: Code modifizieren, Fehler finden, auf neue Probleme anwenden. Mehr dazu im Leitfaden unter Der Expertise-Umkehr-Effekt und Entscheidungsrahmen.\n\n\n\n\n\n\nHAFL: Notwendige Grundlagen vs. delegierbare Berechnungen\nDie Aussage “Effort is the signal” und dass zu einfaches Lernen kein echtes Lernen ist, wirft Fragen auf. An der HAFL arbeiten Studierende viel mit Berechnungen zu Nährstoffkreisläufen, Bodenqualität und Ertragsprognosen. Früher haben sie das mühsam von Hand oder mit Excel durchgerechnet, heute können sie das alles von KI-Tools machen lassen.\nFrage: Müssen Studierende diese Berechnungen wirklich noch selbst durchführen können, oder reicht es, wenn sie die Resultate interpretieren und validieren können? In der Praxis auf dem Betrieb werden sie ja auch digitale Tools nutzen. Wo genau liegt die Grenze zwischen “nötigem Aufwand für Verständnis” und “ineffizienter Zeitverschwendung”? Welche Grundlagen sind wirklich unverzichtbar, und wo darf die KI die mühsame Arbeit übernehmen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Grenze liegt dort, wo Verstehen nötig ist, um Fehler zu erkennen und Anpassungen vorzunehmen. Routine-Berechnungen können delegiert werden, wenn die Konzepte verstanden sind. Die Frage ist: Können sie erkennen, wenn das Tool einen unrealistischen Wert ausgibt? Können sie bei veränderten Bedingungen anpassen? Das erfordert konzeptuelles Verständnis. Mehr dazu im Leitfaden unter Der stärkste Gegeneinwand und Kognition erweitern vs. ersetzen.\n\n\n\n\n\n\nSoziale Arbeit: KI als Tutor, nicht als Antwortgeber\nDer Punkt “KI als Tutor, nicht als Antwortgeber” ist relevant für die Soziale Arbeit. Es geht viel um Fallanalysen und die Entwicklung von Interventionsstrategien. Studierende müssen lernen, komplexe soziale Situationen zu verstehen und ethisch reflektierte Entscheidungen zu treffen.\nFrage: Wenn KI als “Tutor” eingesetzt werden soll, der das Denken stimuliert: Wie macht man das konkret? Sollten Prompts vorgegeben werden, mit denen Studierende Fälle diskutieren? Oder sollten sie aufgefordert werden, ihre eigenen Lösungsansätze zuerst zu entwickeln und dann mit der KI zu reflektieren? Die Sorge ist, dass die KI zu schnell fertige “Lösungen” anbietet, obwohl es in der Sozialen Arbeit selten eindeutige Antworten gibt. Wie verhindert man, dass Studierende die KI-Antworten als “richtig” übernehmen, statt kritisch zu hinterfragen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Sequenz “erst eigene Lösung, dann Reflexion mit KI” ist vielversprechend. Wichtig ist, dass KI nicht als Autorität wahrgenommen wird. Strukturierte Prompts können helfen, KI als Diskussionspartner zu nutzen, nicht als Antwortgeber. Die Gefahr der vorschnellen “Lösung” ist real. Gemeinsame Analyse von KI-Grenzen kann helfen. Mehr dazu im Leitfaden unter Sokratisches Fragen in KI-Tutoren und KI-Tutoren evaluieren.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nImplikationen und offene Fragen\nKognition erweitern vs. ersetzen\nEntscheidungsrahmen\nFazit",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Praktische Implikationen für die Lehre"
    ]
  },
  {
    "objectID": "qa/paradox/index.html#anwendungsfragen",
    "href": "qa/paradox/index.html#anwendungsfragen",
    "title": "Das Produktivitäts-Lern-Paradox",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Klinisches Reasoning und Pflegediagnostik\nIm Unterricht von klinischem Reasoning und Pflegediagnostik im 2. Studienjahr müssen Studierende lernen, Patientensituationen zu analysieren und eigenständig Pflegediagnosen zu stellen. Dabei wird festgestellt, dass einige ChatGPT nutzen, um Fallbeispiele zu lösen.\nFrage: Wenn Studierende mit KI-Unterstützung mehr Fallbeispiele korrekt lösen, aber dann in der Praxis ohne KI schlechter abschneiden: Wie erkennt man das rechtzeitig? Beim OSCE haben sie ja kein Handy dabei, aber bis dahin haben sie schon Monate mit KI geübt. Kann man überhaupt noch davon ausgehen, dass die Selbstlernphasen mit Fallbeispielen einen Lerneffekt haben, wenn viele heimlich ChatGPT verwenden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Problem liegt in der Unterscheidung zwischen Aufgabenleistung und Lernen. Regelmässige formative Assessments ohne KI-Zugang können helfen, den tatsächlichen Lernstand zu erfassen. Mehr dazu im Leitfaden unter Das Produktivitäts-Lern-Paradox und Lernsituationen gestalten.\n\n\n\n\n\nTechnik und Informatik: Code-Assistenten und Grundlagen\nIn Modulen zur objektorientierten Programmierung und Softwarearchitektur sollen Studierende eigenständig kleinere Projekte entwickeln und dabei Design Patterns anwenden lernen.\nFrage: Die Situation ist paradox: Einerseits sollen Studierende GitHub Copilot und ähnliche Tools kennenlernen, weil das zum Berufsalltag gehört. Andererseits zeigt diese Studie ja, dass sie dann die Grundlagen nicht mehr lernen. Wie findet man die richtige Balance? Soll in den ersten Semestern ein komplettes AI-Verbot durchgesetzt und erst ab dem 5. Semester Code-Assistenten erlaubt werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Sequenzierung ist entscheidend: Grundlagen vor Werkzeugen. Der Expertise-Umkehr-Effekt zeigt, dass dieselbe Unterstützung für Novizen schädlich und für Fortgeschrittene hilfreich sein kann. Mehr dazu im Leitfaden unter Die Sequenzierungsfrage und Der Expertise-Umkehr-Effekt.\n\n\n\n\n\nWirtschaft: Konzeptverständnis vs. Formelanwendung\nIm Finanzmanagement und Corporate Finance im Bachelor müssen Studierende Investitionsrechnungen durchführen, Cash-Flow-Analysen erstellen und Unternehmensbewertungen vornehmen können.\nFrage: Das Problem zeigt sich direkt bei Excel-basierten Assignments. Wenn Studierende ChatGPT fragen “Erstelle mir eine Formel für den Net Present Value mit diesen Parametern”, bekommen sie sofort die Lösung. Sie reichen dann perfekte Spreadsheets ein, aber in der schriftlichen Prüfung können sie nicht mal erklären, warum man den Diskontierungssatz überhaupt braucht. Wie gestaltet man Übungsaufgaben, bei denen sie wirklich das Konzept verstehen müssen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer Generierungseffekt zeigt: Selbst erarbeitetes Wissen wird besser behalten. Aufgaben sollten den Prozess bewerten, nicht nur das Produkt. Zwischenschritte einfordern und begründen lassen. Mehr dazu im Leitfaden unter Der Generierungseffekt und Prozess bewerten, nicht nur Produkt.\n\n\n\n\n\nSoziale Arbeit: Reflexionsfähigkeit und Beziehungsarbeit\nIm Unterricht von Gesprächsführung und Case Management lernen Studierende, mit Klientinnen und Klienten professionelle Beratungsgespräche zu führen und individuelle Unterstützungspläne zu entwickeln.\nFrage: In der Sozialen Arbeit wird viel mit Rollenspielen und schriftlichen Fallanalysen gearbeitet. Es zeigt sich, dass Studierende ihre Gesprächsvorbereitungen und Analysen von ChatGPT schreiben lassen. Die Texte klingen plausibel, aber in der praktischen Umsetzung fehlt komplett das Verständnis für Gesprächsdynamiken. Das Paradox ist besonders kritisch: In diesem Berufsfeld geht es um Beziehungsarbeit und situatives Handeln. Wie bereitet man sie dann auf echte Krisensituationen vor, wo keine KI hilft?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nLernen erfordert die kognitive Anstrengung, die KI zu eliminieren droht. Praktische Übungen ohne KI-Unterstützung sind hier besonders wichtig. Die Reflexionsfähigkeit entsteht durch den mühsamen Prozess des Formulierens. Mehr dazu im Leitfaden unter Desirable Difficulties und Kognition erweitern vs. ersetzen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDas Produktivitäts-Lern-Paradox\nDie Bastani-Studie im Detail\nLernsituationen gestalten",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Das Produktivitäts-Lern-Paradox"
    ]
  },
  {
    "objectID": "qa/kognitive-grundlagen/index.html#anwendungsfragen",
    "href": "qa/kognitive-grundlagen/index.html#anwendungsfragen",
    "title": "Kognitive Grundlagen",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Notfallsituationen und Informationsverarbeitung\nIm Bachelor Pflege müssen Studierende in Notfallsituationen sehr schnell viele Informationen gleichzeitig verarbeiten: Vitalwerte, Symptome, Medikamentenwirkungen, und so weiter.\nFrage: Wenn das Working Memory wirklich auf 4±1 Elemente beschränkt ist, wie kann man Studierende dann überhaupt auf solche komplexen Situationen vorbereiten? KI-gestützte Simulationen könnten helfen, aber wenn die kognitive Belastung nicht umgangen werden kann: Sollte dann vielleicht mehr auf klassische Chunking-Strategien gesetzt werden, wo zusammengehörige Informationen gebündelt werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nChunking ist tatsächlich der Schlüssel: Experten speichern Wissen in vernetzten Strukturen, die automatisch abgerufen werden. Diese “Chunks” müssen aber durch Übung aufgebaut werden. KI kann diesen Prozess nicht abkürzen, aber gut gestaltete Simulationen können helfen, Muster zu erkennen. Mehr dazu im Leitfaden unter Wie Expertise entsteht und Was Experten sehen.\n\n\n\n\n\nTechnik und Informatik: Code verstehen vs. kopieren\nStudierende im dritten Semester Informatik programmieren zunehmend mit GitHub Copilot und ChatGPT. Theoretisch umgeht das die kognitive Verarbeitung nicht wirklich: Sie müssen den generierten Code ja trotzdem verstehen und durchdenken.\nFrage: Aber es zeigt sich, dass viele einfach Code kopieren, ohne ihn richtig zu durchdringen. Wie kann man Aufgabenstellungen so gestalten, dass der germane Load, also die lernrelevante Belastung, im Vordergrund steht? Sollten bewusst kleinere Code-Beispiele verwendet werden, damit Studierende innerhalb dieser 4±1 Elemente arbeiten können?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Problem ist, dass KI die lernförderliche Belastung eliminieren kann. Aufgabenstellungen sollten den Denkprozess fordern: Code erklären lassen, Varianten vergleichen, Fehler finden. Kleinere, fokussierte Beispiele können helfen, die kognitive Belastung zu managen. Mehr dazu im Leitfaden unter Cognitive Load Theory und Drei Arten kognitiver Belastung.\n\n\n\n\n\nWirtschaft: KI zur Komplexitätsreduktion\nIm Kurs “Strategisches Management” wird viel mit komplexen Fallstudien gearbeitet: Marktanalysen, Finanzberichte, Wettbewerbsszenarien. Die Studierenden nutzen mittlerweile KI, um diese Fälle vorab zusammenzufassen.\nFrage: Einerseits ist das Problem mit dem Working Memory klar: Wenn Studierende zu viele Variablen gleichzeitig jonglieren müssen, lernen sie nichts. Andererseits: Wenn KI ihnen hilft, die extrinsic load zu reduzieren, also überflüssige Komplexität wegzufiltern, ist das dann nicht sogar förderlich? Oder riskiert man damit, dass sie die Fähigkeit verlieren, selbst relevante von irrelevanten Informationen zu unterscheiden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas ist eine wichtige Unterscheidung: KI kann extrinsische Belastung reduzieren (gut) oder lernförderliche Belastung eliminieren (problematisch). Die Fähigkeit, Relevantes von Irrelevantem zu unterscheiden, ist selbst eine Expertise, die aufgebaut werden muss. Mehr dazu im Leitfaden unter Welche Art der Belastung reduziert KI?.\n\n\n\n\n\nKünste: Kognitive Überlastung durch KI-Output\nIn der Visuellen Kommunikation arbeiten Studierende oft sehr intuitiv und visuell. Viele experimentieren mit Midjourney oder DALL-E und generieren in kurzer Zeit sehr viele Designvarianten.\nFrage: Wenn das Working Memory aber tatsächlich so limitiert ist: Überfordert es Studierende dann nicht kognitiv, wenn sie 50 KI-generierte Entwürfe durchgehen müssen, um den richtigen auszuwählen? Sollte man sie eher anleiten, weniger, aber bewusstere Iterationen zu machen? Kann die Flut an KI-Output den kreativen Lernprozess tatsächlich behindern, weil die kognitive Kapazität überlastet wird?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nJa, zu viele Optionen können das Arbeitsgedächtnis überlasten und den Lernprozess behindern. Bewusste Einschränkungen und fokussierte Iterationen können helfen. Der kreative Prozess des Skizzierens, Iterierens und Verwerfens hat einen eigenen Lernwert. Mehr dazu im Leitfaden unter Das Nadelöhr des Lernens.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nCognitive Load Theory: Das Nadelöhr des Lernens\nDrei Arten kognitiver Belastung\nWie Expertise entsteht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kognitive Grundlagen"
    ]
  },
  {
    "objectID": "qa/erwuenschte-schwierigkeiten/index.html#anwendungsfragen",
    "href": "qa/erwuenschte-schwierigkeiten/index.html#anwendungsfragen",
    "title": "Erwünschte Schwierigkeiten",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Pflegediagnosen und Selbst-Generierung\nIm klinischen Reasoning bei Bachelorstudierenden Pflege arbeiten Studierende Fallbeispiele selbst durch und begründen ihre Pflegediagnosen. Das ist mühsam für sie, aber genau diese Mühe scheint ja wichtig zu sein.\nFrage: Studierende berichten, dass sie ChatGPT nutzen, um sich Pflegediagnosen vorschlagen zu lassen und dann nur noch auswählen. Einerseits ist das verständlich: Die KI gibt oft korrekte Vorschläge. Andererseits besteht die Befürchtung, dass ihnen genau dieser Prozess der Selbst-Generierung fehlt. Wie können Fallbeispiele so umgestaltet werden, dass diese “erwünschte Schwierigkeit” erhalten bleibt, auch wenn Studierende KI nutzen? Oder sollte KI-Nutzung bei solchen Übungen einfach verboten werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer Generierungseffekt zeigt: Selbst formulierte Antworten werden besser behalten. Mögliche Strategien: Erst eigene Diagnose erstellen, dann mit KI vergleichen und Unterschiede begründen. Oder: Prozess dokumentieren lassen, nicht nur das Ergebnis. Mehr dazu im Leitfaden unter Der Generierungseffekt und Desirable Difficulties.\n\n\n\n\n\nTechnik und Informatik: Abkürzung vs. Effizienz\nDas Konzept der “erwünschten Schwierigkeiten” wirft Fragen auf. In Programmierkursen zeigt sich, dass Studierende mit GitHub Copilot und KI-Assistenten viel schneller vorankommen und mehr Projekte umsetzen können.\nFrage: Variation wird als eine dieser Strategien genannt, aber genau das ermöglicht doch die KI? Studierende können jetzt viel mehr verschiedene Frameworks und Ansätze ausprobieren. Wo ist die Grenze zwischen unerwünschter Abkürzung und sinnvoller Effizienzsteigerung? Einerseits sollen Studierende Programmiersprachen beherrschen. Andererseits sollen sie nicht Zeit mit dem Auswendiglernen von Syntax verschwenden. Wie unterscheidet man, welche Schwierigkeiten “erwünscht” sind und welche einfach nur Zeitverschwendung?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nErwünschte Schwierigkeiten sind solche, die zur Schemabildung beitragen. Syntax auswendig lernen ist weniger wichtig als Konzepte verstehen. Die Frage ist: Verstehen sie, warum der Code funktioniert? Können sie Fehler finden und beheben? Mehr dazu im Leitfaden unter Von schwachen zu starken Methoden und Prozeduralisierung.\n\n\n\n\n\nSoziale Arbeit: Reflexionsberichte und aktiver Abruf\nIn der Sozialen Arbeit geht es viel um Gesprächsführung und die Entwicklung einer professionellen Haltung. Studierende schreiben oft Reflexionsberichte nach Praxiseinsätzen, das ist diese “aktive Retrieval”-Strategie, oder?\nFrage: Es zeigt sich, dass manche Arbeiten sprachlich perfekt sind, aber irgendwie leer wirken. Studierende geben zu, dass sie ihre Stichworte in ChatGPT eingeben und dann den Text überarbeiten. Sie meinen, das helfe ihnen, ihre Gedanken zu strukturieren. Einerseits haben sie sich ja mit dem Inhalt auseinandergesetzt. Andererseits stellt sich die Frage, ob dieser Prozess des mühsamen Formulierens nicht genau das ist, was die Reflexion vertieft. Wie können Reflexionsaufgaben so gestaltet werden, dass diese erwünschte Schwierigkeit erhalten bleibt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas mühsame Formulieren ist tatsächlich Teil des Lernprozesses. Schreiben kann ein “epistemisches Werkzeug” sein: Gedanken entwickeln sich durch das Schreiben. Mögliche Ansätze: Handschriftliche Erstfassung, mündliche Reflexion, oder strukturierte Fragen, die KI-Nutzung erschweren. Mehr dazu im Leitfaden unter Die Scaffolding-Hypothese.\n\n\n\n\n\nHAFL: Spaced Learning und KI-Tools in der Praxis\nIn Bodenkunde und Pflanzenernährung ist ein wichtiger Teil des Lernens, dass Studierende lernen, Nährstoffmängel an Pflanzen zu erkennen und zu diagnostizieren. Das braucht Übung: Sie müssen viele Beispiele sehen und selbst interpretieren.\nFrage: Es gibt bereits Apps, die per Bilderkennung Pflanzenkrankheiten und Nährstoffmängel identifizieren. In der Praxis werden Studierende später als Agronomieberatende solche Tools nutzen. Gleichzeitig müssen sie zuerst das Grundwissen aufbauen, um die KI-Vorschläge überhaupt kritisch beurteilen zu können. Wie können diese Übungen so gestaltet werden, dass Studierende lernen, KI-Tools sinnvoll einzusetzen, ohne dass ihnen der mühsame Prozess des Lernens verloren geht? Sollten die KI-Tools in gewissen Phasen erlaubt und in anderen verboten werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Sequenzierung ist entscheidend: Erst die Grundlagen ohne KI, dann KI als Werkzeug. Gestaffelte Übungen können helfen: In frühen Phasen selbst diagnostizieren, später mit KI-Tool vergleichen und Unterschiede analysieren. Mehr dazu im Leitfaden unter Die Sequenzierungsfrage und Übungsphasen schützen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDesirable Difficulties: Warum Anstrengung nötig ist\nDer Generierungseffekt\nRetrieval Practice",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Erwünschte Schwierigkeiten"
    ]
  },
  {
    "objectID": "qa/generierungseffekt/index.html#anwendungsfragen",
    "href": "qa/generierungseffekt/index.html#anwendungsfragen",
    "title": "Der Generierungseffekt",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Pflegepläne und professionelles Verständnis\nIm Fachbereich Pflege erstellen Studierende Pflegepläne für Fallbeispiele. Einige nutzen mittlerweile ChatGPT, um diese Pflegepläne zu generieren. Das Endprodukt sieht oft sehr professionell aus, aber im Praktikum zeigt sich, dass ihnen das Verständnis fehlt.\nFrage: Wie kann die Aufgabenstellung so angepasst werden, dass Studierende den Generierungseffekt wirklich nutzen, aber trotzdem von KI profitieren können? Soll KI komplett verboten werden oder gibt es einen Mittelweg?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nEin Mittelweg könnte sein: Erst eigenen Entwurf erstellen (Generierungseffekt nutzen), dann mit KI-Version vergleichen und Unterschiede analysieren. Der Prozess der eigenen Erstellung ist der Lernmoment, nicht das Endprodukt. Mehr dazu im Leitfaden unter Der Generierungseffekt.\n\n\n\n\n\nWirtschaft: Analysefähigkeit vs. Tool-Kompetenz\nIm Kurs “Strategisches Management” müssen Studierende Unternehmensanalysen durchführen. Wenn sie einfach eine SWOT-Analyse von ChatGPT generieren lassen, ist das Problem mit dem Generierungseffekt klar.\nFrage: Aber gleichzeitig werden sie später im Beruf genau solche Tools nutzen. Wie bereitet man sie realistisch auf die Praxis vor, ohne dass sie das analytische Denken verlernen? Ist es nicht widersprüchlich, wenn im Studium KI verboten wird, aber in der Wirtschaft ist sie Standard?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nEs geht nicht um Verbot, sondern um Sequenzierung. Experten können KI produktiv nutzen, weil sie den Output bewerten können. Studierende müssen erst die analytischen Grundlagen aufbauen. Später kann KI als Werkzeug dienen, dessen Output kritisch geprüft wird. Mehr dazu im Leitfaden unter Warum Experten profitieren, Lernende nicht und Kognition erweitern vs. ersetzen.\n\n\n\n\n\nKünste: Kreativer Prozess vs. KI-Varianten\nIn Visueller Kommunikation und Design geht es sehr viel um den kreativen Prozess: Skizzieren, Iterieren, Verwerfen, Neuanfangen. Das ist der Kern des Lernens. Wenn Studierende jetzt mit Midjourney oder DALL-E arbeiten und in Sekunden 20 Designvarianten bekommen, fehlt dieser ganze Prozess.\nFrage: Andererseits experimentieren sie vielleicht dadurch mit Ideen, auf die sie sonst nicht gekommen wären. Wie bewertet man das? Wie stellt man sicher, dass der Generierungseffekt nicht verloren geht, wenn das eigene Gestalten quasi ausgelagert wird?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer kreative Prozess des Skizzierens und Iterierens hat eigenen Lernwert. KI-generierte Varianten können als Inspiration dienen, sollten aber nicht das eigene Gestalten ersetzen. Möglicher Ansatz: Erst eigene Skizzen, dann KI als Ideengeber, dann bewusste Auswahl und Weiterentwicklung mit eigener Hand. Mehr dazu im Leitfaden unter Die Scaffolding-Hypothese.\n\n\n\n\n\nHAFL: Vernetztes Denken in der Landwirtschaft\nIn der Agronomie sollen Studierende Bewirtschaftungspläne für landwirtschaftliche Betriebe entwickeln. Dabei müssen sie Fruchtfolgen planen, Nährstoffbilanzen berechnen, Arbeitsspitzen berücksichtigen: Das ist komplexes, vernetztes Denken.\nFrage: Wenn Studierende das von einer KI machen lassen, haben sie vielleicht ein korrektes Resultat, aber verstehen nicht die Zusammenhänge. Später als Berater müssen sie aber genau diese Entscheidungen begründen und anpassen können. Wie kann sichergestellt werden, dass sie den Denkprozess durchlaufen, auch wenn KI-Tools in der Praxis immer verfügbarer werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Verstehen der Zusammenhänge ist die Kernkompetenz. Aufgaben sollten Begründungen und Anpassungen an veränderte Bedingungen fordern. KI kann das Resultat liefern, aber nicht die Anpassungsfähigkeit an unvorhergesehene Situationen. Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDer Generierungseffekt\nDie Scaffolding-Hypothese\nKognition erweitern vs. ersetzen",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Generierungseffekt"
    ]
  },
  {
    "objectID": "qa/historische-analogien/index.html#anwendungsfragen",
    "href": "qa/historische-analogien/index.html#anwendungsfragen",
    "title": "Historische Analogien",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nTechnik und Informatik: Technologischer Fortschritt und Grundlagenwissen\nDie historische Entwicklung von Taschenrechner über GPS zu KI wirft Fragen auf. Ist der Vergleich nicht etwas schief? In der Informatik-Ausbildung wurde bewusst entschieden, dass Studierende keinen Assembler mehr von Hand schreiben müssen, weil Compiler das besser machen. Es wurde akzeptiert, dass gewisse Low-Level-Skills obsolet werden.\nFrage: Warum sollte es bei KI anders sein? Wenn Studierende mit KI-Tools schneller zu besseren Lösungen kommen, ist das dann nicht einfach der normale technologische Fortschritt? Wo liegt konkret die Grenze zwischen “wichtiges Grundlagenwissen, das sie trotzdem lernen müssen” und “kann man getrost der KI überlassen”?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Grenze liegt dort, wo Wissen zur Bewertung von KI-Output nötig ist. Assembler kann man delegieren, weil Compiler deterministisch sind. KI-Output muss aber kritisch geprüft werden, und dafür braucht es Fachwissen. Die Frage ist: Was muss man verstehen, um Fehler zu erkennen? Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen.\n\n\n\n\n\nWirtschaft: Blindes Vertrauen in Modelle\nDie Analogie mit dem Taschenrechner ist interessant, aber im Bereich Wirtschaft zeigt sich ein Problem: Studierende müssen später in Unternehmen strategische Entscheidungen treffen, Geschäftsberichte analysieren, Budgets verteidigen.\nFrage: Wenn sie jetzt schon im Studium alle Analysen und Argumentationen von ChatGPT machen lassen, wie sollen sie dann später im Beruf beurteilen können, ob die KI-generierten Vorschläge überhaupt Sinn machen? Bei der Finanzkrise 2008 haben viele blind auf Excel-Modelle vertraut, ohne die Annahmen zu hinterfragen. Besteht nicht die Gefahr, dass eine Generation ausgebildet wird, die zwar KI-Tools bedienen kann, aber nicht mehr die Kompetenz hat, deren Output kritisch zu bewerten?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDiese Sorge ist berechtigt und historisch fundiert. Das Muster wiederholt sich: Werkzeuge, die Experten produktiver machen, können bei unkritischer Nutzung zu Fehlentscheidungen führen. Die Fähigkeit zur kritischen Bewertung erfordert Fachwissen, das aufgebaut werden muss. Mehr dazu im Leitfaden unter Der EdTech-Hype-Zyklus und Der stärkste Gegeneinwand.\n\n\n\n\n\nHAFL: Praktische vs. digitale Kompetenzen\nDie historischen Beispiele kommen alle aus dem digitalen oder städtischen Bereich. Aber Studierende in der Agronomie, die später Landwirtschaftsbetriebe führen oder in der Beratung arbeiten, müssen raus aufs Feld, Böden beurteilen, Krankheiten an Pflanzen erkennen, Wetterentwicklungen einschätzen.\nFrage: Es gibt mittlerweile Precision-Agriculture-Tools und Apps zur Schädlingserkennung, aber am Ende muss man vor Ort sein und die Situation richtig einschätzen können. Wie übertragbar sind diese Erkenntnisse auf praktische, handwerkliche Ausbildungen? Oder ist das Ganze vor allem ein Problem für Büroberufe?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Erkenntnisse sind übertragbar, aber der Kontext ist anders. Praktische Fertigkeiten wie Bodenbeurteilung erfordern implizites Wissen, das nur durch Erfahrung aufgebaut wird. KI-Tools können hier unterstützen, aber nicht das geschulte Auge ersetzen. Die Gefahr ist, dass Studierende sich auf Apps verlassen, ohne das Grundverständnis aufzubauen. Mehr dazu im Leitfaden unter Prozeduralisierung: Vom Wissen zum Können.\n\n\n\n\n\nArchitektur: Handzeichnen und räumliches Verständnis\nDer Vergleich mit GPS ist spannend, weil in der Architektur etwas Ähnliches passiert ist: Früher mussten Studierende von Hand zeichnen und räumlich denken lernen. Dann kam CAD, und es gab grosse Diskussionen, ob das Handzeichnen noch nötig ist. Heute werden generative Design-Tools und KI für Entwurfsvarianten genutzt.\nFrage: Es zeigt sich, dass Studierende, die nie gelernt haben, von Hand zu skizzieren und Proportionen zu erfassen, auch mit den digitalen Tools Mühe haben, weil ihnen das räumliche Verständnis fehlt. Gibt es eine Möglichkeit, diese Grundkompetenzen parallel zur KI-Nutzung zu vermitteln? Oder muss man sich entscheiden zwischen “erst die Grundlagen ohne KI” und “direkt mit KI arbeiten”?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Beobachtung bestätigt das Muster: Grundlegende Fertigkeiten (hier räumliches Denken) sind Voraussetzung für effektive Werkzeugnutzung. Die Sequenz “erst Grundlagen, dann Werkzeuge” ist wahrscheinlich effektiver als paralleles Arbeiten. Das Handzeichnen baut Verständnis auf, das bei der Bewertung von KI-Output hilft. Mehr dazu im Leitfaden unter Die Sequenzierungsfrage und Grundlagen BEVOR Werkzeuge.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nHistorische Analogien\nDer EdTech-Hype-Zyklus\n“Das haben sie über das Schreiben auch gesagt”",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Historische Analogien"
    ]
  },
  {
    "objectID": "qa/experten-vs-lernende/index.html#anwendungsfragen",
    "href": "qa/experten-vs-lernende/index.html#anwendungsfragen",
    "title": "Experten vs. Lernende",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Prüfungen und praktische Kompetenz\nIm klinischen Reasoning im 2. Semester Pflege zeigt sich folgendes Risiko: Studierende könnten mit ChatGPT sehr flüssig klingende Pflegediagnosen erstellen, ohne die zugrundeliegenden Symptommuster wirklich zu erkennen.\nFrage: Wie kann in Prüfungssituationen überhaupt noch festgestellt werden, ob jemand eine Situation selbstständig einschätzen kann? Und noch wichtiger: Wenn Studierende im Praktikum möglicherweise KI-Tools nutzen, um Dokumentationen zu schreiben, wie stellt man sicher, dass sie die kritischen Warnsignale bei Patienten trotzdem wahrnehmen und nicht nur schön formulierte, aber inhaltlich falsche Einschätzungen abgeben?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Risiko der “fliessenden Inkompetenz” ist hier besonders kritisch. Praktische Prüfungen (OSCE), mündliche Fallbesprechungen und Prozessbeobachtung im Praktikum können helfen, die tatsächliche Kompetenz zu erfassen. Mehr dazu im Leitfaden unter Fliessende Inkompetenz und Prozess bewerten, nicht nur Produkt.\n\n\n\n\n\nTechnik und Informatik: Grundstudium ohne Code-Assistenten?\nIn der Informatik zeigt sich das Paradox täglich: Studierende können mit GitHub Copilot funktionierenden Code produzieren, aber wenn nachgefragt wird, warum sie genau diese Datenstruktur gewählt haben, kommt oft nichts.\nFrage: Sollte im Grundstudium bewusst auf Code-Assistenten verzichtet werden, damit Studierende erst mal die fundamentalen Patterns selbst entwickeln? Oder ist das realitätsfern, weil sie in der Berufswelt ja sowieso mit diesen Tools arbeiten werden? Und wie baut man Übungen, bei denen sie lernen, KI-generierten Code kritisch zu evaluieren, wenn sie dafür ja genau das Expertenwissen brauchen, das sie erst aufbauen sollten?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas ist das Kerndilemma: Um KI kritisch zu nutzen, braucht man Expertise. Um Expertise aufzubauen, braucht man Übung ohne Abkürzungen. Die Sequenzierung “Grundlagen zuerst” ist wahrscheinlich der richtige Ansatz. Später kann KI als Werkzeug dienen. Mehr dazu im Leitfaden unter Warum Experten profitieren, Lernende nicht und Die Sequenzierungsfrage.\n\n\n\n\n\nSoziale Arbeit: Systemisches Verstehen vs. Textbausteine\nDas Konzept der “Chunks” und Erfahrungsmuster ist relevant für die Soziale Arbeit, wo viel mit Falldokumentationen und Analysen komplexer Lebenssituationen gearbeitet wird.\nFrage: Wenn Studierende KI nutzen, um Sozialberichte zu schreiben oder Interventionsstrategien zu entwickeln: Wie unterscheidet man, ob sie wirklich die systemischen Zusammenhänge verstehen oder nur AI-generierte Fachliteratur-Versatzstücke aneinanderreihen? Besonders kritisch ist das bei ethischen Dilemmata: KI kann durchaus schlüssig klingende Argumentationen liefern, aber erfasst sie die moralische Komplexität realer Fälle? Wie trainiert man diese professionelle Urteilsfähigkeit, wenn Studierende sich an KI-Output gewöhnen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie professionelle Urteilsfähigkeit ist das, was Experten von Novizen unterscheidet. KI kann plausibel klingende Texte produzieren, aber nicht die kontextspezifische Einschätzung leisten. Fallbesprechungen, Supervisionen und Reflexion über die eigene Entscheidungsfindung sind hier wichtiger als schriftliche Produkte. Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen.\n\n\n\n\n\nWirtschaft: Business-Logik vs. formale Korrektheit\nIm strategischen Management und Business Analytics zeigt sich ein Problem: Studierende können mit KI-Tools beeindruckende Marktanalysen erstellen, aber auf die Frage “Ist diese Strategie für dieses spezifische Unternehmen sinnvoll?” fehlt ihnen das Gespür.\nFrage: Wie gestaltet man Fallstudien und Prüfungen so, dass Studierende zeigen müssen, dass sie die Business-Logik verstehen und nicht nur KI-Output aufhübschen? Und praktisch: Wenn in Gruppenarbeiten die Analyse zwar formal korrekt ist, aber komplett an der Realität des Unternehmens vorbeigeht, wie thematisiert man das, ohne dass es wie ein generelles KI-Verbot klingt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nPrüfungsformate, die Begründungen und kontextspezifische Anpassungen fordern, können helfen. Mündliche Verteidigung von Analysen, unerwartete Folgefragen, Anwendung auf neue Szenarien. Das Thematisieren des Problems ist wichtig: Es geht nicht um KI-Verbot, sondern um Lernziele. Mehr dazu im Leitfaden unter Warum Experten profitieren, Lernende nicht und Entscheidungsrahmen.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nWie Expertise entsteht\nExperten und Novizen sind grundlegend verschieden\nWarum Experten profitieren, Lernende nicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Experten vs. Lernende"
    ]
  },
  {
    "objectID": "qa/expertise-umkehr-effekt/index.html#anwendungsfragen",
    "href": "qa/expertise-umkehr-effekt/index.html#anwendungsfragen",
    "title": "Der Expertise-Umkehr-Effekt",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Heterogene Vorkenntnisse im Kurs\nDas Konzept ist klar, aber wie setzt man es konkret um? In Kursen zur Patientenbeurteilung gibt es oft Studierende mit sehr unterschiedlichen Vorkenntnissen: Einige kommen direkt von der Matur, andere haben bereits eine FaGe-Ausbildung oder Jahre Praxiserfahrung als Pflegeassistenz.\nFrage: Wenn die Empfehlung lautet, “nutzt ChatGPT zur Vorbereitung auf die OSCE-Prüfung”, könnte das den Anfängern helfen, aber den Erfahrenen schaden? Wie findet man heraus, wo bei den Studierenden diese Schwelle liegt? Sollten verschiedene Aufgabenstellungen für verschiedene Levels gemacht werden, oder sollte der KI-Einsatz einfach ganz verboten werden, bis alle ein Grundniveau erreicht haben?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDifferenzierung ist der Schlüssel. Verschiedene Aufgaben für verschiedene Niveaus können sinnvoll sein. Eine Möglichkeit: Selbsteinschätzung kombiniert mit diagnostischen Aufgaben, um das Vorwissen zu erfassen. Dann gestufte KI-Nutzung. Mehr dazu im Leitfaden unter Der Expertise-Umkehr-Effekt und Unterstützung anpassen.\n\n\n\n\n\nTechnik und Informatik: KI-Nutzung nach Expertise differenzieren\nIn der Informatik ist die Situation noch komplizierter. Studierende im Web-Development-Kurs kennen teilweise GitHub Copilot sehr gut. Die Frage ist nicht mehr, ob sie KI nutzen, sondern wie.\nFrage: Wenn hohe Unterstützung bei Experten schaden kann: Heisst das, dass fortgeschrittenen Studierenden abgeraten werden sollte, Copilot zu nutzen? Das scheint realitätsfern, denn in der Industrie arbeitet heute jeder damit. Oder geht es darum, dass sie Copilot anders nutzen sollten als Anfänger? Wie kann das in Übungsaufgaben berücksichtigt werden, wenn die “Schwelle” bei jedem anders liegt und sich während des Semesters verschiebt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDer Expertise-Umkehr-Effekt bezieht sich auf Instruktion, nicht auf Werkzeugnutzung per se. Fortgeschrittene können KI produktiv nutzen, weil sie den Output bewerten können. Die Frage ist: Nutzen sie KI als Abkürzung (problematisch) oder als Effizienzwerkzeug bei bereits verstandenen Konzepten (ok)? Mehr dazu im Leitfaden unter Kognition erweitern vs. ersetzen.\n\n\n\n\n\nWirtschaft: Fallstudien und direkte Instruktion\nDas wirft eine grundsätzliche didaktische Frage auf: In Einführungskursen Marketing wird viel mit Fallstudien gearbeitet. Die Annahme ist oft, dass selbstständiges Problemlösen die beste Methode ist, “Learning by doing”.\nFrage: Könnte das für Erstsemester-Studierende, die noch keine Marketingkonzepte kennen, zu wenig Struktur sein? Müsste am Anfang mehr direkte Instruktion gegeben werden, bevor es an die Fälle geht? Und wenn Studierende dann KI-Tools wie ChatGPT nutzen, um ihre Fallanalysen zu schreiben: Ist das dann quasi eine Form von Unterstützung, die Anfänger brauchen, oder verhindert es genau den Lerneffekt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nFür Novizen ist direkte Instruktion mit Worked Examples tatsächlich oft effektiver als problembasiertes Lernen. KI-Nutzung ist aber nicht dasselbe wie gute Instruktion: KI gibt Antworten, aber nicht didaktisch strukturierte Erklärungen. Die Sequenz wäre: Erst Grundlagen vermitteln (direkte Instruktion), dann angeleitete Übung, dann selbstständige Anwendung, dann KI als Werkzeug. Mehr dazu im Leitfaden unter Explizite Instruktion und Worked Examples.\n\n\n\n\n\nKünste: Grundlagen vor generativen Tools\nIn der künstlerischen Ausbildung ist die Situation speziell: Kreativität entsteht oft gerade durch Einschränkungen und durch das Ringen mit dem Material.\nFrage: Wenn Studierende ihre Gehörbildungsübungen oder Harmonielehre-Aufgaben mit KI-Tools lösen, einige können schon ganz gut harmonisieren, andere kämpfen noch mit Grundlagen, wo liegt da die Grenze? Bei den Fortgeschrittenen könnte KI als “Sparringpartner” funktionieren, um verschiedene Varianten durchzuspielen. Aber schadet es den Anfängern nicht fundamental, wenn sie die KI Lösungen generieren lassen, bevor sie überhaupt ein intuitives Gefühl für Stimmführung entwickelt haben? Wie unterscheidet man zwischen “hilfreicher Unterstützung” und “verhindert den grundlegenden Lernprozess”?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nIn künstlerischen Fächern ist das “Ringen mit dem Material” besonders wichtig. Die intuitive Kompetenz entwickelt sich durch Übung, nicht durch Betrachtung von KI-Output. Für Anfänger ist KI-Nutzung hier wahrscheinlich kontraproduktiv. Für Fortgeschrittene kann KI als Experimentierfeld dienen. Die Schwelle liegt dort, wo die Grundlagen internalisiert sind. Mehr dazu im Leitfaden unter Der Expertise-Umkehr-Effekt und Prozeduralisierung.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nDer Expertise-Umkehr-Effekt\nUnterstützung anpassen\nExplizite Instruktion",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Der Expertise-Umkehr-Effekt"
    ]
  },
  {
    "objectID": "qa/kritisches-denken/index.html#anwendungsfragen",
    "href": "qa/kritisches-denken/index.html#anwendungsfragen",
    "title": "Kritisches Denken und Fachwissen",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Subtile Fehler erkennen ohne Grundwissen\nIm Unterricht von Anatomie und Physiologie im ersten Semester Pflege nutzen Studierende ChatGPT für Zusammenfassungen, obwohl sie noch kein fundiertes Grundwissen haben.\nFrage: Wie soll man reagieren, wenn Studierende KI-generierte Erklärungen zu einem Krankheitsbild zeigen, die subtile Fehler enthalten, die sie selbst nicht erkennen können? Sollte die Nutzung komplett verboten werden in dieser Phase, oder wie baut man gezielt die Fähigkeit auf, KI-Outputs kritisch zu prüfen, wenn das Fachwissen noch fehlt?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Dilemma ist real: Um KI kritisch zu prüfen, braucht man das Wissen, das man aufbauen will. In frühen Phasen ist Zurückhaltung bei KI-Nutzung sinnvoll. Die Fähigkeit zur Prüfung entwickelt sich mit dem Fachwissen. Gemeinsame Analyse von KI-Fehlern kann lehrreich sein, wenn die Grundlagen vorhanden sind. Mehr dazu im Leitfaden unter Kritisches Denken erfordert Fachwissen und Was transferiert, und was nicht.\n\n\n\n\n\nTechnik und Informatik: Code verstehen vs. Code produzieren\nDie Situation in der Informatik ist paradox: Studierende nutzen GitHub Copilot und ChatGPT für Code, aber viele verstehen die Grundlagen nicht wirklich. Es kommt vor, dass Code eingereicht wird, der funktioniert, aber nicht erklärt werden kann.\nFrage: Willingham sagt, kritisches Denken ist kontextabhängig. Heisst das, dass zuerst darauf bestanden werden muss, dass Studierende ohne KI die Grundlagen lernen? Oder soll ihnen beigebracht werden, KI-generierten Code zu lesen und zu bewerten, auch wenn sie ihn noch nicht selbst schreiben könnten?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nFunktionierender Code, den man nicht versteht, ist ein Symptom für fehlendes Grundlagenwissen. Die Fähigkeit, Code zu bewerten, setzt Verständnis voraus. Die Sequenz “erst selbst schreiben, dann mit KI arbeiten” ist wahrscheinlich effektiver. Code Review als Lernmethode kann helfen, erfordert aber bereits Grundwissen. Mehr dazu im Leitfaden unter Evidenz für Domänenspezifität.\n\n\n\n\n\nSoziale Arbeit: KI und professionelle Urteilsfähigkeit\nIn der Sozialen Arbeit geht es viel um Fallanalyse und professionelle Urteilsfähigkeit. Studierende verwenden zunehmend ChatGPT, um Fallsituationen zu analysieren oder Interventionsvorschläge zu entwickeln.\nFrage: Das Problem: Sie können noch nicht einschätzen, ob die KI wichtige Kontextfaktoren übersieht oder zu vereinfachte Lösungen vorschlägt. Wenn kritisches Denken wirklich so stark vom Fachwissen abhängt, wie strukturiert man die Kurse? Erst Theorie und Praxis ohne KI, dann später mit KI? Oder integriert man KI von Anfang an als Diskussionspartner, dessen Schwächen gemeinsam analysiert werden?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Fähigkeit, Kontextfaktoren zu erkennen, ist das, was Experten von Novizen unterscheidet. Gemeinsame Analyse von KI-Output kann lehrreich sein, wenn Dozierende die Schwächen aufzeigen. Die Gefahr ist, dass Studierende allein nicht erkennen können, was fehlt. Sequenzierung (erst Grundlagen) ist wahrscheinlich sicherer. Mehr dazu im Leitfaden unter Angewendet auf KI-Bewertung und Die zentrale Implikation.\n\n\n\n\n\nWirtschaft: Oberflächliche Analysen erkennen\nStudierende im Bachelor Business Administration nutzen KI-Tools für Marktanalysen und Businesspläne. Es kommt vor, dass Wettbewerbsanalysen präsentiert werden, die auf ChatGPT basieren. Die Struktur ist gut, aber die strategischen Schlussfolgerungen sind oberflächlich und teilweise falsch.\nFrage: Studierende können nicht beurteilen, was fehlt, weil ihnen das betriebswirtschaftliche Fundament fehlt. Wie geht man damit um in Modulen, wo genau diese Analysefähigkeit aufgebaut werden soll? Muss KI-Nutzung in den ersten Semestern eingeschränkt werden, oder gibt es einen Weg, damit zu arbeiten, ohne dass das Grundlagenlernen leidet?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDas Problem illustriert genau den Punkt: Ohne Fachwissen kann man die Qualität nicht beurteilen. Einschränkung in frühen Phasen ist wahrscheinlich nötig, um die Analysefähigkeit aufzubauen. Später kann KI als Werkzeug dienen, dessen Output kritisch geprüft wird. Die Fähigkeit zur Prüfung entwickelt sich aber erst mit dem Wissen. Mehr dazu im Leitfaden unter Fach-spezifisches Lernen priorisieren.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nKritisches Denken erfordert Fachwissen\nWillinghams Herausforderung\nWas transferiert, und was nicht",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Kritisches Denken und Fachwissen"
    ]
  },
  {
    "objectID": "qa/praktische-implikationen/index.html#anwendungsfragen",
    "href": "qa/praktische-implikationen/index.html#anwendungsfragen",
    "title": "Praktische Implikationen für die Lehre",
    "section": "Anwendungsfragen",
    "text": "Anwendungsfragen\n\nGesundheit: Grundlagen sicherstellen in der Praxis\nDie Aussage, dass Grundlagen vor Werkzeugen kommen müssen, ist relevant für die Physiotherapie. Im ersten Jahr lernen Studierende die Anatomie und die manuelle Befundaufnahme. Es zeigt sich aber immer mehr, dass sie ChatGPT nutzen, um Diagnosen zu “checken” oder Behandlungspläne zu erstellen, ohne die muskuloskelettalen Zusammenhänge wirklich zu verstehen.\nFrage: Wie kann konkret sichergestellt werden, dass Studierende diese Grundlagen wirklich beherrschen, bevor sie KI-Tools nutzen? Sollte die Nutzung in den ersten Semestern komplett verboten werden, oder gibt es einen Weg, KI so einzusetzen, dass sie das Verständnis fördert statt ersetzt? Bei praktischen Prüfungen am Patienten zeigt sich nämlich, dass einige zwar theoretisch viel wissen, aber die Hände nicht richtig einsetzen können.\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie praktischen Fertigkeiten (“Hände einsetzen”) erfordern Prozeduralisierung, die nur durch Übung entsteht. KI kann hier nicht helfen. Formative Assessments ohne KI können den Lernstand erfassen. In frühen Phasen ist Zurückhaltung sinnvoll, später kann KI als Werkzeug dienen, dessen Vorschläge kritisch geprüft werden. Mehr dazu im Leitfaden unter Prozeduralisierung: Vom Wissen zum Können und Übungsphasen schützen.\n\n\n\n\n\nTechnik und Informatik: Differenzierung nach Niveau\nDie Aussage “Expertise bestimmt den Nutzen” ist interessant. Im Software Engineering zeigt sich genau dieses Paradox: Studierende nutzen GitHub Copilot und ChatGPT schon ab dem ersten Semester für ihre Programmieraufgaben. Die fortgeschrittenen Studierenden nutzen es effektiv als Pair-Programming-Partner, aber die Anfänger kopieren Code, den sie nicht verstehen.\nFrage: Wie unterscheidet man in der Aufgabenstellung zwischen Anfängern und Fortgeschrittenen? Sollten für Erstsemester andere Regeln gelten als für Masterstudierende? Und wie formuliert man Programmieraufgaben so, dass auch mit KI-Unterstützung noch echtes Lernen stattfindet? Reicht es, wenn verlangt wird, dass sie den generierten Code erklären können, oder braucht es fundamentale Coding-Aufgaben komplett ohne KI?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDifferenzierung nach Niveau ist sinnvoll. Für Anfänger: Grundlagen ohne KI aufbauen. Für Fortgeschrittene: KI als Werkzeug erlauben, aber Verständnis prüfen. Code erklären lassen ist ein guter Ansatz, aber nicht ausreichend. Auch: Code modifizieren, Fehler finden, auf neue Probleme anwenden. Mehr dazu im Leitfaden unter Der Expertise-Umkehr-Effekt und Entscheidungsrahmen.\n\n\n\n\n\nHAFL: Notwendige Grundlagen vs. delegierbare Berechnungen\nDie Aussage “Effort is the signal” und dass zu einfaches Lernen kein echtes Lernen ist, wirft Fragen auf. An der HAFL arbeiten Studierende viel mit Berechnungen zu Nährstoffkreisläufen, Bodenqualität und Ertragsprognosen. Früher haben sie das mühsam von Hand oder mit Excel durchgerechnet, heute können sie das alles von KI-Tools machen lassen.\nFrage: Müssen Studierende diese Berechnungen wirklich noch selbst durchführen können, oder reicht es, wenn sie die Resultate interpretieren und validieren können? In der Praxis auf dem Betrieb werden sie ja auch digitale Tools nutzen. Wo genau liegt die Grenze zwischen “nötigem Aufwand für Verständnis” und “ineffizienter Zeitverschwendung”? Welche Grundlagen sind wirklich unverzichtbar, und wo darf die KI die mühsame Arbeit übernehmen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Grenze liegt dort, wo Verstehen nötig ist, um Fehler zu erkennen und Anpassungen vorzunehmen. Routine-Berechnungen können delegiert werden, wenn die Konzepte verstanden sind. Die Frage ist: Können sie erkennen, wenn das Tool einen unrealistischen Wert ausgibt? Können sie bei veränderten Bedingungen anpassen? Das erfordert konzeptuelles Verständnis. Mehr dazu im Leitfaden unter Der stärkste Gegeneinwand und Kognition erweitern vs. ersetzen.\n\n\n\n\n\nSoziale Arbeit: KI als Tutor, nicht als Antwortgeber\nDer Punkt “KI als Tutor, nicht als Antwortgeber” ist relevant für die Soziale Arbeit. Es geht viel um Fallanalysen und die Entwicklung von Interventionsstrategien. Studierende müssen lernen, komplexe soziale Situationen zu verstehen und ethisch reflektierte Entscheidungen zu treffen.\nFrage: Wenn KI als “Tutor” eingesetzt werden soll, der das Denken stimuliert: Wie macht man das konkret? Sollten Prompts vorgegeben werden, mit denen Studierende Fälle diskutieren? Oder sollten sie aufgefordert werden, ihre eigenen Lösungsansätze zuerst zu entwickeln und dann mit der KI zu reflektieren? Die Sorge ist, dass die KI zu schnell fertige “Lösungen” anbietet, obwohl es in der Sozialen Arbeit selten eindeutige Antworten gibt. Wie verhindert man, dass Studierende die KI-Antworten als “richtig” übernehmen, statt kritisch zu hinterfragen?\n\n\n\n\n\n\nTippHinweise zur Antwort\n\n\n\n\n\nDie Sequenz “erst eigene Lösung, dann Reflexion mit KI” ist vielversprechend. Wichtig ist, dass KI nicht als Autorität wahrgenommen wird. Strukturierte Prompts können helfen, KI als Diskussionspartner zu nutzen, nicht als Antwortgeber. Die Gefahr der vorschnellen “Lösung” ist real. Gemeinsame Analyse von KI-Grenzen kann helfen. Mehr dazu im Leitfaden unter Sokratisches Fragen in KI-Tutoren und KI-Tutoren evaluieren.\n\n\n\n\n\n\n\n\n\n\nHinweisVertiefte Informationen\n\n\n\nMehr zu diesem Thema im Leitfaden:\n\nImplikationen und offene Fragen\nKognition erweitern vs. ersetzen\nEntscheidungsrahmen\nFazit",
    "crumbs": [
      "Präsentation",
      "Themen",
      "Praktische Implikationen für die Lehre"
    ]
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#ein-überraschendes-ergebnis",
    "href": "slides/ai-higher-ed/index.html#ein-überraschendes-ergebnis",
    "title": "KI in der Hochschulbildung",
    "section": "Ein überraschendes Ergebnis",
    "text": "Ein überraschendes Ergebnis\n\n\n\nMit KI-Zugang:\n\n+48% / +127%\nAufgaben korrekt gelöst\nGPT Base / GPT Tutor\n\nOhne KI (später):\n\n−17% / ±0%\nvs. Kontrollgruppe\nGPT Base / GPT Tutor\n\n\n\n\nQuelle: Bastani u. a. (2025):\n~1000 Gymnasiasten, GPT-4 Zugang während Mathe-Übungen\n\n\nIch möchte mit einem überraschenden Befund beginnen, der die Komplexität unseres Themas illustriert.\nIn einer gross angelegten Studie mit etwa 1000 Gymnasiasten in der Türkei erhielten Schüler Zugang zu GPT-4 während ihrer Mathematik-Übungen. Zwei Gruppen: GPT Base (uneingeschränkter Zugang) und GPT Tutor (mit pädagogischen Leitplanken).\n[KLICK] GPT Base: 48% mehr Aufgaben gelöst während der Übung.\n[KLICK] GPT Tutor sogar 127% mehr, also mehr als doppelt so viele.\n[KLICK] Aber dann kam die Prüfung ohne KI. GPT Base: 17% schlechter als die Kontrollgruppe.\n[KLICK] GPT Tutor: Kein signifikanter Unterschied zur Kontrollgruppe.\nDas ist die zentrale Spannung: Uneingeschränkter KI-Zugang führt zu besserer Performance, aber schlechterem Lernen. Die pädagogischen Leitplanken neutralisieren den Schaden, bringen aber auch keinen Lernvorteil."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-paradox",
    "href": "slides/ai-higher-ed/index.html#das-paradox",
    "title": "KI in der Hochschulbildung",
    "section": "Das Paradox",
    "text": "Das Paradox\n\n\n\n\nAufgabenleistung ≠ Lernen\n\nHier sehen wir das Paradox visualisiert.\nDie magentafarbene Linie zeigt die Gruppe mit KI-Zugang, die graue die Kontrollgruppe ohne KI.\nIn der Übungsphase links performt die KI-Gruppe deutlich besser. Das macht Sinn: Sie hatten ja Hilfe. Der Unterschied ist klar, die Fehlerbalken überlappen nicht.\nAber schauen Sie, was beim Test passiert. Die KI-Gruppe schneidet tendenziell schlechter ab, aber beachten Sie die Fehlerbalken: Sie überlappen sich. Der Unterschied ist statistisch nicht so dramatisch, wie die Linien allein suggerieren würden.\n[KLICK] Die Kernaussage: Aufgabenleistung ist nicht dasselbe wie Lernen. Wir verwechseln oft Performanz mit Kompetenz. Wenn Studierende mit KI-Hilfe eine Aufgabe lösen, sehen wir die Performanz des Systems, nicht unbedingt das Lernen des Studierenden."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#das-nadelöhr-des-lernens",
    "href": "slides/ai-higher-ed/index.html#das-nadelöhr-des-lernens",
    "title": "KI in der Hochschulbildung",
    "section": "Das Nadelöhr des Lernens",
    "text": "Das Nadelöhr des Lernens\n\n\n\n\n\n\n\n\n\n\n\n Kernaussage: Alles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses (Sweller 2024).\n\n\nUm zu verstehen, warum das passiert, müssen wir einen kurzen Ausflug in die Kognitionspsychologie machen.\nHier sehen Sie ein vereinfachtes Modell des menschlichen Gedächtnisses. Links die neue Information, rechts das Langzeitgedächtnis, und in der Mitte: das Nadelöhr.\nDas Arbeitsgedächtnis hat eine stark begrenzte Kapazität: etwa 4 plus/minus 1 Elemente gleichzeitig. Neue Information links ist unbegrenzt. Das Langzeitgedächtnis rechts ist praktisch unbegrenzt. Aber alles, was von links nach rechts wandern soll, muss durch dieses enge Nadelöhr.\n[KLICK] Das ist die Kernaussage der Cognitive Load Theory: Alles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses. Es gibt keinen Weg drumherum. Keine Abkürzung. Keine KI kann diesen biologischen Engpass umgehen."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#erwünschte-schwierigkeiten",
    "href": "slides/ai-higher-ed/index.html#erwünschte-schwierigkeiten",
    "title": "KI in der Hochschulbildung",
    "section": "Erwünschte Schwierigkeiten",
    "text": "Erwünschte Schwierigkeiten\n\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\n\n\nRobert Bjork (Bjork und Bjork 2011)\n\n\n\n\nSchwerer fühlt sich schlechter an, ist aber besser für langfristiges Lernen.\n\n\nDas bringt uns zu einem kontraintuitiven Konzept: den erwünschten Schwierigkeiten, oder auf Englisch “Desirable Difficulties”.\nHier ein Zitat von Robert Bjork: “Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\nÜbersetzt: Bedingungen, die das scheinbare Lernen verlangsamen, optimieren oft das langfristige Behalten und den Transfer.\n[KLICK] Oder noch kürzer: Schwerer fühlt sich schlechter an, ist aber besser für langfristiges Lernen.\nDas ist ein fundamentales Prinzip, das wir immer wieder vergessen. Wenn Lernen sich leicht anfühlt, lernen wir wahrscheinlich weniger, als wenn es sich anstrengend anfühlt."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-vier-strategien",
    "href": "slides/ai-higher-ed/index.html#die-vier-strategien",
    "title": "KI in der Hochschulbildung",
    "section": "Die vier Strategien",
    "text": "Die vier Strategien\n\n\n\n\n\nSelbst generieren\nEigene Antworten formulieren\n\n\n\nVerteilt lernen\nZeitliche Abstände einbauen\n\n\n\nAktiv abrufen\nWissen aus dem Gedächtnis holen\n\n\n\nVariieren\nThemen und Aufgaben mischen\n\n\n\n\n KI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit übernimmt.\n\n\nBjork hat vier konkrete Strategien identifiziert, die als erwünschte Schwierigkeiten fungieren:\n[KLICK] Erstens, selbst generieren. Eigene Antworten formulieren, statt vorgegebene zu lesen.\n[KLICK] Zweitens, verteilt lernen. Zeitliche Abstände einbauen.\n[KLICK] Drittens, aktiv abrufen. Wissen aus dem Gedächtnis holen, statt es nachzuschlagen.\n[KLICK] Viertens, variieren. Themen und Aufgabentypen mischen.\n[KLICK] Und hier kommt der kritische Punkt: KI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit übernimmt.\nWarum selbst generieren, wenn KI es besser kann? Warum sich anstrengen, wenn die Antwort einen Klick entfernt ist? Warum aus dem Gedächtnis abrufen, wenn ich nachfragen kann?"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-entscheidende-frage",
    "href": "slides/ai-higher-ed/index.html#die-entscheidende-frage",
    "title": "KI in der Hochschulbildung",
    "section": "Die entscheidende Frage",
    "text": "Die entscheidende Frage\n\n\nDasselbe Werkzeug, unterschiedliche Ergebnisse.\n\n\n\n\n Taschenrechner helfen Mathematikern, können aber Lernenden schaden.\n GPS unterstützt Taxifahrer, schwächt aber das räumliche Gedächtnis von Neulingen.\n\n\n\n\n\nDie Frage ist nicht ob KI, sondern wer davon profitiert.\n\n\n\n\nDie Antwort liegt in dem, was Experten von Lernenden unterscheidet.\n\nDas bringt uns zur entscheidenden Frage.\nDasselbe Werkzeug, unterschiedliche Ergebnisse.\n[KLICK] Taschenrechner helfen Mathematikern enorm. Aber für Lernende, die gerade erst das Rechnen verstehen sollen, können sie schädlich sein.\nGPS unterstützt Taxifahrer bei der Navigation. Aber es schwächt nachweislich das räumliche Gedächtnis von Menschen, die es noch nicht aufgebaut haben.\n[KLICK] Die Frage ist also nicht, OB KI nützt oder schadet. Die Frage ist: WER profitiert und wer nicht?\n[KLICK] Die Antwort liegt in dem, was Experten von Lernenden unterscheidet."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-experten-sehen",
    "href": "slides/ai-higher-ed/index.html#was-experten-sehen",
    "title": "KI in der Hochschulbildung",
    "section": "Was Experten sehen",
    "text": "Was Experten sehen\n\n\n\n\n\n\nNovize: sieht Einzelteile\n“64 Felder, 32 Figuren, viele Möglichkeiten”\n. . .\nExperte: sieht Muster und Bedeutung\n“Sizilianische Verteidigung, Königsangriff möglich, Schwäche auf f7”\n. . .\n\nExperten speichern Wissen in Chunks: vernetzte Wissensstrukturen, die automatisch abgerufen werden (Groot und Groot 1978; Chase und Simon 1973).\n\n\nSchauen wir uns an, was Experten von Novizen unterscheidet. Das klassische Beispiel kommt aus der Schachforschung.\nWas sieht ein Novize? 64 Felder, 32 Figuren, viele Möglichkeiten. Er sieht die Einzelteile.\n[KLICK] Was sieht ein Experte? “Sizilianische Verteidigung, Königsangriff möglich, Schwäche auf f7.” Er sieht Muster und Bedeutung.\n[KLICK] Das ist der fundamentale Unterschied. Experten speichern Wissen in sogenannten “Chunks”: vernetzte Wissensstrukturen, die automatisch abgerufen werden.\nEin Schachmeister hat etwa 50.000 solcher Chunks im Langzeitgedächtnis. Die Forschung dazu geht auf de Groot zurück und wurde von Chase und Simon quantifiziert."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#kritisches-denken-braucht-fachwissen",
    "href": "slides/ai-higher-ed/index.html#kritisches-denken-braucht-fachwissen",
    "title": "KI in der Hochschulbildung",
    "section": "Kritisches Denken braucht Fachwissen",
    "text": "Kritisches Denken braucht Fachwissen\n\n\n“Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\nDaniel Willingham (Willingham 2008)\n\n\n\n\n\nBiomedizin-Experte:\nErkennt, wenn ChatGPT bei Biochemie falsch liegt\n\nNovize:\nKann diese Bewertung nicht vornehmen\n\n\n\n\nDu kannst nicht kritisch bewerten, was du nicht verstehst.\n\n\n\nWarum ist Fachwissen so entscheidend? Weil es bestimmt, ob KI deine Kognition erweitert oder ersetzt.\n\nAn diesem Punkt höre ich oft einen Einwand: “Dann bringen wir den Studierenden eben bei, KI-Output kritisch zu prüfen.”\nAber hier kommt ein wichtiger Punkt von Daniel Willingham: Kritisches Denken ist keine kontextfreie Fähigkeit. Man kann nicht einfach “kritisch denken lernen” und es dann überall anwenden.\n[KLICK] Ein Biomedizin-Experte erkennt, wenn ChatGPT bei Biochemie falsch liegt. Ein Novize kann diese Bewertung nicht vornehmen.\n[KLICK] Die Kernaussage: Du kannst nicht kritisch bewerten, was du nicht verstehst.\n[KLICK] Und genau deshalb ist Fachwissen so entscheidend."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#kognition-erweitern-vs.-ersetzen",
    "href": "slides/ai-higher-ed/index.html#kognition-erweitern-vs.-ersetzen",
    "title": "KI in der Hochschulbildung",
    "section": "Kognition erweitern vs. ersetzen",
    "text": "Kognition erweitern vs. ersetzen\n\n\n\n Kognition erweitern:\n\n\nMensch bleibt kognitiv engagiert\nWerkzeug verstärkt, ersetzt nicht\nFähigkeiten bleiben erhalten\n\n\n Kognition ersetzen:\n\n\nMensch wird passiv\nWerkzeug übernimmt das Denken\nAbhängigkeit entsteht\n\n\n\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung (Clark 2025).\n\nAndy Clark, ein Philosoph, hat eine nützliche Unterscheidung eingeführt.\n[KLICK] Kognition erweitern: Der Mensch bleibt kognitiv engagiert. Das Werkzeug verstärkt, ersetzt nicht. Die Fähigkeiten bleiben erhalten.\n[KLICK] Kognition ersetzen: Der Mensch wird passiv. Das Werkzeug übernimmt das Denken. Es entsteht Abhängigkeit.\n[KLICK] Und hier ist der wichtige Punkt: Dasselbe Werkzeug kann beides sein, abhängig von der Nutzung.\nChatGPT kann ein Brainstorming-Partner sein, der die eigene Kreativität verstärkt. Oder es kann ein Ghostwriter sein, der das Denken ersetzt. Die Frage ist nicht das Werkzeug. Die Frage ist die Nutzung."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#die-kernaussage",
    "href": "slides/ai-higher-ed/index.html#die-kernaussage",
    "title": "KI in der Hochschulbildung",
    "section": "Die Kernaussage",
    "text": "Die Kernaussage\n\n\nKI-Werkzeuge sind für Experten gemacht.\n\n\n\n\n\nSie machen Experten produktiver.\n\n\nLernende profitieren oft nicht, weil Lernen die kognitive Anstrengung erfordert, die KI zu eliminieren droht.\n\n\n\n\n\nLernende brauchen erst das Fundament, das kritische KI-Nutzung ermöglicht.\n\n\n[Pause, dann KLICK] KI-Werkzeuge sind für Experten gemacht.\n[KLICK] Das ist keine Wertung, sondern eine Feststellung. Diese Werkzeuge wurden von Experten entwickelt und funktionieren am besten für Menschen, die bereits wissen, was sie tun.\nSie machen Experten produktiver.\n[KLICK] Aber: Lernende profitieren oft nicht. Lernen erfordert genau die kognitive Anstrengung, die KI zu eliminieren droht.\nDas ist nicht KI-Feindlichkeit. Lernen braucht Anstrengung. KI kann diese Anstrengung reduzieren, wenn sie passiv genutzt wird. Aber: Es ist nicht unvermeidlich. Erinnern Sie sich an den GPT-Tutor? Die Art der Nutzung entscheidet.\n[KLICK] Die Konsequenz: Lernende brauchen erst das Fundament, das kritische KI-Nutzung ermöglicht. Nicht “keine KI”, aber “Fundament zuerst”."
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#was-bedeutet-das-für-die-lehre",
    "href": "slides/ai-higher-ed/index.html#was-bedeutet-das-für-die-lehre",
    "title": "KI in der Hochschulbildung",
    "section": "Was bedeutet das für die Lehre?",
    "text": "Was bedeutet das für die Lehre?\n\n\n\n\n\nAnstrengung ist das Signal\n\n\n\nKI als Tutor, nicht als Antwortgeber\n\n\n\nExpertise bestimmt den Nutzen\n\n\n\n\nWenn Lernen sich zu leicht anfühlt, findet es wahrscheinlich nicht statt.\n\nKI soll Denkprozesse anregen, nicht ersetzen.\n\nDasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.\n\n\n\n\nGrundlagen BEVOR Werkzeuge\n\nZum Abschluss: Was bedeutet das konkret für unsere Lehre?\n[KLICK] Erstens: Anstrengung ist das Signal. Wenn Lernen sich zu leicht anfühlt, findet es wahrscheinlich nicht statt.\n[KLICK] Zweitens: KI als Tutor, nicht als Antwortgeber. KI soll Denkprozesse anregen, nicht ersetzen.\n[KLICK] Drittens: Expertise bestimmt den Nutzen. Dasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen.\n[KLICK] Und die Zusammenfassung: Grundlagen BEVOR Werkzeuge.\nErst das Fundament, dann die Erweiterung. Erst verstehen, dann automatisieren. Erst selbst können, dann delegieren.\nVielen Dank."
  },
  {
    "objectID": "notes/speaker-notes-short.html",
    "href": "notes/speaker-notes-short.html",
    "title": "Speaker Notes: KI in der Hochschulbildung (Kurzversion)",
    "section": "",
    "text": "= Klick auf Folie |  = Kernaussage |  = Kurs-Hinweis\n\n1 Ein überraschendes Ergebnis\nSprechtext:\nIch möchte mit einem überraschenden Befund beginnen, der die Komplexität unseres Themas illustriert.\nIn einer gross angelegten Studie mit etwa 1000 Gymnasiasten in der Türkei erhielten Schüler Zugang zu GPT-4 während ihrer Mathematik-Übungen.\n\nDie Ergebnisse während der Übungsphase waren beeindruckend: Die Schüler mit KI-Zugang lösten 48 Prozent mehr Aufgaben korrekt.\n\nKlingt nach einem Erfolg, oder? Aber dann kam der Test. Und zwar ohne KI-Zugang.\n\nDie Gruppe, die zuvor mit KI geübt hatte, schnitt 17 Prozent schlechter ab als die Kontrollgruppe, die nie KI-Zugang hatte.\n\n\n\n\n\n\n\nWarnung Kernaussage\n\n\n\nMehr Aufgaben gelöst bedeutet nicht automatisch mehr gelernt.\n\n\n\n\n\n\n\n\nHinweisHintergrund zur Bastani-Studie\n\n\n\nDie Studie von Bastani et al. (2025) “Generative AI Can Harm Learning” ist eine der ersten rigorosen randomisierten kontrollierten Studien zu KI im Bildungskontext. Die Autoren sind von der Harvard Business School und MIT.\nWichtige Details:\n\nCa. 1000 türkische Gymnasiasten, 9. Klasse\nFach: Mathematik\nIntervention: GPT-4 Zugang während Übungsphasen\nDer 17%-Nachteil betraf den direkten GPT-4-Zugang\n\nPraktische Einordnung der Effektstärke:\nDer 17%-Nachteil klingt dramatisch, sollte aber eingeordnet werden. In der Studie entspricht dies etwa 0.2-0.3 Standardabweichungen, ein kleiner bis mittlerer Effekt. Zum Vergleich: Der Unterschied zwischen einem Schüler auf dem 50. und dem 40. Perzentil. Relevant, aber kein Totalausfall.\nDer GPT-Tutor-Befund (oft übersehen):\nDie Studie testete auch einen “GPT Tutor” mit pädagogischen Leitplanken: Das System gab keine direkten Antworten, sondern Hinweise und Fragen. Diese Bedingung zeigte deutlich bessere Ergebnisse als der direkte GPT-4-Zugang. Das ist ein zentraler Befund: Das Problem ist nicht KI an sich, sondern wie KI eingesetzt wird. Ein gut designtes KI-Tutoring-System kann die negativen Effekte abmildern oder vermeiden.\nEinschränkungen:\n\nSpezifischer Kontext (Türkei, Mathematik, Gymnasium)\nKurzfristige Messung (Wochen, nicht Semester)\nReplikationen stehen aus\nGeneralisierung auf Schweizer Hochschulstudierende in anderen Fächern erfordert Vorsicht\n\nDennoch wichtig: Die Kernaussage, dass Aufgabenleistung und Lernen auseinanderfallen können, ist theoretisch gut fundiert und deckt sich mit der Cognitive Load Theory. Und der GPT-Tutor-Befund zeigt einen Weg nach vorne.\n\n\n\n\n\n2 Das Paradox\nSprechtext:\nHier sehen wir das Paradox visualisiert.\nDie magentafarbene Linie zeigt die Gruppe mit KI-Zugang, die graue die Kontrollgruppe ohne KI.\nIn der Übungsphase links performt die KI-Gruppe deutlich besser. Das macht Sinn: Sie hatten ja Hilfe. Der Unterschied ist klar, die Fehlerbalken überlappen nicht.\nAber schauen Sie, was beim Test passiert, bei dem beide Gruppen ohne KI arbeiten mussten. Die KI-Gruppe schneidet tendenziell schlechter ab, aber beachten Sie die Fehlerbalken: Sie überlappen sich. Der Unterschied ist statistisch nicht so dramatisch, wie die Linien allein suggerieren würden.\nDas ist wichtig für die ehrliche Interpretation: Der Vorteil während der Übung ist verschwunden, und es gibt Hinweise auf einen Nachteil, aber wir sollten die Unsicherheit nicht ignorieren.\n\n\n\n\n\n\n\nWarnung Kernaussage\n\n\n\nAufgabenleistung ist nicht dasselbe wie Lernen.\n\n\nWir verwechseln oft Performanz mit Kompetenz. Wenn Studierende mit KI-Hilfe eine Aufgabe lösen, sehen wir die Performanz des Systems, nicht unbedingt das Lernen des Studierenden. Und selbst wenn der Nachteil in dieser einen Studie nicht riesig war: Der erwartete Lernvorteil blieb aus.\n\n\n\n\n\n\nHinweisHintergrund: Performance vs. Learning\n\n\n\nDiese Unterscheidung geht auf Robert Bjork zurück, einen führenden Gedächtnisforscher. Er unterscheidet:\n\nPerformance: Momentane Leistung unter bestimmten Bedingungen\nLearning: Dauerhafte Veränderung im Langzeitgedächtnis\n\nDie beiden können dissoziieren. Hohe Performance während des Übens (mit Hilfe) kann mit niedrigem Learning einhergehen. Umgekehrt kann niedrige Performance während des Übens (ohne Hilfe, mit Anstrengung) zu hohem Learning führen.\nDas ist keine neue Erkenntnis. Jeder Sporttrainer weiss, dass Training härter sein muss als der Wettkampf. Was neu ist: KI macht es extrem einfach, Performance ohne Learning zu erreichen.\n\n\n\n\n\n3 Das Nadelöhr des Lernens\nSprechtext:\nUm zu verstehen, warum das passiert, müssen wir einen kurzen Ausflug in die Kognitionspsychologie machen.\nHier sehen Sie ein vereinfachtes Modell des menschlichen Gedächtnisses. Links die neue Information, rechts das Langzeitgedächtnis, und in der Mitte: das Nadelöhr.\nDas Arbeitsgedächtnis hat eine stark begrenzte Kapazität. Die aktuelle Forschung spricht von etwa 4 plus/minus 1 Elementen, die wir gleichzeitig aktiv verarbeiten können.\nNeue Information links ist unbegrenzt. Das Langzeitgedächtnis rechts ist praktisch unbegrenzt. Aber alles, was von links nach rechts wandern soll, muss durch dieses enge Nadelöhr.\n\n\n\n\n\n\n\nWarnung Kernaussage\n\n\n\nAlles Lernen muss durch das Nadelöhr des Arbeitsgedächtnisses.\nEs gibt keinen Weg drumherum. Keine Abkürzung. Keine KI kann diesen biologischen Engpass umgehen.\n\n\n\n\n\n\n\n\nHinweisHintergrund: Cognitive Load Theory\n\n\n\nDie Cognitive Load Theory wurde von John Sweller in den 1980er Jahren entwickelt und ist heute eine der einflussreichsten Theorien im Instruktionsdesign.\nDie drei Arten von Cognitive Load:\n\nIntrinsic Load: Inherente Komplexität des Materials (nicht reduzierbar ohne Vereinfachung)\nExtraneous Load: Unnötige kognitive Belastung durch schlechtes Design (zu minimieren)\nGermane Load: Produktive Anstrengung, die zum Lernen führt (zu optimieren)\n\nWarum das für KI relevant ist:\nWenn KI die kognitive Arbeit übernimmt, reduziert sie potenziell den Germane Load. Das ist gut für Experten (weniger Routinearbeit), aber schlecht für Lernende (weniger Lernarbeit).\nDie Kapazität von “4±1” stammt aus Cowan’s (2001) Revision von Millers klassischer “7±2” Regel. Moderne Forschung zeigt, dass die echte Kapazität ohne Chunking-Strategien näher bei 4 liegt.\n\n\n\n\n\n4 Erwünschte Schwierigkeiten\nSprechtext:\nDas bringt uns zu einem kontraintuitiven Konzept: den erwünschten Schwierigkeiten, oder auf Englisch “Desirable Difficulties”.\nHier ein Zitat von Robert Bjork, der dieses Konzept geprägt hat:\n\n“Conditions that slow the rate of apparent learning often optimize long-term retention and transfer.”\n\nÜbersetzt: Bedingungen, die das scheinbare Lernen verlangsamen, optimieren oft das langfristige Behalten und den Transfer.\n\n\n\n\n\n\n\nWarnung Merksatz\n\n\n\nSchwerer fühlt sich schlechter an, ist aber besser für langfristiges Lernen.\n\n\nDas ist ein fundamentales Prinzip, das wir immer wieder vergessen. Wenn Lernen sich leicht anfühlt, lernen wir wahrscheinlich weniger, als wenn es sich anstrengend anfühlt.\n\n\n\n\n\n\nHinweisHintergrund: Desirable Difficulties\n\n\n\nRobert Bjork prägte diesen Begriff in den 1990er Jahren. Die Forschung zeigt konsistent, dass bestimmte “Schwierigkeiten” das Lernen verbessern:\nWarum wirken Desirable Difficulties?\n\nSie erzwingen tiefere Verarbeitung\nSie aktivieren Abrufprozesse, die das Gedächtnis stärken\nSie verhindern “Fluency Illusions” (wir überschätzen unser Wissen, wenn etwas leicht erscheint)\n\nWichtige Einschränkung:\nNicht alle Schwierigkeiten sind erwünscht. Die Schwierigkeit muss produktiv sein, also tatsächlich zu Lernprozessen führen. Frustrierende, verwirrende oder irrelevante Schwierigkeiten sind nicht erwünscht.\nDie Kunst liegt darin, den “Sweet Spot” zu finden: herausfordernd genug, um Lernen zu erzwingen, aber nicht so schwer, dass Lernende aufgeben.\n\n\n\n\n\n5 Die vier Strategien\nSprechtext:\nBjork hat vier konkrete Strategien identifiziert, die als erwünschte Schwierigkeiten fungieren:\n für jede Strategie\n\n Selbst generieren. Eigene Antworten formulieren, statt vorgegebene zu lesen.\n Verteilt lernen. Zeitliche Abstände einbauen. 4x1h &gt; 1x4h.\n Aktiv abrufen. Wissen aus dem Gedächtnis holen, statt nachzuschlagen.\n Variieren. Themen und Aufgabentypen mischen.\n\n\n\n\n\n\n\n\nWichtig Kritischer Punkt\n\n\n\nKI kann jede dieser Strategien untergraben, wenn sie die kognitive Arbeit übernimmt.\nWarum selbst generieren, wenn KI es besser kann? Warum sich anstrengen, wenn die Antwort einen Klick entfernt ist?\n\n\n\n\n\n\n\n\nTipp Kurs-Hinweis\n\n\n\nWie man KI-Anwendungen so gestaltet, dass sie diese Strategien unterstützen statt untergraben: Intermediate-Kurs\n\n\n\n\n\n\n\n\nHinweisHintergrund: Die vier Strategien im Detail\n\n\n\n1. Generation Effect (Selbst generieren) - Erste Studien: Slamecka & Graf (1978) - Material, das selbst produziert wird, wird besser behalten als gelesenes - Gilt für Wörter, Sätze, Konzepte, Problemlösungen\n2. Spacing Effect (Verteiltes Lernen) - Einer der robustesten Befunde der Lernpsychologie - Optimaler Abstand: Ebbinghaus (1885), Cepeda et al. (2006) - Gilt über Minuten, Tage, Wochen, Monate\n3. Testing Effect / Retrieval Practice (Aktiver Abruf) - Roediger & Karpicke (2006): Testen ist besser als erneutes Studieren - Jeder erfolgreiche Abruf stärkt die Gedächtnisspur - Auch erfolglose Abrufversuche (mit Feedback) sind wirksam\n4. Interleaving (Variieren) - Rohrer & Taylor (2007): Gemischtes Üben schlägt geblocktes Üben - Erhöht die Diskriminationsfähigkeit - Fühlt sich während des Übens schwieriger an, führt aber zu besserem Transfer\nKI und diese Strategien:\n\nGeneration: KI generiert für uns\nSpacing: KI liefert instant Antworten, kein Warten\nRetrieval: KI macht Abruf unnötig\nInterleaving: KI löst jede Aufgabe einzeln, ohne Variation zu erzwingen\n\n\n\n\n\n\n6 Der Generierungseffekt\nSprechtext:\nSchauen wir uns den Generierungseffekt genauer an, weil er besonders relevant für KI ist.\nDie Grafik zeigt die Behaltensleistung in Prozent. Selbst generierte Information wird am besten behalten, etwa 70 Prozent. Gelesene Information liegt bei etwa 50 Prozent. Und von KI erhaltene Information? Noch niedriger, hier spekulativ bei etwa 35 Prozent dargestellt.\nDie Forschung zum Generierungseffekt stammt aus den 1970er Jahren. Slamecka und Graf zeigten, dass selbst produziertes Material besser behalten wird als passiv aufgenommenes.\n\n\n\n\n\n\n\nWarnung Implikation\n\n\n\nWenn KI generiert, was Studierende selbst produzieren sollten, entfällt der Lerneffekt.\n\n\n\nAber dieser Effekt ist nicht neu. Immer wenn Technologie kognitive Arbeit übernimmt, sehen wir ähnliche Muster. Das bringt uns zu den historischen Analogien.\n\n\n\n\n\n\nHinweisHintergrund: Der Generierungseffekt\n\n\n\nUrsprüngliche Studie: Slamecka & Graf (1978) zeigten, dass Teilnehmer Wörter besser erinnerten, wenn sie diese aus einem Hinweis generieren mussten (z.B. “schnell - s____” für “schnell - schnee”), als wenn sie beide Wörter nur lasen.\nWarum funktioniert es?\n\nTiefere Verarbeitung während der Generierung\nVerknüpfung mit bestehendem Wissen\nStärkere Gedächtnisrepräsentation\n\nGrenzen:\n\nEffekt ist stärker für semantisch bedeutsames Material\nGenerierung muss erfolgreich sein (oder Feedback muss folgen)\nÜberanstrengung kann kontraproduktiv sein\n\nDer “Von KI erhalten”-Balken:\nDie 35% sind illustrativ, nicht aus einer spezifischen Studie. Allerdings gibt es Hinweise, dass passiv erhaltene, nicht selbst verarbeitete Information schlecht behalten wird. Die Bastani-Studie und ähnliche Befunde deuten in diese Richtung.\n\n\n\n\n\n7 Historische Analogien\nSprechtext:\nHier sehen Sie eine Zeitlinie technologischer Entwicklungen und ihrer Auswirkungen auf unsere kognitiven Fähigkeiten.\nDie 1970er: Der Taschenrechner. Studien zeigen, dass früher und intensiver Taschenrechner-Einsatz das konzeptuelle mathematische Verständnis beeinträchtigen kann.\nDie 1990er: GPS-Navigation. Habitueller GPS-Gebrauch ist mit schwächerem räumlichem Gedächtnis assoziiert. Londoner Taxifahrer, die “The Knowledge” lernen müssen, haben messbar grössere Hippocampi.\nDie 2000er: Google. Sparrow und Kollegen zeigten den “Google-Effekt”: Wir erinnern besser, WO Information zu finden ist, als WAS die Information ist.\nDie 2020er: KI. Und jetzt? KI kombiniert und verstärkt all diese Effekte. Sie kann Rechnen, Navigieren, Suchen, aber auch: Schreiben, Analysieren, Argumentieren, Kreativ sein.\n\n\n\n\n\n\n\nWarnung Der Unterschied\n\n\n\nKI ist breiter als GPS oder Taschenrechner. Sie betrifft nicht eine kognitive Domäne, sondern potenziell alle.\n\n\n\n\n\n\n\n\nHinweisHintergrund: Die Studien im Detail\n\n\n\nTaschenrechner (1970er-heute): Meta-Analysen zeigen gemischte Ergebnisse. Der Schlüssel ist WANN Taschenrechner eingesetzt werden. Für bereits beherrschte Algorithmen: förderlich. Bevor konzeptuelles Verständnis aufgebaut ist: hinderlich.\nGPS (Dahmani und Bohbot 2020): Die Studie zeigte, dass häufiger GPS-Gebrauch mit schlechterem räumlichem Gedächtnis korreliert, auch nach Kontrolle für andere Faktoren. Die Kausalität ist schwer zu etablieren, aber die Theorie ist plausibel: Wer nicht navigiert, trainiert den Hippocampus nicht.\nDie berühmte Taxifahrer-Studie (Maguire et al., 2000) zeigte strukturelle Gehirnveränderungen bei Londoner Cabbies. Interessanterweise: Nach der Pensionierung bildete sich der Effekt teilweise zurück.\nGoogle-Effekt (Sparrow, Liu, und Wegner 2011): Teilnehmer erinnerten Information schlechter, wenn sie glaubten, diese sei gespeichert und abrufbar. Aber sie erinnerten den Speicherort besser. Das Gehirn outsourcet strategisch.\nDie KI-Frage: Was passiert, wenn wir nicht nur Faktenwissen, sondern auch Denk- und Analyseprozesse outsourcen können? Die historischen Analogien sind instruktiv, aber KI ist qualitativ anders.\n\n\n\n\n\n8 Die entscheidende Frage\nSprechtext:\nDas bringt uns zur entscheidenden Frage.\nDas gleiche Werkzeug, unterschiedliche Ergebnisse.\n\n\n Taschenrechner helfen Mathematikern enorm. Aber für Lernende können sie schädlich sein.\n GPS unterstützt Taxifahrer. Aber es schwächt das räumliche Gedächtnis von Menschen, die es noch nicht aufgebaut haben.\n\n\n\n\n\n\n\n\nWarnung Die entscheidende Frage\n\n\n\nNicht OB KI nützt oder schadet. Sondern: WER profitiert und wer nicht?\n\n\n\nDie Antwort liegt in dem, was Experten von Lernenden unterscheidet.\n\n\n\n\n\n\nHinweisHintergrund: Die Werkzeug-Nutzer-Interaktion\n\n\n\nDas Paradox kognitiver Werkzeuge:\nWerkzeuge, die Experten produktiver machen, können Lernenden schaden. Das liegt an unterschiedlichen Bedürfnissen:\n\nExperten müssen Routine-Aufgaben erledigen, um sich auf höhere Aufgaben zu konzentrieren. Werkzeuge, die Routine automatisieren, befreien kognitive Kapazität.\nLernende müssen genau diese Routine-Aufgaben üben, um Expertise aufzubauen. Werkzeuge, die übernehmen, nehmen die Lernchance.\n\nDas Matthew-Prinzip:\n“Wer hat, dem wird gegeben.” Experten werden durch Werkzeuge noch besser. Lernende riskieren, nie Expertise zu entwickeln.\nImplikation:\nDie pauschale Frage “Sollten wir KI im Unterricht erlauben?” ist falsch gestellt. Die richtige Frage ist: “Für wen, wann, unter welchen Bedingungen, und mit welcher Unterstützung?”\n\n\n\n\n\n9 Was Experten sehen\nSprechtext:\nSchauen wir uns an, was Experten von Novizen unterscheidet. Das klassische Beispiel kommt aus der Schachforschung.\n[Bild zeigt eine Schachstellung]\n Novize sieht: 64 Felder, 32 Figuren, viele Möglichkeiten. Die Einzelteile.\n\n Experte sieht: “Sizilianische Verteidigung, Königsangriff möglich, Schwäche auf f7.” Muster und Bedeutung.\n\n\n\n\n\n\n\nWarnung Der fundamentale Unterschied\n\n\n\nExperten speichern Wissen in “Chunks”: vernetzte Wissensstrukturen, die automatisch abgerufen werden.\n\n\nEin Schachmeister hat etwa 50.000 solcher Chunks im Langzeitgedächtnis. Er sieht nicht 32 Figuren, er sieht bekannte Konstellationen, Pläne, Gefahren.\nDie Forschung dazu geht auf de Groot zurück und wurde von Chase und Simon quantifiziert. Wenn man Meistern und Anfängern kurz eine Stellung zeigt, erinnern Meister viel mehr. Aber nur bei sinnvollen Stellungen! Bei zufällig platzierten Figuren sind Meister nicht besser als Anfänger.\n\n\n\n\n\n\nHinweisHintergrund: Expertise-Forschung im Schach\n\n\n\nDe Groot (1965/1978): Der niederländische Psychologe Adriaan de Groot untersuchte, wie Grossmeister denken. Überraschenderweise rechneten sie nicht mehr Züge voraus als schwächere Spieler. Sie erkannten bessere Züge schneller.\nChase & Simon (1973): Sie quantifizierten den Expertise-Effekt: - 5-Sekunden-Exposition einer Schachstellung - Meister erinnerten ~16 von 24 Figuren - Anfänger erinnerten ~4 von 24 Figuren - Bei Zufallsstellungen: beide etwa 3-4\nDie Chunk-Hypothese: Experten haben nicht bessere Gedächtnisse. Sie haben bessere Organisationsstrukturen. Ein “Chunk” ist eine bedeutungsvolle Einheit (z.B. “Königsindische Verteidigung” statt “Springer auf f6, Bauern auf d6 und e5, Läufer auf g7…”).\nGeschätzte Chunk-Anzahl: - Grossmeister: ~50.000-100.000 Schach-Chunks - Zum Vergleich: Ein Wortschatz hat ähnliche Grössenordnungen\nTransfer zu anderen Domänen: Ähnliche Muster wurden gefunden bei: - Ärzten bei der Diagnose (Chi et al.) - Programmierern beim Code-Lesen - Physikern bei Problemkategorisierung\n\n\n\n\n\n10 Der Expertise-Umkehr-Effekt\nSprechtext:\nDas bringt uns zu einem der wichtigsten Befunde der Instruktionsforschung: dem Expertise-Umkehr-Effekt.\n Hinweis auf Interaktivität: Sie können die Prozent-Buttons anklicken, um zu sehen, wie sich die optimale Lehrmethode verändert.\nAuf der x-Achse sehen Sie das Vorwissen des Lernenden, von niedrig bis hoch. Auf der y-Achse den Lerneffekt.\nDie magentafarbene Linie zeigt hohe Unterstützung: ausgearbeitete Beispiele, direkte Instruktion, Schritt-für-Schritt-Anleitungen.\nDie graue Linie zeigt niedrige Unterstützung: problembasiertes Lernen, eigene Lösungswege finden lassen.\nBei niedrigem Vorwissen (klicken Sie mal auf 20%): hohe Unterstützung besser. Novizen brauchen Struktur.\nAber bei hohem Vorwissen (80% oder 100%): niedrige Unterstützung besser. Detaillierte Anleitungen werden redundant und stören sogar.\n\n\n\n\n\n\nWarnung Expertise-Umkehr-Effekt\n\n\n\nWas für Novizen optimal ist, ist für Experten suboptimal. Und umgekehrt.\n\n\n\n\n\n\n\n\nHinweisHintergrund: Expertise Reversal Effect\n\n\n\nUrsprung: Der Effekt wurde von Kalyuga et al. (2003) systematisch dokumentiert, basierend auf Swellers Cognitive Load Theory.\nMechanismus:\nBei Novizen: - Wenig Chunks im Langzeitgedächtnis - Arbeitsgedächtnis wird schnell überlastet - Externe Unterstützung reduziert Cognitive Load - Mehr Kapazität für Lernen\nBei Experten: - Viele Chunks verfügbar - Externe Instruktion wird mit internem Wissen integriert - Redundante Information erzeugt EXTRA Cognitive Load - Weniger Kapazität für Lernen\nPraktische Implikation:\nInstruktion muss dynamisch an den Lernstand angepasst werden. “Fading” ist eine Technik: Beginne mit hoher Unterstützung, reduziere sie graduell mit wachsender Expertise.\nFür KI:\nKI bietet typischerweise “volle Unterstützung” (direkte Antworten). Das ist für Experten nützlich, für Novizen potenziell schädlich. “GPT Tutors” mit pädagogischen Leitplanken versuchen, dies zu adressieren.\n\n\n\n\n\n11 Warum Experten profitieren, Lernende nicht\nSprechtext:\nJetzt können wir zusammenfassen, warum Experten und Lernende so unterschiedlich von KI-Werkzeugen betroffen sind.\n für jeden Punkt\n Experten:\n\n Können Routine auslagern\n Können KI-Output bewerten\n Mehr Kapazität für Komplexes\n\n\n Lernende:\n\n Können KI-Output nicht bewerten\n Überspringen möglicherweise Grundlagen\n Risiko: “fliessende Inkompetenz” (mit Hilfe alles, ohne Hilfe nichts)\n\n\n\n\n\n\n\n\nWarnung Fazit\n\n\n\nDasselbe Werkzeug, fundamental unterschiedliche Auswirkungen.\n\n\n\n\n\n\n\n\nTipp Kurs-Hinweis\n\n\n\nWarum das so ist: Beginner-Kurs erklärt Funktionsweise und Limitationen von Sprachmodellen.\n\n\n\n\n\n\n\n\nHinweisHintergrund: “Fliessende Inkompetenz”\n\n\n\nDer Begriff: “Fluent incompetence” oder “fliessende Inkompetenz” beschreibt einen Zustand, in dem jemand mit Hilfsmitteln kompetent erscheint, aber ohne sie scheitert.\nHistorische Beispiele: - Pilotin, die nur mit Autopilot fliegen kann - Ärztin, die nur mit Diagnose-Software diagnostizieren kann - Studierende, die nur mit KI schreiben können\nDas Problem:\n\nDie Inkompetenz wird maskiert, bis ein kritischer Moment kommt\nBetroffene überschätzen ihre eigenen Fähigkeiten\nDas Hilfsmittel wird zur unverzichtbaren Krücke\n\nBesonders relevant für Prüfungen:\nWenn Studierende mit KI üben und ohne KI geprüft werden (wie in der Bastani-Studie), wird die fliessende Inkompetenz sichtbar.\nAber auch darüber hinaus:\nWas passiert, wenn die KI nicht verfügbar ist? Bei technischem Ausfall? In Situationen, die Spontanität erfordern? Im Vorstellungsgespräch?\n\n\n\n\n\n12 Kritisches Denken braucht Fachwissen\nSprechtext:\nAn diesem Punkt höre ich oft einen Einwand: “Gut, Lernende können KI-Output nicht bewerten. Aber das ist doch lösbar! Wir bringen ihnen einfach bei, KI-Output kritisch zu prüfen. Kritisches Denken als Kompetenz.”\nDas klingt vernünftig. Aber hier kommt ein wichtiger Punkt von Daniel Willingham, der diesen Ansatz grundlegend in Frage stellt:\n\n “Critical thinking is not a skill. There is not a set of critical thinking skills that can be acquired and deployed regardless of context.”\n\nKritisches Denken ist keine kontextfreie Fähigkeit. Man kann nicht einfach “kritisch denken lernen” und es dann überall anwenden.\n\nBeispiel:\n\n Biomedizin-Experte erkennt Fehler in ChatGPT-Antwort zu Biochemie\n Novize kann diese Bewertung nicht vornehmen\n\n\n\n\n\n\n\n\nWarnung Kernaussage\n\n\n\nDu kannst nicht kritisch bewerten, was du nicht verstehst.\n\n\n\nUnd genau deshalb ist Fachwissen so entscheidend: Es bestimmt, ob KI deine Kognition erweitert oder ersetzt.\n\n\n\n\n\n\nHinweisHintergrund: Willinghams Argument\n\n\n\nDaniel Willingham ist kognitiver Psychologe an der University of Virginia, bekannt für die Anwendung kognitiver Forschung auf Bildung.\nSein Argument im Detail:\nKritisches Denken erfordert: 1. Domänenwissen (Fakten und Konzepte) 2. Kenntnis der relevanten Argumente und Gegenargumente 3. Vertrautheit mit typischen Fehlern in der Domäne\nKeines davon ist übertragbar. Wer kritisch über Geschichte denken kann, kann nicht automatisch kritisch über Biologie denken.\nImplikation für “KI-Kompetenz”:\nEs gibt keine allgemeine “Fähigkeit, KI-Output zu bewerten”. Man kann KI-Output in einer Domäne nur bewerten, wenn man die Domäne versteht.\nDas Problem für Lernende:\nWenn man ihnen sagt “Prüfe die KI-Antwort kritisch”, ohne dass sie das Fachwissen haben, ist das eine leere Anweisung. Sie können höchstens oberflächliche Checks durchführen (Konsistenz, Grammatik), aber nicht inhaltliche.\nMöglicher Ausweg:\nKI als Tutor, der nicht Antworten gibt, sondern Fragen stellt und Hinweise gibt. Dann bleibt das Denken beim Lernenden.\n\n\n\n\n\n13 Kognition erweitern vs. ersetzen\nSprechtext:\nAndy Clark, ein Philosoph an der University of Edinburgh, hat eine nützliche Unterscheidung eingeführt.\n für linke Spalte\n Kognition erweitern:\n\nMensch bleibt kognitiv engagiert\nWerkzeug verstärkt Fähigkeiten, ersetzt sie nicht\nBeispiel: Taschenrechner für Mathematiker\n\n für rechte Spalte\n Kognition ersetzen:\n\nMensch wird passiv\nWerkzeug übernimmt das Denken\nBeispiel: Student lässt ChatGPT Essay schreiben\n\n\n\n\n\n\n\n\nWarnung Wichtiger Punkt\n\n\n\nDasselbe Werkzeug kann beides sein, abhängig von der Nutzung.\nChatGPT als Brainstorming-Partner  Erweiterung\nChatGPT als Ghostwriter  Ersetzung\n\n\n\n\n\n\n\n\nHinweisHintergrund: Extended Mind Thesis\n\n\n\nAndy Clark entwickelte mit David Chalmers die “Extended Mind Thesis” (1998): Kognition endet nicht an der Schädelgrenze. Werkzeuge können Teil des kognitiven Systems werden.\nClarks neuere Arbeit zu KI:\nIn “Extending Minds with Generative AI” (2025) argumentiert Clark, dass generative KI besonders geeignet ist, Kognition zu erweitern, weil sie flexibel und sprachbasiert ist.\nAber mit einer Warnung:\nErweiterung gelingt nur, wenn: 1. Der Nutzer das Werkzeug versteht 2. Der Nutzer die Kontrolle behält 3. Der Nutzer die Ergebnisse evaluieren kann\nFür Experten sind diese Bedingungen typischerweise erfüllt. Für Lernende nicht unbedingt.\nErsetzung vs. Erweiterung:\n\nErweiterung: Du + Werkzeug &gt; Du allein\nErsetzung: Werkzeug anstelle von Dir\n\nBei Ersetzung: Keine Entwicklung, keine Übung, keine Expertise.\nDie pädagogische Frage:\nWie gestalten wir KI-Nutzung so, dass sie erweitert statt ersetzt? Antwort: Durch Aufgabendesign, Leitplanken, und bewusste Reflexion.\n\n\n\n\n\n14 Die Sequenzierungsfrage\nSprechtext:\nDas bringt uns zur praktischen Frage: Wenn Experten profitieren und Lernende Gefahr laufen, wann ist der Übergang?\nHier sehen wir das Spektrum: Links der Novize, rechts der Experte. Irgendwo dazwischen liegt eine Schwelle.\n für jeden Punkt\n Das Problem:\n\nSchwelle ist unbekannt\nVariiert nach Domäne und Person\nKeine pauschalen Regeln möglich\n\n\n\n\n\n\n\n\nWarnung Die praktische Frage\n\n\n\nWer profitiert von KI-Werkzeugen? Und wer nicht?\n Hängt ab vom spezifischen Kontext, der Person, der Aufgabe.\n\n\n\n\n\n\n\n\nHinweisHintergrund: Die Sequenzierungsfrage\n\n\n\nDas Dilemma:\nWenn wir zu früh KI erlauben: Lernende bauen keine Expertise auf. Wenn wir zu lange KI verbieten: Wir ignorieren nützliche Werkzeuge und bereiten nicht auf die Realität vor.\nAnsätze aus der Literatur:\n\nErst Grundlagen, dann Werkzeuge: Wie bei Taschenrechnern. Erst Kopfrechnen, dann Taschenrechner.\nFading: Beginne ohne KI, führe sie graduell ein.\nReflexive Integration: Erlaube KI, aber fordere explizite Reflexion über den eigenen Lernprozess.\nAufgabendifferenzierung: Manche Aufgaben ohne KI, andere mit.\n\nDas Forschungsdefizit:\nEs gibt noch keine Längsschnittstudien, die zeigen, welche Sequenzierung optimal ist. Die Bastani-Studie ist kurzfristig. Wir wissen nicht, wie sich verschiedene Strategien über Semester oder Jahre auswirken.\nPraktische Empfehlung:\nIn Ermangelung perfekter Evidenz: Konservativ beginnen. Die Risiken des zu frühen Einsatzes (Lerndefizite) sind schwerer zu reparieren als die Kosten des zu späten Einsatzes (ineffiziente Arbeit).\n\n\n\n\n\n15 Die Kernaussage\nSprechtext:\n[Pause]\n\n\n\n\n\n\n\nWichtig   DIE KERNAUSSAGE\n\n\n\nKI-Werkzeuge sind für Experten gemacht.\n\n\n\nDas ist keine Wertung, sondern eine Feststellung. Diese Werkzeuge wurden von Experten entwickelt, für Experten-Workflows optimiert, und funktionieren am besten für Menschen, die bereits wissen, was sie tun.\nSie machen Experten produktiver:\n\n Programmierer mit GitHub Copilot\n Forscher mit Literature-Review-Tools\n Schreiber mit KI-Unterstützung\n\n\nAber: Lernende profitieren oft nicht. Lernen erfordert genau die kognitive Anstrengung, die KI zu eliminieren droht.\n Der entscheidende Punkt: Es ist nicht unvermeidlich! Erinnern Sie sich an den GPT-Tutor aus der Bastani-Studie? KI, die Fragen stellt statt Antworten zu geben  erhält die kognitive Anstrengung.\n\n\n\n\n\n\nTipp Kurs-Hinweis\n\n\n\nIm Advanced-Kurs entwickeln Sie selbst ein solches pädagogisch gestaltetes KI-Tool.\n\n\n\n\n\n\n\n\n\nWichtig Die wichtigste Aussage heute\n\n\n\nLernende brauchen erst das Fundament, das kritische KI-Nutzung ermöglicht.\nNicht “keine KI”, aber “Fundament zuerst”.\n\n\n\n\n\n\n\n\nHinweisHintergrund: Zusammenfassung der Argumentation\n\n\n\nDie Argumentationskette:\n\nKI übernimmt kognitive Arbeit\nFür Experten: Entlastung von Routine, mehr Kapazität für Komplexes\nFür Lernende: Wegfall der Lernarbeit, keine Expertise-Entwicklung\nDer Expertise-Umkehr-Effekt erklärt diesen Unterschied theoretisch\nDie Bastani-Studie belegt ihn empirisch\n\nWas das NICHT bedeutet:\n\nKI ist schlecht (Nein: KI ist kontextabhängig)\nKI sollte verboten werden (Nein: KI sollte klug eingesetzt werden)\nStudierende sind unmündig (Nein: aber sie brauchen Anleitung beim Aufbau von Expertise)\n\nWas es BEDEUTET:\n\nDifferenzierte Strategien je nach Lernstand\nExplizite Reflexion über KI-Nutzung\nPrüfungsformate überdenken\nDozierende müssen selbst KI-kompetent werden\n\nDie Rolle der Institution:\nHochschulen müssen Rahmenbedingungen schaffen, die gesunde KI-Nutzung ermöglichen. Das erfordert Diskussion, Experimente, und Iteration. Es gibt keine einfachen Antworten.\n\n\n\n\n\n16 Was bedeutet das für die Lehre?\nSprechtext:\nZum Abschluss: Was bedeutet das konkret für unsere Lehre?\n für jede Säule\n\n\n\n\n\n\nWarnung Anstrengung ist das Signal\n\n\n\nWenn Lernen sich zu leicht anfühlt, findet es wahrscheinlich nicht statt.\n\n\n\n\n\n\n\n\nWarnung KI als Tutor, nicht als Antwortgeber\n\n\n\nKI soll Denkprozesse anregen, nicht ersetzen. Fragen stellen, Hinweise geben.\n\n\n\n\n\n\n\n\nWarnung Expertise bestimmt den Nutzen\n\n\n\nDasselbe Werkzeug wirkt unterschiedlich je nach Vorwissen. Differenzieren!\n\n\n\n\n\n\n\n\n\nWichtig   ZUSAMMENFASSUNG\n\n\n\nGrundlagen BEVOR Werkzeuge.\nErst das Fundament, dann die Erweiterung.\nErst verstehen, dann automatisieren.\nErst selbst können, dann delegieren.\n\n\nVielen Dank. \n\n\n\n\n\n\nHinweisHintergrund: Praktische Implikationen\n\n\n\nFür die Kursplanung:\n\nExplizit machen: Erklären Sie Studierenden, warum bestimmte Aufgaben ohne KI zu lösen sind\nStufenweise einführen: KI-Zugang kann mit steigender Kompetenz erweitert werden\nReflexion einbauen: Fragen Sie nach jedem KI-Einsatz: “Was habe ich dabei gelernt?”\n\nFür Prüfungen:\n\nDiversifizieren: Nicht alle Prüfungen können KI-gestützt sein\nProzessprüfungen: Nicht nur Endprodukte, sondern auch den Weg dorthin prüfen\nMündliche Elemente: KI kann (noch) nicht für jemanden sprechen\n\nFür die eigene Entwicklung:\n\nSelbst KI nutzen: Nur wer KI kennt, kann sinnvoll beraten\nExperimente wagen: Probieren Sie verschiedene Ansätze aus\nAustausch suchen: Sprechen Sie mit Kolleginnen und Kollegen\n\nWeiterführende Ressourcen:\n\nMollick, E. (2024). “Co-Intelligence”\nNationales Forum Hochschullehre: KI-Leitlinien\nStanford HAI: Reports zu KI in der Bildung\n\nBFH Weiterbildung:\n\nBeginner: Grundlagen zu Sprachmodellen und Chatbots\nIntermediate: Lernpsychologie und KI-gestütztes Lerndesign\nAdvanced: Workshop zur Entwicklung eines eigenen KI-Lerntools\n\n\n\n\n\n\n17 Referenzen\nSprechtext:\nDie Referenzen finden Sie in den Folien und im begleitenden Materialien. Die wichtigsten sind:\n\nBastani et al. für die empirische Studie\nSweller für die Cognitive Load Theory\nBjork für die erwünschten Schwierigkeiten\nKalyuga für den Expertise-Umkehr-Effekt\nWillingham für kritisches Denken und Fachwissen\nClark für die Erweiterung vs. Ersetzung der Kognition\n\nIch freue mich auf Ihre Fragen und die Diskussion.\n\n\n\n\n\n\nHinweisVollständige Referenzliste\n\n\n\nHauptquellen der Präsentation:\n\nBastani, H., et al. (2025). Generative AI can harm learning. PNAS.\nBjork, R. A. (2011). Making things hard on yourself, but in a good way. In Gernsbacher et al. (Eds.), Psychology and the real world.\nChase, W. G., & Simon, H. A. (1973). Perception in chess. Cognitive Psychology.\nClark, A. (2025). Extending minds with generative AI. Philosophy & Technology.\nDahmani, L., & Bhorer, V. (2020). Habitual use of GPS negatively impacts spatial memory. Scientific Reports.\nde Groot, A. D. (1978). Thought and choice in chess. Mouton.\nKalyuga, S. (2009). The expertise reversal effect. In Plass et al. (Eds.), Cognitive load theory.\nSlamecka, N. J., & Graf, P. (1978). The generation effect. Journal of Experimental Psychology: Human Learning and Memory.\nSparrow, B., et al. (2011). Google effects on memory. Science.\nSweller, J. (2024). Cognitive load theory. In The Cambridge handbook of cognition and education.\nWillingham, D. T. (2008). Critical thinking: Why is it so hard to teach? Arts Education Policy Review.\n\n\n\n\n\n\n\n\n Zurück nach obenLiteratur\n\nDahmani, Louisa, und Véronique D. Bohbot. 2020. „Habitual Use of GPS Negatively Impacts Spatial Memory During Self-Guided Navigation“. Scientific Reports 10 (1): 6310. https://doi.org/10.1038/s41598-020-62877-0.\n\n\nSparrow, Betsy, Jenny Liu, und Daniel M. Wegner. 2011. „Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips“. Science (New York, N.Y.) 333 (6043): 776–78. https://doi.org/10.1126/science.1207745."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html",
    "href": "notes/socratic-questioning-expose.html",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "",
    "text": "The integration of large language models into educational technology has revived long-standing enthusiasm for Socratic tutoring: the ancient pedagogical method of guiding learners toward understanding through strategic questioning rather than direct instruction. Proponents suggest that AI chatbots can now deliver personalized, one-on-one Socratic dialogue at scale, democratizing access to the kind of individualized instruction once available only to the privileged few with access to expert human tutors.\nThis enthusiasm is understandable. The “two sigma problem” identified by Bloom (1984) demonstrated that students receiving one-on-one tutoring performed two standard deviations better than those in conventional classroom instruction, an effect so large that it would move an average student to the 98th percentile. If AI could approximate even a fraction of this benefit, the implications for educational equity would be profound.\nMarketing materials from educational technology companies now routinely invoke Socratic methods, promising that their AI tutors will ask probing questions, guide discovery, and foster deep understanding. Yet a careful examination reveals a substantial gap between these claims and the current evidence base. This exposé examines what cognitive science tells us about why Socratic questioning might work, what the empirical evidence actually shows, and what challenges must be overcome before AI can deliver on these promises."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#introduction-the-promise-of-the-digital-socrates",
    "href": "notes/socratic-questioning-expose.html#introduction-the-promise-of-the-digital-socrates",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "",
    "text": "The integration of large language models into educational technology has revived long-standing enthusiasm for Socratic tutoring: the ancient pedagogical method of guiding learners toward understanding through strategic questioning rather than direct instruction. Proponents suggest that AI chatbots can now deliver personalized, one-on-one Socratic dialogue at scale, democratizing access to the kind of individualized instruction once available only to the privileged few with access to expert human tutors.\nThis enthusiasm is understandable. The “two sigma problem” identified by Bloom (1984) demonstrated that students receiving one-on-one tutoring performed two standard deviations better than those in conventional classroom instruction, an effect so large that it would move an average student to the 98th percentile. If AI could approximate even a fraction of this benefit, the implications for educational equity would be profound.\nMarketing materials from educational technology companies now routinely invoke Socratic methods, promising that their AI tutors will ask probing questions, guide discovery, and foster deep understanding. Yet a careful examination reveals a substantial gap between these claims and the current evidence base. This exposé examines what cognitive science tells us about why Socratic questioning might work, what the empirical evidence actually shows, and what challenges must be overcome before AI can deliver on these promises."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#the-cognitive-mechanisms-why-questioning-might-matter",
    "href": "notes/socratic-questioning-expose.html#the-cognitive-mechanisms-why-questioning-might-matter",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "The cognitive mechanisms: Why questioning might matter",
    "text": "The cognitive mechanisms: Why questioning might matter\nBefore evaluating AI implementations, we must understand the cognitive mechanisms that make Socratic questioning potentially effective. Three interconnected processes are particularly relevant: the generation effect, self-explanation, and the management of cognitive load.\n\nThe generation effect\nThe generation effect refers to the robust finding that actively generating information produces better retention than passively receiving it [@slameckaGenerationEffect1978]. When a tutor asks a question rather than providing an answer, the learner must retrieve relevant knowledge, construct a response, and articulate their thinking. This effortful processing creates stronger and more accessible memory traces than simply reading or hearing an explanation.\nHowever, the generation effect has important boundary conditions. It is most pronounced when learners possess sufficient prior knowledge to generate meaningful responses. When prerequisite knowledge is absent, generation attempts may produce errors that become encoded alongside correct information, potentially interfering with subsequent learning [@metcalfeLearningErrors2017]. This suggests that effective Socratic tutoring requires accurate diagnosis of learner knowledge states, a challenge we will return to below.\n\n\nSelf-explanation\nChi and colleagues [-@chiSelfExplanationsHowStudents1989; -@chiElicitingSelfExplanationsImproves1994] demonstrated that learners who explain material to themselves, articulating the reasoning behind problem solutions or connecting new information to prior knowledge, show superior learning outcomes. Socratic questioning can prompt self-explanation by asking learners to justify their reasoning, consider why an approach works, or relate new concepts to familiar ones.\nThe self-explanation effect appears to operate through multiple mechanisms: identifying gaps in understanding, integrating new information with existing knowledge structures, and making implicit knowledge explicit. Importantly, prompting self-explanation is more effective than simply providing explanations, because the learner must engage in the constructive work of building coherent mental representations [@wylieChiSelfExplanationPrinciple2014].\n\n\nCognitive load considerations\nCognitive load theory [@swellerCognitiveLoadTheory2011] reminds us that working memory capacity is severely limited, and instructional designs must manage the demands placed on this bottleneck. Socratic questioning introduces a paradox: the additional cognitive effort required to generate responses and self-explain may enhance learning through desirable difficulty, but it may also overwhelm learners who lack adequate schemas to support the processing.\nExpert human tutors navigate this tension through continuous assessment, adjusting question difficulty and providing scaffolding based on moment-to-moment feedback about learner states. They simplify when cognitive overload threatens and challenge when capacity permits. The question for AI implementation is whether current systems can perform this dynamic calibration."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#the-evidence-gap-claims-vs.-data",
    "href": "notes/socratic-questioning-expose.html#the-evidence-gap-claims-vs.-data",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "The evidence gap: Claims vs. data",
    "text": "The evidence gap: Claims vs. data\nDespite the theoretical appeal of Socratic AI tutoring, the empirical evidence remains surprisingly thin. A careful review reveals several concerns about the current state of research.\n\nWhat studies actually show\nEarly intelligent tutoring systems (ITS) that incorporated Socratic elements, such as LISP Tutor and later cognitive tutors, did demonstrate learning gains compared to conventional instruction [@andersonCognitiveTutors1995; @vanlehnRelativeEffectivenessHuman2011]. However, these systems operated in highly constrained domains with explicitly programmed knowledge models, quite different from the open-ended dialogue capabilities of modern large language models.\nVanLehn’s [-@vanlehnRelativeEffectivenessHuman2011] meta-analysis found that human tutoring produced an effect size of approximately 0.79 standard deviations compared to classroom instruction, notably smaller than Bloom’s earlier estimate and suggesting that much of the “two sigma” effect may have reflected methodological artifacts or Hawthorne effects. Intelligent tutoring systems achieved effects around 0.76, surprisingly close to human tutors, but the comparison conditions and outcome measures varied substantially across studies.\nMore recent studies specifically examining LLM-based Socratic tutoring are scarce and methodologically limited. Many rely on user satisfaction surveys rather than learning outcomes, compare AI tutoring to no tutoring rather than alternative instructional methods, or assess performance immediately after instruction without examining retention or transfer. The published literature shows clear signs of publication bias, with negative or null results presumably languishing in file drawers.\n\n\nQuestionable research practices in EdTech research\nSeveral red flags warrant attention. Studies funded by educational technology companies rarely report null findings. Effect sizes often cluster suspiciously close to statistical significance thresholds. Sample sizes are frequently underpowered for detecting the modest effects that educational interventions typically produce. And the enthusiasm gap between press releases and peer-reviewed findings is substantial.\nThe replication crisis has been slower to reach educational technology research than fields like social psychology, but there is little reason to believe the underlying problems (HARKing, p-hacking, and selective reporting) are less prevalent. Researchers evaluating claims about AI tutoring should demand pre-registration, adequately powered samples, and independent replication before accepting strong conclusions."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#key-challenges-for-ai-implementation",
    "href": "notes/socratic-questioning-expose.html#key-challenges-for-ai-implementation",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "Key challenges for AI implementation",
    "text": "Key challenges for AI implementation\nEven granting optimistic assumptions about the underlying mechanisms, AI implementation of Socratic tutoring faces several formidable challenges.\n\nThe diagnosis problem\nEffective Socratic questioning requires accurate assessment of what the learner currently understands and where misconceptions reside. Human tutors accomplish this through years of experience with common error patterns, real-time interpretation of verbal and nonverbal cues, and iterative hypothesis testing. Current AI systems lack access to most of these signals and must infer learner states from text alone.\nThis diagnosis problem is particularly acute because the same incorrect answer can arise from different underlying misconceptions, each requiring different remediation. A student who incorrectly answers that 1/2 + 1/3 = 2/5 might be adding numerators and denominators (a procedural error), might not understand what fractions represent (a conceptual error), or might have made a careless slip. The appropriate Socratic response differs dramatically across these cases.\nLarge language models can generate plausible diagnostic hypotheses, but their accuracy in distinguishing between alternative misconceptions remains largely untested. Without accurate diagnosis, questioning may be misaligned with learner needs: too challenging when foundational gaps exist, too elementary when the learner is ready to advance.\n\n\nQuestioning sequence and contingency\nSocratic dialogue is not simply asking questions; it is asking the right questions in the right order, contingent on learner responses. Collins and Stevens [-@collinsGoalsStrategiesInquiry1982] identified numerous questioning strategies used by expert Socratic tutors: systematically varying cases, testing hypotheses, probing for deeper justification, and introducing counterexamples. The sequencing of these moves is highly responsive to the trajectory of the dialogue.\nCurrent AI systems can generate individual questions that appear Socratic, but maintaining coherent pedagogical trajectories across extended dialogues remains challenging. The tendency of large language models to be agreeably deferential, accepting learner responses without appropriate challenge, may undermine the productive discomfort that genuine Socratic questioning produces. Conversely, excessive challenge without adequate scaffolding may induce frustration and disengagement.\n\n\nFeedback timing and error handling\nWhen learners make errors during Socratic dialogue, tutors face decisions about whether to provide immediate correction, guide the learner toward self-correction through further questioning, or allow productive failure before intervening. Research on feedback timing suggests that the optimal approach depends on learner characteristics, error types, and learning goals: variables that are difficult to assess in real-time AI interactions.\nMoreover, the errors that AI systems themselves make (generating incorrect information, misunderstanding learner queries, or providing inconsistent guidance) create additional complications. Learners may encode AI errors as correct information, particularly when the conversational interface lends an air of authority to responses."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#practical-recommendations-for-educators",
    "href": "notes/socratic-questioning-expose.html#practical-recommendations-for-educators",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "Practical recommendations for educators",
    "text": "Practical recommendations for educators\nGiven the current state of evidence, educators evaluating AI tutoring tools should adopt a stance of informed skepticism. The following recommendations may guide decision-making.\nDemand evidence, not testimonials. Request peer-reviewed studies examining learning outcomes (not just satisfaction), conducted by researchers independent of the company, with adequate sample sizes and appropriate comparison conditions. Be especially wary of studies that compare AI tutoring to no intervention rather than to alternative uses of instructional time.\nAssess diagnostic capabilities. Effective Socratic tutoring requires accurate understanding of learner knowledge states. Evaluate whether the system can distinguish between different types of errors and adjust its questioning accordingly. Generic Socratic prompts applied without diagnosis are unlikely to outperform simpler interventions.\nConsider opportunity costs. Time spent with AI tutors is time not spent on other learning activities. Even if AI tutoring produces some benefit, the relevant question is whether it produces more benefit than alternatives available at similar cost. Reading a well-designed textbook, working through practice problems with immediate feedback, or participating in peer discussion might yield comparable or superior outcomes with less technological overhead.\nStart with constrained domains. The challenges of diagnosis and questioning sequence are more tractable in well-structured domains with clear right and wrong answers. Mathematics and formal logic may be more amenable to AI Socratic tutoring than interpretation-heavy domains like literary analysis or ethical reasoning. Pilot implementations in favorable contexts before broader adoption.\nMonitor for unintended consequences. AI tutoring systems may inadvertently teach students to game the system rather than genuinely engage with content. They may also undermine the development of self-regulated learning skills if students become dependent on external prompting. Implement monitoring to detect such effects."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#conclusion",
    "href": "notes/socratic-questioning-expose.html#conclusion",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "Conclusion",
    "text": "Conclusion\nThe enthusiasm for Socratic AI tutoring rests on genuine cognitive science insights about the benefits of active generation and self-explanation. These mechanisms are well-established, and there is no reason to doubt that appropriate questioning can enhance learning. The question is whether current AI systems can implement these mechanisms effectively in real educational contexts.\nThe honest answer is that we do not yet know. The theoretical case is plausible, but the empirical evidence specific to LLM-based Socratic tutoring remains thin and methodologically limited. The challenges of diagnosis, questioning sequence, and feedback timing are substantial, and current systems have not demonstrated mastery of these capabilities.\nThis is not an argument for dismissing AI tutoring tools entirely. Some may provide value for some learners in some contexts. But educators should resist marketing claims that outpace evidence, maintain appropriate skepticism about extraordinary promises, and insist on rigorous evaluation before committing institutional resources. The goal should be evidence-informed adoption, not technology enthusiasm masquerading as pedagogical innovation.\nSocrates himself might appreciate the irony: the best way to evaluate tools that claim to embody his method is to ask probing questions and refuse to accept answers that lack adequate justification."
  },
  {
    "objectID": "notes/socratic-questioning-expose.html#references",
    "href": "notes/socratic-questioning-expose.html#references",
    "title": "Socratic Questioning in AI Educational Chatbots: Hype vs. Evidence",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "slides/ai-higher-ed/index.html#section",
    "href": "slides/ai-higher-ed/index.html#section",
    "title": "KI in der Hochschulbildung",
    "section": "",
    "text": "Werkzeuge für Experten,Herausforderungen für Lernende\n\n\nWillkommen. Bevor wir beginnen, möchte ich kurz erklären, warum ich diesen Vortrag so aufgebaut habe.\nWenn wir über KI in der Bildung sprechen, hören wir meist zwei Narrative: Entweder “KI revolutioniert das Lernen” oder “KI zerstört die Bildung”. Beide sind zu einfach.\nWas wir brauchen, ist ein Rahmen, um zu verstehen, wann KI hilft und wann sie schadet. Und diesen Rahmen liefert uns die Kognitionspsychologie.\nDer Eisberg hier zeigt das zentrale Problem: Was wir sehen, ist Performance. Was wir nicht sehen, ist Learning. Und die beiden sind nicht dasselbe.\nIch beginne mit einer konkreten Studie, die dieses Paradox illustriert. Dann fragen wir: Warum passiert das? Die Antwort liegt in der Architektur des menschlichen Gedächtnisses.\nAm Ende werden Sie einen Rahmen haben, um KI-Nutzung differenziert zu beurteilen. Nicht “KI ja oder nein”, sondern “für wen, wann, und wie”."
  }
]